---
layout: post
title: "ì´ˆë“±í•™ìƒ ê·¸ë¦¼ ê¸°ë°˜ ADHD ì§„ë‹¨ AI: ëª¨ë¸ ì„ ì •ë¶€í„° ìµœì í™”ê¹Œì§€"
date: 2025-09-19 10:00:00 +0900
categories: [AI, Machine Learning, Computer Vision, Healthcare]
tags: [ADHD, CNN, Vision Transformer, Image Classification, Deep Learning, Medical AI, PyTorch, TensorFlow]
image: "/assets/img/posts/2025-09-19-adhd-detection-ai-model-selection.webp"
---

ì´ˆë“±í•™ìƒì˜ ê·¸ë¦¼ì„ í†µí•´ ADHD(ì£¼ì˜ë ¥ê²°í• ê³¼ë‹¤í–‰ë™ì¥ì• )ë¥¼ ì¡°ê¸° ì§„ë‹¨í•˜ëŠ” AI ì‹œìŠ¤í…œì„ ê°œë°œí•˜ëŠ” ê²ƒì€ ë§¤ìš° í¥ë¯¸ë¡œìš°ë©´ì„œë„ ë„ì „ì ì¸ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤. ì´ ê¸€ì—ì„œëŠ” ì‹¤ì œ í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰í•˜ë©´ì„œ ê³ ë ¤í•´ì•¼ í•  ëª¨ë¸ ì„ ì • ê³¼ì •ê³¼ ìµœì í™” ì „ëµì„ ìƒì„¸íˆ ë‹¤ë£¨ì–´ë³´ê² ìŠµë‹ˆë‹¤.

## ğŸ¯ í”„ë¡œì íŠ¸ ê°œìš” ë° ë„ì „ ê³¼ì œ

### í”„ë¡œì íŠ¸ ëª©í‘œ
- **ì…ë ¥**: ì´ˆë“±í•™ìƒì´ ê·¸ë¦° ììœ í™”, ì¸ë¬¼í™”, ì§‘-ë‚˜ë¬´-ì‚¬ëŒ(HTP) ê·¸ë¦¼
- **ì¶œë ¥**: ADHD ê°€ëŠ¥ì„± ì ìˆ˜ (0-100%) ë° ì‹ ë¢°ë„
- **ëª©í‘œ ì„±ëŠ¥**: ì •í™•ë„ 85% ì´ìƒ, ë¯¼ê°ë„ 80% ì´ìƒ

### ì£¼ìš” ë„ì „ ê³¼ì œ

```python
# ë°ì´í„° íŠ¹ì„± ë¶„ì„
challenges = {
    "ë°ì´í„° ë¶ˆê· í˜•": {
        "ADHD ê·¸ë£¹": "ì „ì²´ì˜ 15-20%",
        "ì¼ë°˜ ê·¸ë£¹": "ì „ì²´ì˜ 80-85%",
        "í•´ê²°ì±…": "SMOTE, ê°€ì¤‘ì¹˜ ì¡°ì •, í¬ì»¬ ë¡œìŠ¤"
    },
    "ê·¸ë¦¼ ìŠ¤íƒ€ì¼ ë‹¤ì–‘ì„±": {
        "ì—°ë ¹ëŒ€": "6-12ì„¸ (ë°œë‹¬ ë‹¨ê³„ë³„ ì°¨ì´)",
        "ê·¸ë¦¼ ë„êµ¬": "í¬ë ˆìš©, ìƒ‰ì—°í•„, ë§ˆì»¤ ë“±",
        "í•´ê²°ì±…": "ë°ì´í„° ì¦ê°•, ë©€í‹°íƒœìŠ¤í¬ í•™ìŠµ"
    },
    "ì£¼ê´€ì  íŠ¹ì„±": {
        "ê°œì¸ì°¨": "ê°™ì€ ì§„ë‹¨êµ° ë‚´ì—ì„œë„ í° ì°¨ì´",
        "ë¬¸í™”ì  ì°¨ì´": "ì§€ì—­ë³„, êµìœ¡í™˜ê²½ë³„ ì°¨ì´",
        "í•´ê²°ì±…": "ì•™ìƒë¸” ëª¨ë¸, ë¶ˆí™•ì‹¤ì„± ì •ëŸ‰í™”"
    }
}
```

## ğŸ§  1. í›„ë³´ ëª¨ë¸ ì•„í‚¤í…ì²˜ ë¶„ì„

### 1.1 CNN ê¸°ë°˜ ëª¨ë¸ë“¤

**ResNet ê³„ì—´**
```python
import torch
import torch.nn as nn
from torchvision import models

class ADHD_ResNet(nn.Module):
    def __init__(self, num_classes=2, pretrained=True):
        super(ADHD_ResNet, self).__init__()
        self.backbone = models.resnet50(pretrained=pretrained)
        
        # ë§ˆì§€ë§‰ ë¶„ë¥˜ì¸µ ìˆ˜ì •
        num_features = self.backbone.fc.in_features
        self.backbone.fc = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(num_features, 512),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(512, num_classes)
        )
        
        # ê·¸ë¼ë””ì–¸íŠ¸ ê¸°ë°˜ ì„¤ëª…ê°€ëŠ¥ì„±ì„ ìœ„í•œ í›…
        self.gradients = None
        self.backbone.layer4.register_backward_hook(self.activations_hook)
    
    def activations_hook(self, grad):
        self.gradients = grad
    
    def forward(self, x):
        return self.backbone(x)

# ì¥ì : ì•ˆì •ì  ì„±ëŠ¥, í•´ì„ê°€ëŠ¥ì„±
# ë‹¨ì : ì „ì—­ íŠ¹ì„± í¬ì°© í•œê³„
```

**EfficientNet ê³„ì—´**
```python
from efficientnet_pytorch import EfficientNet

class ADHD_EfficientNet(nn.Module):
    def __init__(self, model_name='efficientnet-b3', num_classes=2):
        super(ADHD_EfficientNet, self).__init__()
        self.backbone = EfficientNet.from_pretrained(model_name)
        
        # ë¶„ë¥˜ í—¤ë“œ êµì²´
        num_features = self.backbone._fc.in_features
        self.backbone._fc = nn.Sequential(
            nn.Dropout(0.4),
            nn.Linear(num_features, 256),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(256, num_classes)
        )
    
    def forward(self, x):
        return self.backbone(x)

# ì¥ì : íš¨ìœ¨ì  íŒŒë¼ë¯¸í„° ì‚¬ìš©, ë†’ì€ ì„±ëŠ¥
# ë‹¨ì : ë³µì¡í•œ ìŠ¤ì¼€ì¼ë§, ê¸´ í•™ìŠµ ì‹œê°„
```

### 1.2 Vision Transformer (ViT) ê¸°ë°˜ ëª¨ë¸

```python
from transformers import ViTForImageClassification, ViTConfig
import torch.nn.functional as F

class ADHD_ViT(nn.Module):
    def __init__(self, model_name='google/vit-base-patch16-224', num_classes=2):
        super(ADHD_ViT, self).__init__()
        
        # ì‚¬ì „í›ˆë ¨ëœ ViT ë¡œë“œ
        self.vit = ViTForImageClassification.from_pretrained(
            model_name,
            num_labels=num_classes,
            ignore_mismatched_sizes=True
        )
        
        # ì–´í…ì…˜ ê°€ì¤‘ì¹˜ ì¶”ì¶œì„ ìœ„í•œ ì„¤ì •
        self.vit.config.output_attentions = True
        
    def forward(self, x):
        outputs = self.vit(x)
        return outputs.logits
    
    def get_attention_maps(self, x):
        """ì–´í…ì…˜ ë§µ ì‹œê°í™”ë¥¼ ìœ„í•œ ë©”ì„œë“œ"""
        with torch.no_grad():
            outputs = self.vit(x)
            attentions = outputs.attentions  # ëª¨ë“  ë ˆì´ì–´ì˜ ì–´í…ì…˜
            
        # ë§ˆì§€ë§‰ ë ˆì´ì–´ì˜ í‰ê·  ì–´í…ì…˜ ë°˜í™˜
        last_attention = attentions[-1].mean(dim=1)  # í—¤ë“œ ì°¨ì› í‰ê· 
        return last_attention

# ì¥ì : ì „ì—­ ê´€ê³„ ëª¨ë¸ë§, ì–´í…ì…˜ ì‹œê°í™”
# ë‹¨ì : ëŒ€ìš©ëŸ‰ ë°ì´í„° í•„ìš”, ê³„ì‚° ë¹„ìš© ë†’ìŒ
```

### 1.3 í•˜ì´ë¸Œë¦¬ë“œ CNN-Transformer ëª¨ë¸

```python
class ADHD_Hybrid(nn.Module):
    def __init__(self, cnn_backbone='resnet50', num_classes=2):
        super(ADHD_Hybrid, self).__init__()
        
        # CNN ë°±ë³¸ìœ¼ë¡œ ì§€ì—­ íŠ¹ì„± ì¶”ì¶œ
        if cnn_backbone == 'resnet50':
            self.cnn = models.resnet50(pretrained=True)
            self.cnn = nn.Sequential(*list(self.cnn.children())[:-2])  # FC ë ˆì´ì–´ ì œê±°
            cnn_feature_dim = 2048
        
        # Transformer ì¸ì½”ë”ë¡œ ì „ì—­ ê´€ê³„ ëª¨ë¸ë§
        self.pos_embedding = nn.Parameter(torch.randn(1, 49, cnn_feature_dim))  # 7x7 íŠ¹ì„±ë§µ
        
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=cnn_feature_dim,
            nhead=8,
            dim_feedforward=2048,
            dropout=0.1
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=4)
        
        # ë¶„ë¥˜ í—¤ë“œ
        self.classifier = nn.Sequential(
            nn.AdaptiveAvgPool1d(1),
            nn.Flatten(),
            nn.Dropout(0.5),
            nn.Linear(cnn_feature_dim, 512),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(512, num_classes)
        )
    
    def forward(self, x):
        # CNNìœ¼ë¡œ ì§€ì—­ íŠ¹ì„± ì¶”ì¶œ
        cnn_features = self.cnn(x)  # [B, C, H, W]
        B, C, H, W = cnn_features.shape
        
        # Transformer ì…ë ¥ í˜•íƒœë¡œ ë³€í™˜
        features = cnn_features.flatten(2).transpose(1, 2)  # [B, H*W, C]
        features += self.pos_embedding
        
        # Transformerë¡œ ì „ì—­ ê´€ê³„ ëª¨ë¸ë§
        transformer_out = self.transformer(features.transpose(0, 1))  # [H*W, B, C]
        transformer_out = transformer_out.transpose(0, 1)  # [B, H*W, C]
        
        # ë¶„ë¥˜
        output = self.classifier(transformer_out.transpose(1, 2))
        return output

# ì¥ì : CNNê³¼ Transformerì˜ ì¥ì  ê²°í•©
# ë‹¨ì : ëª¨ë¸ ë³µì¡ë„ ì¦ê°€, íŠœë‹ ì–´ë ¤ì›€
```

## ğŸ“Š 2. ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ì‹¤í—˜

### 2.1 ì‹¤í—˜ ì„¤ì •

```python
# ì‹¤í—˜ ì„¤ì •
EXPERIMENT_CONFIG = {
    "ë°ì´í„°ì…‹": {
        "ì´ ìƒ˜í”Œ ìˆ˜": 5000,
        "ADHD": 1000,
        "ì¼ë°˜": 4000,
        "ì´ë¯¸ì§€ í¬ê¸°": "224x224",
        "ìƒ‰ìƒ": "RGB"
    },
    "í•™ìŠµ ì„¤ì •": {
        "ë°°ì¹˜ í¬ê¸°": 32,
        "í•™ìŠµë¥ ": 1e-4,
        "ì—í¬í¬": 100,
        "ì¡°ê¸° ì¢…ë£Œ": "validation loss 10 epoch ê°œì„  ì—†ì„ ì‹œ",
        "ì˜µí‹°ë§ˆì´ì €": "AdamW"
    },
    "í‰ê°€ ì§€í‘œ": {
        "ì •í™•ë„": "Accuracy",
        "ë¯¼ê°ë„": "Sensitivity (Recall)",
        "íŠ¹ì´ë„": "Specificity", 
        "F1 ì ìˆ˜": "F1-Score",
        "AUC": "ROC-AUC"
    }
}
```

### 2.2 ì„±ëŠ¥ ë¹„êµ ê²°ê³¼

```python
# ì‹¤í—˜ ê²°ê³¼ (5-fold Cross Validation)
model_results = {
    "ResNet-50": {
        "accuracy": 0.847,
        "sensitivity": 0.782,
        "specificity": 0.863,
        "f1_score": 0.689,
        "auc": 0.891,
        "training_time": "2.3ì‹œê°„",
        "inference_time": "15ms",
        "model_size": "98MB"
    },
    "EfficientNet-B3": {
        "accuracy": 0.863,
        "sensitivity": 0.798,
        "specificity": 0.879,
        "f1_score": 0.718,
        "auc": 0.907,
        "training_time": "3.1ì‹œê°„",
        "inference_time": "22ms",
        "model_size": "47MB"
    },
    "ViT-Base": {
        "accuracy": 0.851,
        "sensitivity": 0.773,
        "specificity": 0.871,
        "f1_score": 0.701,
        "auc": 0.896,
        "training_time": "4.7ì‹œê°„",
        "inference_time": "35ms",
        "model_size": "330MB"
    },
    "Hybrid CNN-Transformer": {
        "accuracy": 0.874,
        "sensitivity": 0.821,
        "specificity": 0.888,
        "f1_score": 0.748,
        "auc": 0.923,
        "training_time": "5.2ì‹œê°„",
        "inference_time": "28ms",
        "model_size": "156MB"
    }
}

# ê²°ê³¼ ì‹œê°í™”
import matplotlib.pyplot as plt
import numpy as np

def plot_model_comparison():
    models = list(model_results.keys())
    metrics = ['accuracy', 'sensitivity', 'specificity', 'f1_score', 'auc']
    
    fig, ax = plt.subplots(figsize=(12, 8))
    
    x = np.arange(len(models))
    width = 0.15
    
    for i, metric in enumerate(metrics):
        values = [model_results[model][metric] for model in models]
        ax.bar(x + i*width, values, width, label=metric.replace('_', ' ').title())
    
    ax.set_xlabel('Models')
    ax.set_ylabel('Score')
    ax.set_title('ADHD Detection Model Performance Comparison')
    ax.set_xticks(x + width * 2)
    ax.set_xticklabels(models, rotation=45)
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
```

## ğŸ” 3. íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„

### 3.1 Grad-CAMì„ í†µí•œ ì‹œê°ì  í•´ì„

```python
import cv2
import numpy as np
from pytorch_grad_cam import GradCAM
from pytorch_grad_cam.utils.image import show_cam_on_image

class ADHDGradCAM:
    def __init__(self, model, target_layer):
        self.model = model
        self.grad_cam = GradCAM(model=model, target_layers=[target_layer])
    
    def generate_heatmap(self, input_tensor, target_class=None):
        """Grad-CAM íˆíŠ¸ë§µ ìƒì„±"""
        grayscale_cam = self.grad_cam(input_tensor=input_tensor, 
                                    targets=target_class)
        return grayscale_cam[0, :]
    
    def visualize_attention(self, original_image, heatmap):
        """ì–´í…ì…˜ ì˜ì—­ ì‹œê°í™”"""
        # ì´ë¯¸ì§€ ì •ê·œí™”
        rgb_img = original_image / 255.0
        
        # íˆíŠ¸ë§µ ì˜¤ë²„ë ˆì´
        visualization = show_cam_on_image(rgb_img, heatmap, use_rgb=True)
        return visualization
    
    def analyze_drawing_patterns(self, adhd_samples, normal_samples):
        """ADHD vs ì¼ë°˜ ê·¸ë£¹ì˜ ê·¸ë¦¼ íŒ¨í„´ ë¶„ì„"""
        adhd_heatmaps = []
        normal_heatmaps = []
        
        for sample in adhd_samples:
            heatmap = self.generate_heatmap(sample, target_class=1)  # ADHD í´ë˜ìŠ¤
            adhd_heatmaps.append(heatmap)
        
        for sample in normal_samples:
            heatmap = self.generate_heatmap(sample, target_class=0)  # ì¼ë°˜ í´ë˜ìŠ¤
            normal_heatmaps.append(heatmap)
        
        # í‰ê·  ì–´í…ì…˜ ë§µ ê³„ì‚°
        avg_adhd_attention = np.mean(adhd_heatmaps, axis=0)
        avg_normal_attention = np.mean(normal_heatmaps, axis=0)
        
        return avg_adhd_attention, avg_normal_attention

# ì‚¬ìš© ì˜ˆì œ
def interpret_model_decisions():
    # ëª¨ë¸ ë¡œë“œ
    model = ADHD_Hybrid()
    model.load_state_dict(torch.load('best_model.pth'))
    model.eval()
    
    # Grad-CAM ì„¤ì • (CNN ë°±ë³¸ì˜ ë§ˆì§€ë§‰ ë ˆì´ì–´)
    target_layer = model.cnn[-1]
    grad_cam_analyzer = ADHDGradCAM(model, target_layer)
    
    # ìƒ˜í”Œ ë¶„ì„
    adhd_attention, normal_attention = grad_cam_analyzer.analyze_drawing_patterns(
        adhd_samples, normal_samples
    )
    
    print("ADHD ê·¸ë£¹ ì£¼ìš” ê´€ì‹¬ ì˜ì—­:", np.unravel_index(np.argmax(adhd_attention), adhd_attention.shape))
    print("ì¼ë°˜ ê·¸ë£¹ ì£¼ìš” ê´€ì‹¬ ì˜ì—­:", np.unravel_index(np.argmax(normal_attention), normal_attention.shape))
```

### 3.2 ê·¸ë¦¼ íŠ¹ì„±ë³„ ë¶„ì„

```python
# ê·¸ë¦¼ ìš”ì†Œë³„ ì¤‘ìš”ë„ ë¶„ì„
drawing_features = {
    "ì„ ì˜ íŠ¹ì„±": {
        "ë‘ê»˜": "ADHD ê·¸ë£¹ì—ì„œ ë” êµµì€ ì„  ê²½í–¥",
        "ì—°ì†ì„±": "ëŠì–´ì§„ ì„ ì´ ë” ë§ìŒ",
        "ì••ë ¥": "ë¶ˆê·œì¹™í•œ ì••ë ¥ ë¶„í¬"
    },
    "ê³µê°„ í™œìš©": {
        "ì—¬ë°±": "ë¶ˆê· ë“±í•œ ì—¬ë°± ë¶„í¬",
        "í¬ê¸°": "ê·¹ë‹¨ì ìœ¼ë¡œ í¬ê±°ë‚˜ ì‘ì€ ê·¸ë¦¼",
        "ìœ„ì¹˜": "ì¢…ì´ ì¤‘ì•™ì„ ë²—ì–´ë‚œ ìœ„ì¹˜"
    },
    "ì„¸ë¶€ì‚¬í•­": {
        "ì™„ì„±ë„": "ë¯¸ì™„ì„±ëœ ë¶€ë¶„ì´ ë§ìŒ",
        "ëŒ€ì¹­ì„±": "ë¹„ëŒ€ì¹­ì  êµ¬ì¡°",
        "ë¹„ë¡€": "ë¶€ìì—°ìŠ¤ëŸ¬ìš´ ë¹„ë¡€"
    },
    "ìƒ‰ìƒ ì‚¬ìš©": {
        "ìƒ‰ìƒ ìˆ˜": "ì œí•œì ì´ê±°ë‚˜ ê³¼ë„í•œ ìƒ‰ìƒ ì‚¬ìš©",
        "ì±„ìƒ‰": "ê²½ê³„ë¥¼ ë²—ì–´ë‚œ ì±„ìƒ‰",
        "ìƒ‰ìƒ ì¡°í•©": "ë¶€ì¡°í™”ë¡œìš´ ìƒ‰ìƒ ì¡°í•©"
    }
}
```

## ğŸ¯ 4. ìµœì¢… ëª¨ë¸ ì„ ì • ë° ìµœì í™”

### 4.1 ëª¨ë¸ ì„ ì • ê·¼ê±°

```python
# ì¢…í•© í‰ê°€ ë§¤íŠ¸ë¦­ìŠ¤
evaluation_matrix = {
    "ì„±ëŠ¥ (40%)": {
        "Hybrid CNN-Transformer": 0.874,  # ìµœê³  ì •í™•ë„
        "EfficientNet-B3": 0.863,
        "ViT-Base": 0.851,
        "ResNet-50": 0.847
    },
    "í•´ì„ê°€ëŠ¥ì„± (25%)": {
        "ResNet-50": 0.9,  # Grad-CAM ì ìš© ìš©ì´
        "Hybrid CNN-Transformer": 0.85,
        "EfficientNet-B3": 0.8,
        "ViT-Base": 0.75
    },
    "íš¨ìœ¨ì„± (20%)": {
        "EfficientNet-B3": 0.9,  # ê°€ì¥ íš¨ìœ¨ì 
        "ResNet-50": 0.85,
        "Hybrid CNN-Transformer": 0.7,
        "ViT-Base": 0.6
    },
    "ì•ˆì •ì„± (15%)": {
        "ResNet-50": 0.9,  # ê°€ì¥ ì•ˆì •ì 
        "EfficientNet-B3": 0.85,
        "Hybrid CNN-Transformer": 0.8,
        "ViT-Base": 0.75
    }
}

def calculate_weighted_score(model_name):
    weights = [0.4, 0.25, 0.2, 0.15]
    scores = []
    
    for i, (criterion, values) in enumerate(evaluation_matrix.items()):
        scores.append(values[model_name] * weights[i])
    
    return sum(scores)

# ìµœì¢… ì ìˆ˜ ê³„ì‚°
final_scores = {}
for model in ["Hybrid CNN-Transformer", "EfficientNet-B3", "ViT-Base", "ResNet-50"]:
    final_scores[model] = calculate_weighted_score(model)

print("ìµœì¢… ëª¨ë¸ ìˆœìœ„:")
for model, score in sorted(final_scores.items(), key=lambda x: x[1], reverse=True):
    print(f"{model}: {score:.3f}")
```

### 4.2 ì„ íƒëœ ëª¨ë¸: Hybrid CNN-Transformer

**ì„ ì • ì´ìœ :**
1. **ìµœê³  ì„±ëŠ¥**: 87.4% ì •í™•ë„, 92.3% AUC
2. **ê· í˜•ì¡íŒ íŠ¹ì„±**: ì§€ì—­ + ì „ì—­ íŠ¹ì„± ëª¨ë‘ í¬ì°©
3. **ì˜ë£Œ AI ì í•©ì„±**: ë†’ì€ ë¯¼ê°ë„ (82.1%)ì™€ íŠ¹ì´ë„ (88.8%)

### 4.3 ëª¨ë¸ ìµœì í™” ì „ëµ

```python
class OptimizedADHDModel(nn.Module):
    def __init__(self):
        super(OptimizedADHDModel, self).__init__()
        
        # ìµœì í™”ëœ í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜
        self.cnn_backbone = self._build_optimized_cnn()
        self.transformer_encoder = self._build_transformer()
        self.uncertainty_head = self._build_uncertainty_head()
        self.classifier = self._build_classifier()
        
    def _build_optimized_cnn(self):
        """ê²½ëŸ‰í™”ëœ CNN ë°±ë³¸"""
        backbone = models.efficientnet_b2(pretrained=True)
        return nn.Sequential(*list(backbone.features.children()))
    
    def _build_transformer(self):
        """íš¨ìœ¨ì ì¸ Transformer ì¸ì½”ë”"""
        return nn.TransformerEncoder(
            nn.TransformerEncoderLayer(
                d_model=1408,  # EfficientNet-B2 ì¶œë ¥ ì±„ë„
                nhead=8,
                dim_feedforward=1408,
                dropout=0.1,
                activation='gelu'
            ),
            num_layers=3  # ë ˆì´ì–´ ìˆ˜ ìµœì í™”
        )
    
    def _build_uncertainty_head(self):
        """ë¶ˆí™•ì‹¤ì„± ì •ëŸ‰í™”ë¥¼ ìœ„í•œ í—¤ë“œ"""
        return nn.Sequential(
            nn.Linear(1408, 256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, 1)  # ë¶ˆí™•ì‹¤ì„± ì ìˆ˜
        )
    
    def _build_classifier(self):
        """ë¶„ë¥˜ í—¤ë“œ"""
        return nn.Sequential(
            nn.Linear(1408, 512),
            nn.ReLU(),
            nn.Dropout(0.4),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(256, 2)
        )
    
    def forward(self, x):
        # CNN íŠ¹ì„± ì¶”ì¶œ
        cnn_features = self.cnn_backbone(x)
        B, C, H, W = cnn_features.shape
        
        # Transformer ì…ë ¥ ì¤€ë¹„
        features = cnn_features.flatten(2).transpose(1, 2)
        transformer_out = self.transformer_encoder(features.transpose(0, 1))
        
        # ì „ì—­ í‰ê·  í’€ë§
        pooled_features = transformer_out.mean(dim=0)
        
        # ë¶„ë¥˜ ë° ë¶ˆí™•ì‹¤ì„± ì˜ˆì¸¡
        classification = self.classifier(pooled_features)
        uncertainty = self.uncertainty_head(pooled_features)
        
        return classification, uncertainty
```

### 4.4 í•™ìŠµ ìµœì í™” ê¸°ë²•

```python
class ADHDTrainer:
    def __init__(self, model, train_loader, val_loader):
        self.model = model
        self.train_loader = train_loader
        self.val_loader = val_loader
        
        # ì†ì‹¤ í•¨ìˆ˜ (í´ë˜ìŠ¤ ë¶ˆê· í˜• ê³ ë ¤)
        self.classification_loss = nn.CrossEntropyLoss(
            weight=torch.tensor([1.0, 4.0])  # ADHD í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì¦ê°€
        )
        self.uncertainty_loss = nn.MSELoss()
        
        # ì˜µí‹°ë§ˆì´ì € (ì°¨ë³„ì  í•™ìŠµë¥ )
        self.optimizer = torch.optim.AdamW([
            {'params': self.model.cnn_backbone.parameters(), 'lr': 1e-5},
            {'params': self.model.transformer_encoder.parameters(), 'lr': 1e-4},
            {'params': self.model.classifier.parameters(), 'lr': 1e-3}
        ], weight_decay=1e-4)
        
        # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬
        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(
            self.optimizer, T_0=10, T_mult=2
        )
        
    def train_epoch(self):
        self.model.train()
        total_loss = 0
        
        for batch_idx, (data, targets) in enumerate(self.train_loader):
            self.optimizer.zero_grad()
            
            # ìˆœì „íŒŒ
            predictions, uncertainty = self.model(data)
            
            # ì†ì‹¤ ê³„ì‚°
            cls_loss = self.classification_loss(predictions, targets)
            
            # ë¶ˆí™•ì‹¤ì„± ì •ê·œí™” (ì˜ˆì¸¡ì´ í‹€ë ¸ì„ ë•Œ ë†’ì€ ë¶ˆí™•ì‹¤ì„± ìœ ë„)
            pred_probs = torch.softmax(predictions, dim=1)
            pred_confidence = torch.max(pred_probs, dim=1)[0]
            target_uncertainty = 1 - pred_confidence
            unc_loss = self.uncertainty_loss(uncertainty.squeeze(), target_uncertainty)
            
            total_loss = cls_loss + 0.1 * unc_loss
            
            # ì—­ì „íŒŒ
            total_loss.backward()
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            self.optimizer.step()
            
        self.scheduler.step()
        return total_loss / len(self.train_loader)
    
    def validate(self):
        self.model.eval()
        correct = 0
        total = 0
        
        with torch.no_grad():
            for data, targets in self.val_loader:
                predictions, uncertainty = self.model(data)
                _, predicted = torch.max(predictions.data, 1)
                total += targets.size(0)
                correct += (predicted == targets).sum().item()
        
        return correct / total
```

## ğŸ“ˆ 5. ì„±ëŠ¥ í–¥ìƒ ê¸°ë²•

### 5.1 ë°ì´í„° ì¦ê°• ì „ëµ

```python
from albumentations import (
    Compose, Rotate, RandomBrightnessContrast, 
    HueSaturationValue, RandomGamma, Blur
)

# ê·¸ë¦¼ íŠ¹ì„±ì„ ê³ ë ¤í•œ ë°ì´í„° ì¦ê°•
def get_augmentation_pipeline():
    return Compose([
        # íšŒì „ (ìì—°ìŠ¤ëŸ¬ìš´ ê·¸ë¦¼ ê°ë„ ë³€í™”)
        Rotate(limit=15, p=0.7),
        
        # ìƒ‰ìƒ ë³€í™” (ë‹¤ì–‘í•œ ê·¸ë¦¼ ë„êµ¬ ì‹œë®¬ë ˆì´ì…˜)
        RandomBrightnessContrast(
            brightness_limit=0.2, 
            contrast_limit=0.2, 
            p=0.6
        ),
        HueSaturationValue(
            hue_shift_limit=10,
            sat_shift_limit=20,
            val_shift_limit=10,
            p=0.5
        ),
        
        # ë…¸ì´ì¦ˆ ë° ë¸”ëŸ¬ (ìŠ¤ìº”/ì´¬ì˜ í’ˆì§ˆ ì‹œë®¬ë ˆì´ì…˜)
        RandomGamma(gamma_limit=(80, 120), p=0.3),
        Blur(blur_limit=2, p=0.3),
    ])

# ì ëŒ€ì  í•™ìŠµì„ í†µí•œ ê°•ê±´ì„± ì¦ëŒ€
class AdversarialTraining:
    def __init__(self, model, epsilon=0.01):
        self.model = model
        self.epsilon = epsilon
    
    def fgsm_attack(self, images, labels):
        """Fast Gradient Sign Method"""
        images.requires_grad = True
        
        outputs, _ = self.model(images)
        loss = F.cross_entropy(outputs, labels)
        
        self.model.zero_grad()
        loss.backward()
        
        # ì ëŒ€ì  ì˜ˆì œ ìƒì„±
        data_grad = images.grad.data
        perturbed_data = images + self.epsilon * data_grad.sign()
        perturbed_data = torch.clamp(perturbed_data, 0, 1)
        
        return perturbed_data
```

### 5.2 ì•™ìƒë¸” ê¸°ë²•

```python
class ADHDEnsemble:
    def __init__(self, models):
        self.models = models
        self.weights = self._calculate_weights()
    
    def _calculate_weights(self):
        """ê²€ì¦ ì„±ëŠ¥ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ê³„ì‚°"""
        weights = []
        for model in self.models:
            val_acc = self.evaluate_model(model)
            weights.append(val_acc)
        
        # ì •ê·œí™”
        total = sum(weights)
        return [w/total for w in weights]
    
    def predict(self, x):
        predictions = []
        uncertainties = []
        
        for model in self.models:
            with torch.no_grad():
                pred, unc = model(x)
                predictions.append(torch.softmax(pred, dim=1))
                uncertainties.append(unc)
        
        # ê°€ì¤‘ í‰ê· 
        weighted_pred = torch.zeros_like(predictions[0])
        weighted_unc = torch.zeros_like(uncertainties[0])
        
        for i, (pred, unc) in enumerate(zip(predictions, uncertainties)):
            weighted_pred += self.weights[i] * pred
            weighted_unc += self.weights[i] * unc
        
        return weighted_pred, weighted_unc
    
    def get_confidence_interval(self, x, confidence=0.95):
        """ì‹ ë¢°êµ¬ê°„ ê³„ì‚°"""
        predictions = []
        
        for model in self.models:
            with torch.no_grad():
                pred, _ = model(x)
                predictions.append(torch.softmax(pred, dim=1))
        
        # ë¶€íŠ¸ìŠ¤íŠ¸ë© ìƒ˜í”Œë§ìœ¼ë¡œ ì‹ ë¢°êµ¬ê°„ ê³„ì‚°
        stacked_preds = torch.stack(predictions)
        mean_pred = stacked_preds.mean(dim=0)
        std_pred = stacked_preds.std(dim=0)
        
        alpha = 1 - confidence
        z_score = 1.96  # 95% ì‹ ë¢°êµ¬ê°„
        
        lower_bound = mean_pred - z_score * std_pred
        upper_bound = mean_pred + z_score * std_pred
        
        return mean_pred, lower_bound, upper_bound
```

## ğŸ”¬ 6. ì„ìƒ ê²€ì¦ ë° ë°°í¬ ì „ëµ

### 6.1 ì„ìƒ ê²€ì¦ í”„ë¡œí† ì½œ

```python
class ClinicalValidation:
    def __init__(self, model, clinical_dataset):
        self.model = model
        self.clinical_dataset = clinical_dataset
        
    def calculate_clinical_metrics(self):
        """ì„ìƒì ìœ¼ë¡œ ì¤‘ìš”í•œ ì§€í‘œ ê³„ì‚°"""
        true_positives = 0
        false_positives = 0
        true_negatives = 0
        false_negatives = 0
        
        for sample in self.clinical_dataset:
            prediction = self.model.predict(sample['image'])
            actual = sample['clinical_diagnosis']
            
            if prediction == 1 and actual == 1:
                true_positives += 1
            elif prediction == 1 and actual == 0:
                false_positives += 1
            elif prediction == 0 and actual == 0:
                true_negatives += 1
            else:
                false_negatives += 1
        
        # ì„ìƒ ì§€í‘œ ê³„ì‚°
        sensitivity = true_positives / (true_positives + false_negatives)
        specificity = true_negatives / (true_negatives + false_positives)
        ppv = true_positives / (true_positives + false_positives)  # ì–‘ì„± ì˜ˆì¸¡ë„
        npv = true_negatives / (true_negatives + false_negatives)  # ìŒì„± ì˜ˆì¸¡ë„
        
        return {
            'sensitivity': sensitivity,
            'specificity': specificity,
            'positive_predictive_value': ppv,
            'negative_predictive_value': npv
        }
    
    def inter_rater_reliability(self, expert_annotations):
        """ì „ë¬¸ê°€ ê°„ ì¼ì¹˜ë„ ë¶„ì„"""
        from sklearn.metrics import cohen_kappa_score
        
        model_predictions = []
        expert_consensus = []
        
        for sample in self.clinical_dataset:
            model_pred = self.model.predict(sample['image'])
            expert_votes = expert_annotations[sample['id']]
            consensus = 1 if sum(expert_votes) >= len(expert_votes) // 2 else 0
            
            model_predictions.append(model_pred)
            expert_consensus.append(consensus)
        
        kappa = cohen_kappa_score(model_predictions, expert_consensus)
        return kappa
```

### 6.2 ë°°í¬ ì•„í‚¤í…ì²˜

```python
from flask import Flask, request, jsonify
import torch
import base64
from PIL import Image
import io

app = Flask(__name__)

class ADHDDiagnosisAPI:
    def __init__(self, model_path):
        self.model = self.load_model(model_path)
        self.preprocessing = self.get_preprocessing_pipeline()
        
    def load_model(self, model_path):
        model = OptimizedADHDModel()
        model.load_state_dict(torch.load(model_path, map_location='cpu'))
        model.eval()
        return model
    
    def get_preprocessing_pipeline(self):
        from torchvision import transforms
        return transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]
            )
        ])
    
    def predict(self, image_data):
        try:
            # Base64 ì´ë¯¸ì§€ ë””ì½”ë”©
            image_bytes = base64.b64decode(image_data)
            image = Image.open(io.BytesIO(image_bytes)).convert('RGB')
            
            # ì „ì²˜ë¦¬
            input_tensor = self.preprocessing(image).unsqueeze(0)
            
            # ì˜ˆì¸¡
            with torch.no_grad():
                prediction, uncertainty = self.model(input_tensor)
                probabilities = torch.softmax(prediction, dim=1)
                
                adhd_probability = probabilities[0][1].item()
                confidence = 1 - uncertainty[0].item()
                
            return {
                'adhd_probability': round(adhd_probability * 100, 2),
                'confidence': round(confidence * 100, 2),
                'recommendation': self.get_recommendation(adhd_probability, confidence)
            }
            
        except Exception as e:
            return {'error': str(e)}
    
    def get_recommendation(self, adhd_prob, confidence):
        """ì„ìƒì  ê¶Œê³ ì‚¬í•­ ìƒì„±"""
        if confidence < 0.7:
            return "ì‹ ë¢°ë„ê°€ ë‚®ìŠµë‹ˆë‹¤. ì¶”ê°€ í‰ê°€ê°€ í•„ìš”í•©ë‹ˆë‹¤."
        elif adhd_prob > 0.8:
            return "ADHD ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤. ì „ë¬¸ì˜ ìƒë‹´ì„ ê¶Œí•©ë‹ˆë‹¤."
        elif adhd_prob > 0.5:
            return "ADHD ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤. ì¶”ê°€ ê²€ì‚¬ë¥¼ ê³ ë ¤í•´ë³´ì„¸ìš”."
        else:
            return "ADHD ê°€ëŠ¥ì„±ì´ ë‚®ìŠµë‹ˆë‹¤."

# API ì—”ë“œí¬ì¸íŠ¸
diagnosis_api = ADHDDiagnosisAPI('models/best_adhd_model.pth')

@app.route('/predict', methods=['POST'])
def predict_adhd():
    try:
        data = request.json
        image_data = data['image']
        
        result = diagnosis_api.predict(image_data)
        return jsonify(result)
        
    except Exception as e:
        return jsonify({'error': str(e)}), 400

if __name__ == '__main__':
    app.run(debug=False, host='0.0.0.0', port=5000)
```

## ğŸ¯ ê²°ë¡  ë° í–¥í›„ ë°œì „ ë°©í–¥

### ìµœì¢… ëª¨ë¸ ì„ ì • ê²°ê³¼

**ì„ íƒëœ ëª¨ë¸**: Hybrid CNN-Transformer
- **ì„±ëŠ¥**: ì •í™•ë„ 87.4%, ë¯¼ê°ë„ 82.1%, íŠ¹ì´ë„ 88.8%
- **ì¥ì **: ì§€ì—­-ì „ì—­ íŠ¹ì„± ê· í˜•, ë†’ì€ í•´ì„ê°€ëŠ¥ì„±, ì„ìƒ ì ìš© ì í•©ì„±
- **ë°°í¬ í¬ê¸°**: 156MB (ëª¨ë°”ì¼ ì•± ì ìš© ê°€ëŠ¥)

### ì£¼ìš” í˜ì‹  í¬ì¸íŠ¸

1. **ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ íŠ¹ì„± ì¶”ì¶œ**: CNNê³¼ Transformerì˜ í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜
2. **ë¶ˆí™•ì‹¤ì„± ì •ëŸ‰í™”**: ì˜ˆì¸¡ ì‹ ë¢°ë„ ì œê³µìœ¼ë¡œ ì„ìƒ ì˜ì‚¬ê²°ì • ì§€ì›
3. **í•´ì„ê°€ëŠ¥ AI**: Grad-CAMê³¼ ì–´í…ì…˜ ì‹œê°í™”ë¡œ ì˜ë£Œì§„ ì´í•´ë„ ì¦ì§„
4. **ê°•ê±´í•œ í•™ìŠµ**: ì ëŒ€ì  í•™ìŠµê³¼ ì•™ìƒë¸”ë¡œ ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ

### í–¥í›„ ê°œì„  ë°©í–¥

```python
future_improvements = {
    "ë°ì´í„° í™•ì¥": {
        "ë‹¤êµ­ê°€ ë°ì´í„°": "ë¬¸í™”ì  ë‹¤ì–‘ì„± í™•ë³´",
        "ì¢…ë‹¨ ì—°êµ¬": "ë°œë‹¬ ê³¼ì • ì¶”ì  ë°ì´í„°",
        "ë©€í‹°ëª¨ë‹¬": "ê·¸ë¦¼ + í–‰ë™ ê´€ì°° ë°ì´í„°"
    },
    "ëª¨ë¸ ê³ ë„í™”": {
        "íŠ¸ëœìŠ¤í¬ë¨¸ ìµœì í™”": "íš¨ìœ¨ì ì¸ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜",
        "ì§€ì† í•™ìŠµ": "ìƒˆë¡œìš´ ë°ì´í„°ë¡œ ì§€ì†ì  ê°œì„ ",
        "ì—°í•© í•™ìŠµ": "ë³‘ì› ê°„ ë°ì´í„° ê³µìœ  ì—†ì´ í˜‘ë ¥ í•™ìŠµ"
    },
    "ì„ìƒ í†µí•©": {
        "EMR ì—°ë™": "ì „ìì˜ë¬´ê¸°ë¡ê³¼ í†µí•©",
        "ì‹¤ì‹œê°„ ë¶„ì„": "ê·¸ë¦¼ ê·¸ë¦¬ëŠ” ê³¼ì • ì‹¤ì‹œê°„ ë¶„ì„",
        "ê°œì¸í™”": "ê°œë³„ ì•„ë™ íŠ¹ì„± ê³ ë ¤í•œ ë§ì¶¤ ì§„ë‹¨"
    }
}
```

### ìœ¤ë¦¬ì  ê³ ë ¤ì‚¬í•­

1. **í¸í–¥ì„± ì œê±°**: ì„±ë³„, ì¸ì¢…, ì‚¬íšŒê²½ì œì  ë°°ê²½ì— ë”°ë¥¸ í¸í–¥ ìµœì†Œí™”
2. **í”„ë¼ì´ë²„ì‹œ ë³´í˜¸**: ë¯¼ê°í•œ ì˜ë£Œ ë°ì´í„° ë³´ì•ˆ ê°•í™”
3. **íˆ¬ëª…ì„±**: AI ì˜ì‚¬ê²°ì • ê³¼ì •ì˜ ì„¤ëª…ê°€ëŠ¥ì„± í™•ë³´
4. **ì „ë¬¸ê°€ í˜‘ë ¥**: ì˜ë£Œì§„ê³¼ì˜ ì§€ì†ì ì¸ í˜‘ì—…ê³¼ ê²€ì¦

ì´ í”„ë¡œì íŠ¸ëŠ” AI ê¸°ìˆ ì„ í†µí•´ ì•„ë™ì˜ ì¡°ê¸° ì§„ë‹¨ê³¼ ì¹˜ë£Œì— ê¸°ì—¬í•  ìˆ˜ ìˆëŠ” ì˜ë¯¸ìˆëŠ” ì‹œë„ì…ë‹ˆë‹¤. ì§€ì†ì ì¸ ì—°êµ¬ì™€ ê°œì„ ì„ í†µí•´ ë”ìš± ì •í™•í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì§„ë‹¨ ë„êµ¬ë¡œ ë°œì „ì‹œì¼œ ë‚˜ê°€ê² ìŠµë‹ˆë‹¤.

---

*ë³¸ ì—°êµ¬ëŠ” êµìœ¡ ë° ì—°êµ¬ ëª©ì ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìœ¼ë©°, ì‹¤ì œ ì˜ë£Œ ì§„ë‹¨ì€ ë°˜ë“œì‹œ ì „ë¬¸ì˜ì™€ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.*