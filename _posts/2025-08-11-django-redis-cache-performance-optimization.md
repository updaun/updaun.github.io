---
layout: post
title: "Django Redis ìºì‹œ ì™„ì „ ê°€ì´ë“œ: ì„±ëŠ¥ ìµœì í™”ì˜ í•µì‹¬"
date: 2025-08-11 10:00:00 +0900
categories: [Django, Redis, Cache, Performance]
tags: [Django, Redis, Cache, Performance, Optimization, Session, Cache Framework, Caching Strategy, Django-Redis, Memory]
---

Django ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì„±ëŠ¥ ë³‘ëª©ì„ í•´ê²°í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”? Redisë¥¼ í™œìš©í•œ ìºì‹œ ì‹œìŠ¤í…œì€ Django ì„±ëŠ¥ ìµœì í™”ì˜ í•µì‹¬ ìš”ì†Œì…ë‹ˆë‹¤. ì´ ê°€ì´ë“œì—ì„œëŠ” Djangoì—ì„œ Redis ìºì‹œë¥¼ êµ¬í˜„í•˜ëŠ” ë°©ë²•ë¶€í„° ê³ ê¸‰ ìµœì í™” ê¸°ë²•ê¹Œì§€ ì‹¤ì „ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ ìƒì„¸íˆ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.

## ğŸ“š Redis ìºì‹œì˜ ê¸°ë³¸ ì´í•´

### ì™œ Redisì¸ê°€?

Redis(Remote Dictionary Server)ëŠ” ë©”ëª¨ë¦¬ ê¸°ë°˜ í‚¤-ê°’ ì €ì¥ì†Œë¡œ, Django ìºì‹œ ë°±ì—”ë“œë¡œ ê°€ì¥ ì¸ê¸° ìˆëŠ” ì„ íƒì…ë‹ˆë‹¤:

**Redisì˜ ì¥ì :**
- ğŸš€ **ë¹ ë¥¸ ì„±ëŠ¥**: ë©”ëª¨ë¦¬ ê¸°ë°˜ìœ¼ë¡œ ë§ˆì´í¬ë¡œì´ˆ ë‹¨ìœ„ ì‘ë‹µ
- ğŸ”„ **ë‹¤ì–‘í•œ ë°ì´í„° êµ¬ì¡°**: String, Hash, List, Set, Sorted Set ì§€ì›
- ğŸ’¾ **ì˜ì†ì„±**: ë°ì´í„° ë°±ì—… ë° ë³µêµ¬ ê°€ëŠ¥
- ğŸ”€ **í™•ì¥ì„±**: í´ëŸ¬ìŠ¤í„°ë§ ë° ë ˆí”Œë¦¬ì¼€ì´ì…˜ ì§€ì›
- ğŸ¯ **ë§Œë£Œ ì‹œê°„**: TTL(Time To Live) ìë™ ê´€ë¦¬

### Django ìºì‹œ í”„ë ˆì„ì›Œí¬ ê°œìš”

DjangoëŠ” ì—¬ëŸ¬ ìºì‹œ ë ˆë²¨ì„ ì œê³µí•©ë‹ˆë‹¤:

```python
# ìºì‹œ ë ˆë²¨ë³„ ì ìš© ë²”ìœ„
1. ì‚¬ì´íŠ¸ ì „ì²´ ìºì‹œ    # ê°€ì¥ ìƒìœ„ ë ˆë²¨
2. ë·° ë ˆë²¨ ìºì‹œ        # íŠ¹ì • ë·° ê²°ê³¼ ìºì‹œ
3. í…œí”Œë¦¿ ì¡°ê° ìºì‹œ     # í…œí”Œë¦¿ ì¼ë¶€ ìºì‹œ
4. ì €ìˆ˜ì¤€ ìºì‹œ API     # ê°œë°œìê°€ ì§ì ‘ ì œì–´
```

## ğŸ› ï¸ Redis ì„¤ì¹˜ ë° Django ì„¤ì •

### Redis ì„œë²„ ì„¤ì¹˜

```bash
# macOS (Homebrew)
brew install redis
brew services start redis

# Ubuntu/Debian
sudo apt-get update
sudo apt-get install redis-server
sudo systemctl start redis-server

# CentOS/RHEL
sudo yum install redis
sudo systemctl start redis

# Docker ì‚¬ìš©
docker run -d --name redis-server -p 6379:6379 redis:alpine
```

### Django-Redis ì„¤ì¹˜ ë° ì„¤ì •

```bash
# Django-Redis íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install django-redis
```

```python
# settings.py
CACHES = {
    'default': {
        'BACKEND': 'django_redis.cache.RedisCache',
        'LOCATION': 'redis://127.0.0.1:6379/1',  # ë°ì´í„°ë² ì´ìŠ¤ 1 ì‚¬ìš©
        'OPTIONS': {
            'CLIENT_CLASS': 'django_redis.client.DefaultClient',
            'CONNECTION_POOL_KWARGS': {
                'max_connections': 20,
                'retry_on_timeout': True,
            },
            'SERIALIZER': 'django_redis.serializers.json.JSONSerializer',
            'COMPRESSOR': 'django_redis.compressors.zlib.ZlibCompressor',
        },
        'KEY_PREFIX': 'myproject',  # í‚¤ ì¶©ëŒ ë°©ì§€
        'VERSION': 1,
        'TIMEOUT': 300,  # 5ë¶„ ê¸°ë³¸ ë§Œë£Œ ì‹œê°„
    }
}

# ìºì‹œ í‚¤ ìƒì„± í•¨ìˆ˜ ì„¤ì •
def make_key(key, key_prefix, version):
    """ìºì‹œ í‚¤ ìƒì„± ë¡œì§ ì»¤ìŠ¤í„°ë§ˆì´ì§•"""
    return f"{key_prefix}:{version}:{key}"

CACHES['default']['KEY_FUNCTION'] = 'myproject.utils.cache.make_key'
```

### í™˜ê²½ë³„ Redis ì„¤ì •

```python
# settings/base.py
import os

REDIS_URL = os.environ.get('REDIS_URL', 'redis://127.0.0.1:6379/1')

CACHES = {
    'default': {
        'BACKEND': 'django_redis.cache.RedisCache',
        'LOCATION': REDIS_URL,
        'OPTIONS': {
            'CLIENT_CLASS': 'django_redis.client.DefaultClient',
        },
    }
}

# settings/development.py
CACHES['default']['OPTIONS'].update({
    'CONNECTION_POOL_KWARGS': {
        'max_connections': 5,
    }
})

# settings/production.py
CACHES['default']['OPTIONS'].update({
    'CONNECTION_POOL_KWARGS': {
        'max_connections': 50,
        'retry_on_timeout': True,
        'retry_on_error': [ConnectionError, TimeoutError],
    },
    'SERIALIZER': 'django_redis.serializers.msgpack.MSGPackSerializer',  # ë” ë¹ ë¥¸ ì§ë ¬í™”
    'COMPRESSOR': 'django_redis.compressors.zlib.ZlibCompressor',
})
```

## ğŸ¯ Django ìºì‹œ êµ¬í˜„ ì „ëµ

### 1. ì‚¬ì´íŠ¸ ì „ì²´ ìºì‹œ

ê°€ì¥ ê°„ë‹¨í•˜ê³  íš¨ê³¼ì ì¸ ìºì‹œ ë°©ë²•ì…ë‹ˆë‹¤:

```python
# settings.py
MIDDLEWARE = [
    'django.middleware.cache.UpdateCacheMiddleware',  # ë§¨ ìœ„
    'django.middleware.common.CommonMiddleware',
    # ... ë‹¤ë¥¸ ë¯¸ë“¤ì›¨ì–´ë“¤
    'django.middleware.cache.FetchFromCacheMiddleware',  # ë§¨ ì•„ë˜
]

# ì‚¬ì´íŠ¸ ì „ì²´ ìºì‹œ ì„¤ì •
CACHE_MIDDLEWARE_ALIAS = 'default'
CACHE_MIDDLEWARE_SECONDS = 600  # 10ë¶„
CACHE_MIDDLEWARE_KEY_PREFIX = 'site'
```

**ì£¼ì˜ì‚¬í•­:**
- ì‚¬ìš©ìë³„ ê°œì¸í™” ì½˜í…ì¸ ê°€ ìˆìœ¼ë©´ ì‚¬ìš© ë¶ˆê°€
- ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ê°€ í•„ìš”í•œ ì‚¬ì´íŠ¸ì—ëŠ” ë¶€ì í•©

### 2. ë·° ë ˆë²¨ ìºì‹œ

íŠ¹ì • ë·°ì˜ ê²°ê³¼ë¥¼ ìºì‹œí•©ë‹ˆë‹¤:

```python
from django.views.decorators.cache import cache_page
from django.utils.decorators import method_decorator
from django.views.generic import ListView

# í•¨ìˆ˜ ê¸°ë°˜ ë·°
@cache_page(60 * 15)  # 15ë¶„ ìºì‹œ
def product_list(request):
    products = Product.objects.select_related('category').all()
    return render(request, 'products/list.html', {'products': products})

# í´ë˜ìŠ¤ ê¸°ë°˜ ë·°
@method_decorator(cache_page(60 * 15), name='dispatch')
class ProductListView(ListView):
    model = Product
    template_name = 'products/list.html'
    context_object_name = 'products'
    
    def get_queryset(self):
        return Product.objects.select_related('category').filter(active=True)

# ì¡°ê±´ë¶€ ìºì‹œ
from django.views.decorators.vary import vary_on_headers

@cache_page(60 * 15)
@vary_on_headers('User-Agent', 'Accept-Language')
def localized_view(request):
    # ì‚¬ìš©ì ì—ì´ì „íŠ¸ì™€ ì–¸ì–´ë³„ë¡œ ë‹¤ë¥¸ ìºì‹œ
    return render(request, 'localized.html')
```

### 3. í…œí”Œë¦¿ ì¡°ê° ìºì‹œ

í…œí”Œë¦¿ì˜ íŠ¹ì • ë¶€ë¶„ë§Œ ìºì‹œí•©ë‹ˆë‹¤:

```html
<!-- products/list.html -->
```html
<!-- products/list.html -->
{%raw%}{% load cache %}{%endraw%}

<!-- ë¹„ì‹¼ ê³„ì‚° ê²°ê³¼ ìºì‹œ -->
{%raw%}{% cache 300 expensive_calculation request.user.id %}{%endraw%}
    <div class="statistics">
        {%raw%}{% for stat in expensive_stats %}{%endraw%}
            <div class="stat-item">{%raw%}{{ stat.name }}: {{ stat.value }}{%endraw%}</div>
        {%raw%}{% endfor %}{%endraw%}
    </div>
{%raw%}{% endcache %}{%endraw%}

<!-- ì¹´í…Œê³ ë¦¬ë³„ ìºì‹œ -->
{%raw%}{% for category in categories %}{%endraw%}
    {%raw%}{% cache 600 category_products category.id %}{%endraw%}
        <div class="category-section">
            <h3>{%raw%}{{ category.name }}{%endraw%}</h3>
            {%raw%}{% for product in category.products.all %}{%endraw%}
                <div class="product-item">{%raw%}{{ product.name }}{%endraw%}</div>
            {%raw%}{% endfor %}{%endraw%}
        </div>
    {%raw%}{% endcache %}{%endraw%}
{%raw%}{% endfor %}{%endraw%}

<!-- ì¡°ê±´ë¶€ í…œí”Œë¦¿ ìºì‹œ -->
{%raw%}{% cache 300 user_specific_content request.user.id only if not user.is_staff %}{%endraw%}
    <!-- ì¼ë°˜ ì‚¬ìš©ìì—ê²Œë§Œ ìºì‹œ ì ìš© -->
    <div class="user-dashboard">
        <!-- ë³µì¡í•œ ì‚¬ìš©ì ëŒ€ì‹œë³´ë“œ -->
    </div>
{%raw%}{% endcache %}{%endraw%}
```

### 4. ì €ìˆ˜ì¤€ ìºì‹œ API

ê°€ì¥ ì„¸ë°€í•œ ì œì–´ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤:

```python
from django.core.cache import cache
from django.core.cache.utils import make_template_fragment_key
import hashlib
import json

class ProductService:
    @staticmethod
    def get_product_stats(product_id):
        """ì œí’ˆ í†µê³„ ìºì‹œ"""
        cache_key = f'product_stats:{product_id}'
        stats = cache.get(cache_key)
        
        if stats is None:
            # ë³µì¡í•œ í†µê³„ ê³„ì‚°
            stats = {
                'total_sales': Product.objects.get(id=product_id).calculate_total_sales(),
                'avg_rating': Product.objects.get(id=product_id).calculate_avg_rating(),
                'view_count': Product.objects.get(id=product_id).get_view_count(),
            }
            cache.set(cache_key, stats, timeout=3600)  # 1ì‹œê°„ ìºì‹œ
        
        return stats
    
    @staticmethod
    def get_related_products(product_id, limit=5):
        """ê´€ë ¨ ìƒí’ˆ ìºì‹œ"""
        cache_key = f'related_products:{product_id}:{limit}'
        products = cache.get(cache_key)
        
        if products is None:
            # ë³µì¡í•œ ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜
            products = Product.objects.filter(
                category__products__id=product_id
            ).exclude(id=product_id)[:limit]
            
            # QuerySetì„ ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
            products_data = [
                {
                    'id': p.id,
                    'name': p.name,
                    'price': str(p.price),
                    'image_url': p.image.url if p.image else None,
                }
                for p in products
            ]
            cache.set(cache_key, products_data, timeout=1800)  # 30ë¶„ ìºì‹œ
            products = products_data
        
        return products

# ìºì‹œ í‚¤ ìƒì„± í—¬í¼
def generate_cache_key(*args, **kwargs):
    """ì¼ê´€ëœ ìºì‹œ í‚¤ ìƒì„±"""
    key_parts = [str(arg) for arg in args]
    key_parts.extend([f"{k}:{v}" for k, v in sorted(kwargs.items())])
    key_string = ":".join(key_parts)
    return hashlib.md5(key_string.encode()).hexdigest()

# ì‚¬ìš© ì˜ˆì‹œ
def get_user_recommendations(user_id, category=None, limit=10):
    cache_key = generate_cache_key(
        'user_recommendations',
        user_id=user_id,
        category=category,
        limit=limit
    )
    
    recommendations = cache.get(cache_key)
    if recommendations is None:
        # ë³µì¡í•œ ì¶”ì²œ ë¡œì§
        recommendations = calculate_recommendations(user_id, category, limit)
        cache.set(cache_key, recommendations, timeout=7200)  # 2ì‹œê°„
    
    return recommendations
```

## ğŸ”„ ìºì‹œ ë¬´íš¨í™” ì „ëµ

### ì‹ í˜¸ ê¸°ë°˜ ìë™ ë¬´íš¨í™”

```python
from django.db.models.signals import post_save, post_delete
from django.dispatch import receiver
from django.core.cache import cache
from django.core.cache.utils import make_template_fragment_key

@receiver(post_save, sender=Product)
def invalidate_product_cache(sender, instance, **kwargs):
    """ìƒí’ˆ ì €ì¥ì‹œ ê´€ë ¨ ìºì‹œ ë¬´íš¨í™”"""
    # ìƒí’ˆë³„ ìºì‹œ ì‚­ì œ
    cache.delete(f'product_stats:{instance.id}')
    cache.delete(f'product_detail:{instance.id}')
    
    # ì¹´í…Œê³ ë¦¬ ê´€ë ¨ ìºì‹œ ì‚­ì œ
    cache.delete(f'category_products:{instance.category_id}')
    
    # í…œí”Œë¦¿ ì¡°ê° ìºì‹œ ì‚­ì œ
    fragment_key = make_template_fragment_key(
        'product_detail', 
        [instance.id]
    )
    cache.delete(fragment_key)
    
    # ê´€ë ¨ ìƒí’ˆ ìºì‹œ ì‚­ì œ (íŒ¨í„´ ë§¤ì¹­)
    cache.delete_pattern(f'related_products:*')

@receiver(post_delete, sender=Product)
def invalidate_product_cache_on_delete(sender, instance, **kwargs):
    """ìƒí’ˆ ì‚­ì œì‹œ ìºì‹œ ì •ë¦¬"""
    # ëª¨ë“  ê´€ë ¨ ìºì‹œ ì‚­ì œ
    invalidate_product_cache(sender, instance, **kwargs)
    
    # ì¶”ê°€ì ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ ê°œìˆ˜ ìºì‹œë„ ë¬´íš¨í™”
    cache.delete(f'category_count:{instance.category_id}')
```

### ë²„ì „ ê¸°ë°˜ ìºì‹œ ê´€ë¦¬

```python
from django.core.cache import cache
from django.conf import settings

class VersionedCache:
    """ë²„ì „ ê´€ë¦¬ê°€ ê°€ëŠ¥í•œ ìºì‹œ ë˜í¼"""
    
    def __init__(self, namespace):
        self.namespace = namespace
    
    def _get_version_key(self):
        return f'{self.namespace}:version'
    
    def _get_versioned_key(self, key):
        version = cache.get(self._get_version_key(), 1)
        return f'{self.namespace}:{version}:{key}'
    
    def get(self, key, default=None):
        versioned_key = self._get_versioned_key(key)
        return cache.get(versioned_key, default)
    
    def set(self, key, value, timeout=None):
        versioned_key = self._get_versioned_key(key)
        cache.set(versioned_key, value, timeout)
    
    def invalidate_all(self):
        """ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì˜ ëª¨ë“  ìºì‹œ ë¬´íš¨í™”"""
        version_key = self._get_version_key()
        current_version = cache.get(version_key, 1)
        cache.set(version_key, current_version + 1)

# ì‚¬ìš© ì˜ˆì‹œ
product_cache = VersionedCache('products')

def get_product_list():
    products = product_cache.get('list')
    if products is None:
        products = Product.objects.all().values('id', 'name', 'price')
        product_cache.set('list', list(products), timeout=3600)
    return products

# ëª¨ë“  ìƒí’ˆ ìºì‹œ ë¬´íš¨í™”
def invalidate_all_product_caches():
    product_cache.invalidate_all()
```

### íƒœê·¸ ê¸°ë°˜ ìºì‹œ ë¬´íš¨í™”

```python
from django.core.cache import cache
from django.core.cache.backends.base import DEFAULT_TIMEOUT

class TaggedCache:
    """íƒœê·¸ ê¸°ë°˜ ìºì‹œ ê´€ë¦¬"""
    
    @staticmethod
    def set_with_tags(key, value, tags, timeout=DEFAULT_TIMEOUT):
        """íƒœê·¸ì™€ í•¨ê»˜ ìºì‹œ ì„¤ì •"""
        cache.set(key, value, timeout)
        
        # ê° íƒœê·¸ì— ëŒ€í•´ í‚¤ ëª©ë¡ ê´€ë¦¬
        for tag in tags:
            tag_key = f'tag:{tag}'
            tagged_keys = cache.get(tag_key, set())
            tagged_keys.add(key)
            cache.set(tag_key, tagged_keys, timeout=None)  # íƒœê·¸ëŠ” ì˜êµ¬ ë³´ì¡´
    
    @staticmethod
    def invalidate_tag(tag):
        """íŠ¹ì • íƒœê·¸ì˜ ëª¨ë“  ìºì‹œ ë¬´íš¨í™”"""
        tag_key = f'tag:{tag}'
        tagged_keys = cache.get(tag_key, set())
        
        if tagged_keys:
            # íƒœê·¸ëœ ëª¨ë“  í‚¤ ì‚­ì œ
            cache.delete_many(list(tagged_keys))
            # íƒœê·¸ ìì²´ë„ ì‚­ì œ
            cache.delete(tag_key)

# ì‚¬ìš© ì˜ˆì‹œ
def cache_product_with_tags(product):
    cache_key = f'product:{product.id}'
    tags = [
        f'category:{product.category_id}',
        f'brand:{product.brand_id}',
        'products'
    ]
    
    TaggedCache.set_with_tags(
        cache_key, 
        product.to_dict(), 
        tags, 
        timeout=3600
    )

# ì¹´í…Œê³ ë¦¬ ë³€ê²½ì‹œ ê´€ë ¨ ìƒí’ˆ ìºì‹œ ëª¨ë‘ ë¬´íš¨í™”
def invalidate_category_caches(category_id):
    TaggedCache.invalidate_tag(f'category:{category_id}')
```

## ğŸ—„ï¸ ì„¸ì…˜ ì €ì¥ì†Œë¡œ Redis í™œìš©

### Redis ì„¸ì…˜ ë°±ì—”ë“œ ì„¤ì •

```python
# settings.py
SESSION_ENGINE = 'django.contrib.sessions.backends.cache'
SESSION_CACHE_ALIAS = 'default'
SESSION_COOKIE_AGE = 1209600  # 2ì£¼
SESSION_SAVE_EVERY_REQUEST = False  # ì„±ëŠ¥ ìµœì í™”
SESSION_EXPIRE_AT_BROWSER_CLOSE = False

# ë³´ì•ˆ ì„¤ì •
SESSION_COOKIE_SECURE = True  # HTTPSì—ì„œë§Œ ì „ì†¡
SESSION_COOKIE_HTTPONLY = True  # XSS ë°©ì§€
SESSION_COOKIE_SAMESITE = 'Lax'  # CSRF ë°©ì§€
```

### ì»¤ìŠ¤í…€ ì„¸ì…˜ ê´€ë¦¬

```python
from django.contrib.sessions.models import Session
from django.contrib.auth import get_user_model
from django.core.cache import cache
import json

User = get_user_model()

class SessionManager:
    @staticmethod
    def get_active_users():
        """í˜„ì¬ í™œì„± ì‚¬ìš©ì ëª©ë¡ ìºì‹œ"""
        cache_key = 'active_users'
        active_users = cache.get(cache_key)
        
        if active_users is None:
            # Redisì—ì„œ ì„¸ì…˜ ë°ì´í„° ì¡°íšŒ
            from django_redis import get_redis_connection
            redis_conn = get_redis_connection("default")
            
            # ì„¸ì…˜ í‚¤ íŒ¨í„´ìœ¼ë¡œ í™œì„± ì„¸ì…˜ ì°¾ê¸°
            session_keys = redis_conn.keys(':1:django.contrib.sessions.cache*')
            
            user_ids = set()
            for session_key in session_keys:
                try:
                    session_data = redis_conn.get(session_key)
                    if session_data:
                        session_dict = json.loads(session_data)
                        user_id = session_dict.get('_auth_user_id')
                        if user_id:
                            user_ids.add(int(user_id))
                except (json.JSONDecodeError, ValueError):
                    continue
            
            active_users = list(User.objects.filter(id__in=user_ids))
            cache.set(cache_key, active_users, timeout=300)  # 5ë¶„ ìºì‹œ
        
        return active_users
    
    @staticmethod
    def force_logout_user(user_id):
        """íŠ¹ì • ì‚¬ìš©ìì˜ ëª¨ë“  ì„¸ì…˜ ê°•ì œ ì¢…ë£Œ"""
        from django_redis import get_redis_connection
        redis_conn = get_redis_connection("default")
        
        # í•´ë‹¹ ì‚¬ìš©ìì˜ ëª¨ë“  ì„¸ì…˜ ì°¾ì•„ì„œ ì‚­ì œ
        session_keys = redis_conn.keys(':1:django.contrib.sessions.cache*')
        for session_key in session_keys:
            try:
                session_data = redis_conn.get(session_key)
                if session_data:
                    session_dict = json.loads(session_data)
                    if session_dict.get('_auth_user_id') == str(user_id):
                        redis_conn.delete(session_key)
            except (json.JSONDecodeError, ValueError):
                continue
        
        # í™œì„± ì‚¬ìš©ì ìºì‹œ ë¬´íš¨í™”
        cache.delete('active_users')
```

## ğŸ“Š ìºì‹œ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

### ìºì‹œ íˆíŠ¸ìœ¨ ì¸¡ì •

```python
from django.core.cache import cache
from django.utils.decorators import method_decorator
from django.views.decorators.cache import never_cache
import time
import logging

logger = logging.getLogger(__name__)

class CacheMonitoringMixin:
    """ìºì‹œ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë¯¹ìŠ¤ì¸"""
    
    def get_with_stats(self, cache_key, callback, timeout=300):
        """ìºì‹œ íˆíŠ¸ìœ¨ í†µê³„ì™€ í•¨ê»˜ ë°ì´í„° ì¡°íšŒ"""
        start_time = time.time()
        
        # ìºì‹œì—ì„œ ì¡°íšŒ ì‹œë„
        data = cache.get(cache_key)
        cache_hit = data is not None
        
        if not cache_hit:
            # ìºì‹œ ë¯¸ìŠ¤ - ì½œë°±ìœ¼ë¡œ ë°ì´í„° ìƒì„±
            data = callback()
            cache.set(cache_key, data, timeout)
        
        # í†µê³„ ê¸°ë¡
        execution_time = time.time() - start_time
        self._record_cache_stats(cache_key, cache_hit, execution_time)
        
        return data
    
    def _record_cache_stats(self, cache_key, cache_hit, execution_time):
        """ìºì‹œ í†µê³„ ê¸°ë¡"""
        stats_key = f'cache_stats:{cache_key}'
        stats = cache.get(stats_key, {
            'hits': 0,
            'misses': 0,
            'total_time': 0,
            'count': 0
        })
        
        if cache_hit:
            stats['hits'] += 1
        else:
            stats['misses'] += 1
        
        stats['total_time'] += execution_time
        stats['count'] += 1
        stats['hit_ratio'] = stats['hits'] / stats['count']
        stats['avg_time'] = stats['total_time'] / stats['count']
        
        # í†µê³„ëŠ” 24ì‹œê°„ ë³´ì¡´
        cache.set(stats_key, stats, timeout=86400)
        
        # íˆíŠ¸ìœ¨ì´ ë‚®ìœ¼ë©´ ë¡œê¹…
        if stats['count'] > 10 and stats['hit_ratio'] < 0.5:
            logger.warning(
                f"Low cache hit ratio for {cache_key}: {stats['hit_ratio']:.2%}"
            )

class ProductService(CacheMonitoringMixin):
    def get_popular_products(self, limit=10):
        def fetch_popular_products():
            return Product.objects.filter(
                is_active=True
            ).order_by('-view_count')[:limit]
        
        return self.get_with_stats(
            f'popular_products:{limit}',
            fetch_popular_products,
            timeout=3600
        )
```

### ìºì‹œ ìƒíƒœ ëŒ€ì‹œë³´ë“œ

```python
from django.http import JsonResponse
from django.views.generic import View
from django_redis import get_redis_connection
import json

class CacheStatsView(View):
    """ìºì‹œ ìƒíƒœ ëª¨ë‹ˆí„°ë§ API"""
    
    def get(self, request):
        redis_conn = get_redis_connection("default")
        
        # Redis ì„œë²„ ì •ë³´
        redis_info = redis_conn.info()
        
        # ìºì‹œ í†µê³„ ìˆ˜ì§‘
        cache_stats = {}
        stats_keys = cache.keys('cache_stats:*')
        
        for stats_key in stats_keys:
            stats_data = cache.get(stats_key)
            if stats_data:
                cache_name = stats_key.replace('cache_stats:', '')
                cache_stats[cache_name] = stats_data
        
        # ì „ì²´ í†µê³„ ê³„ì‚°
        total_hits = sum(stats['hits'] for stats in cache_stats.values())
        total_misses = sum(stats['misses'] for stats in cache_stats.values())
        total_requests = total_hits + total_misses
        overall_hit_ratio = total_hits / total_requests if total_requests > 0 else 0
        
        return JsonResponse({
            'redis_info': {
                'used_memory': redis_info['used_memory_human'],
                'connected_clients': redis_info['connected_clients'],
                'total_commands_processed': redis_info['total_commands_processed'],
                'keyspace_hits': redis_info.get('keyspace_hits', 0),
                'keyspace_misses': redis_info.get('keyspace_misses', 0),
            },
            'cache_stats': cache_stats,
            'overall_stats': {
                'total_hits': total_hits,
                'total_misses': total_misses,
                'hit_ratio': overall_hit_ratio,
                'total_requests': total_requests,
            }
        })

# ìºì‹œ ìƒíƒœ ëª…ë ¹í–‰ ë„êµ¬
from django.core.management.base import BaseCommand

class Command(BaseCommand):
    help = 'Display cache statistics'
    
    def handle(self, *args, **options):
        redis_conn = get_redis_connection("default")
        info = redis_conn.info()
        
        self.stdout.write(
            self.style.SUCCESS('=== Redis Cache Statistics ===')
        )
        self.stdout.write(f"Used Memory: {info['used_memory_human']}")
        self.stdout.write(f"Connected Clients: {info['connected_clients']}")
        self.stdout.write(f"Total Commands: {info['total_commands_processed']}")
        
        # í‚¤ ê°œìˆ˜ í‘œì‹œ
        total_keys = 0
        for db_info in info.get('db0', {}).values():
            if isinstance(db_info, dict) and 'keys' in db_info:
                total_keys += db_info['keys']
        
        self.stdout.write(f"Total Keys: {total_keys}")
        
        # íˆíŠ¸ìœ¨ í‘œì‹œ
        hits = info.get('keyspace_hits', 0)
        misses = info.get('keyspace_misses', 0)
        if hits + misses > 0:
            hit_ratio = hits / (hits + misses)
            self.stdout.write(f"Hit Ratio: {hit_ratio:.2%}")
```

## âš¡ ê³ ê¸‰ ìµœì í™” ê¸°ë²•

### ìºì‹œ ì›Œë°ì—… ì „ëµ

```python
from django.core.management.base import BaseCommand
from django.core.cache import cache
from concurrent.futures import ThreadPoolExecutor
import time

class CacheWarmer:
    """ìºì‹œ ì‚¬ì „ ë¡œë”© í´ë˜ìŠ¤"""
    
    def __init__(self, max_workers=5):
        self.max_workers = max_workers
    
    def warm_product_caches(self):
        """ìƒí’ˆ ê´€ë ¨ ìºì‹œ ì‚¬ì „ ë¡œë”©"""
        
        def warm_category_cache(category_id):
            """ì¹´í…Œê³ ë¦¬ë³„ ìƒí’ˆ ìºì‹œ"""
            cache_key = f'category_products:{category_id}'
            if not cache.get(cache_key):
                products = Product.objects.filter(
                    category_id=category_id, 
                    is_active=True
                ).select_related('category')[:20]
                
                cache.set(cache_key, list(products.values()), timeout=3600)
                return f"Warmed cache for category {category_id}"
        
        # ëª¨ë“  í™œì„± ì¹´í…Œê³ ë¦¬ ID ì¡°íšŒ
        category_ids = Category.objects.filter(
            is_active=True
        ).values_list('id', flat=True)
        
        # ë³‘ë ¬ë¡œ ìºì‹œ ì›Œë°ì—…
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = [
                executor.submit(warm_category_cache, cat_id) 
                for cat_id in category_ids
            ]
            
            for future in futures:
                try:
                    result = future.result(timeout=30)
                    print(result)
                except Exception as e:
                    print(f"Cache warming failed: {e}")
    
    def warm_user_caches(self):
        """ì‚¬ìš©ì ê´€ë ¨ ìºì‹œ ì‚¬ì „ ë¡œë”©"""
        
        def warm_user_recommendations(user_id):
            cache_key = f'user_recommendations:{user_id}'
            if not cache.get(cache_key):
                # ì‚¬ìš©ì ì¶”ì²œ ê³„ì‚° (ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ëŠ” ì‘ì—…)
                recommendations = calculate_user_recommendations(user_id)
                cache.set(cache_key, recommendations, timeout=7200)
        
        # ìµœê·¼ í™œì„± ì‚¬ìš©ìë“¤ì— ëŒ€í•´ ìºì‹œ ì›Œë°ì—…
        recent_users = User.objects.filter(
            last_login__gte=timezone.now() - timedelta(days=7)
        ).values_list('id', flat=True)[:100]  # ìµœê·¼ 100ëª…ë§Œ
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            for user_id in recent_users:
                executor.submit(warm_user_recommendations, user_id)

# ê´€ë¦¬ ëª…ë ¹ì–´
class Command(BaseCommand):
    help = 'Warm up caches with frequently accessed data'
    
    def add_arguments(self, parser):
        parser.add_argument(
            '--type',
            choices=['products', 'users', 'all'],
            default='all',
            help='Type of cache to warm up'
        )
    
    def handle(self, *args, **options):
        warmer = CacheWarmer()
        
        start_time = time.time()
        
        if options['type'] in ['products', 'all']:
            self.stdout.write('Warming product caches...')
            warmer.warm_product_caches()
        
        if options['type'] in ['users', 'all']:
            self.stdout.write('Warming user caches...')
            warmer.warm_user_caches()
        
        elapsed = time.time() - start_time
        self.stdout.write(
            self.style.SUCCESS(
                f'Cache warming completed in {elapsed:.2f} seconds'
            )
        )
```

### ë¶„ì‚° ìºì‹œ ë½ êµ¬í˜„

```python
import time
import uuid
from django_redis import get_redis_connection

class DistributedLock:
    """Redisë¥¼ ì´ìš©í•œ ë¶„ì‚° ë½"""
    
    def __init__(self, lock_name, timeout=10, retry_delay=0.1):
        self.lock_name = f'lock:{lock_name}'
        self.timeout = timeout
        self.retry_delay = retry_delay
        self.redis_conn = get_redis_connection('default')
        self.lock_value = str(uuid.uuid4())
    
    def acquire(self):
        """ë½ íšë“"""
        end_time = time.time() + self.timeout
        
        while time.time() < end_time:
            # SET ëª…ë ¹ì–´ë¡œ ë½ ì„¤ì • (NX: keyê°€ ì—†ì„ ë•Œë§Œ, EX: ë§Œë£Œ ì‹œê°„)
            if self.redis_conn.set(
                self.lock_name, 
                self.lock_value, 
                nx=True, 
                ex=self.timeout
            ):
                return True
            
            time.sleep(self.retry_delay)
        
        return False
    
    def release(self):
        """ë½ í•´ì œ"""
        # Lua ìŠ¤í¬ë¦½íŠ¸ë¡œ ì›ìì  í•´ì œ (ìì‹ ì´ ì„¤ì •í•œ ë½ë§Œ í•´ì œ)
        lua_script = """
        if redis.call("GET", KEYS[1]) == ARGV[1] then
            return redis.call("DEL", KEYS[1])
        else
            return 0
        end
        """
        return self.redis_conn.eval(lua_script, 1, self.lock_name, self.lock_value)
    
    def __enter__(self):
        if not self.acquire():
            raise Exception(f"Failed to acquire lock: {self.lock_name}")
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.release()

# ì‚¬ìš© ì˜ˆì‹œ: ì¤‘ë³µ ê³„ì‚° ë°©ì§€
def get_expensive_calculation(param):
    cache_key = f'expensive_calc:{param}'
    result = cache.get(cache_key)
    
    if result is None:
        # ë¶„ì‚° ë½ìœ¼ë¡œ ì¤‘ë³µ ê³„ì‚° ë°©ì§€
        with DistributedLock(f'calc_lock:{param}', timeout=30):
            # ë½ íšë“ í›„ ë‹¤ì‹œ í•œ ë²ˆ ìºì‹œ í™•ì¸
            result = cache.get(cache_key)
            if result is None:
                # ì‹¤ì œ ê³„ì‚° ìˆ˜í–‰
                result = perform_expensive_calculation(param)
                cache.set(cache_key, result, timeout=3600)
    
    return result
```

### ìºì‹œ ì••ì¶• ë° ì§ë ¬í™” ìµœì í™”

```python
import pickle
import zlib
import json
from django.core.cache.backends.base import BaseCache

class OptimizedRedisCache:
    """ìµœì í™”ëœ Redis ìºì‹œ ë˜í¼"""
    
    def __init__(self):
        self.redis_conn = get_redis_connection('default')
    
    def _serialize_and_compress(self, data):
        """ë°ì´í„° ì§ë ¬í™” ë° ì••ì¶•"""
        # JSONìœ¼ë¡œ ì§ë ¬í™” ì‹œë„ (ë¹ ë¦„)
        try:
            serialized = json.dumps(data).encode('utf-8')
            compression_type = 'json'
        except (TypeError, ValueError):
            # JSONì´ ì•ˆë˜ë©´ pickle ì‚¬ìš© (ëŠë¦¬ì§€ë§Œ ëª¨ë“  ê°ì²´ ì§€ì›)
            serialized = pickle.dumps(data)
            compression_type = 'pickle'
        
        # ë°ì´í„°ê°€ í¬ë©´ ì••ì¶•
        if len(serialized) > 1024:  # 1KB ì´ìƒì´ë©´ ì••ì¶•
            compressed = zlib.compress(serialized)
            if len(compressed) < len(serialized) * 0.9:  # 10% ì´ìƒ ì••ì¶•ë˜ë©´ ì‚¬ìš©
                return compressed, f'{compression_type}+zlib'
        
        return serialized, compression_type
    
    def _decompress_and_deserialize(self, data, metadata):
        """ë°ì´í„° ì••ì¶• í•´ì œ ë° ì—­ì§ë ¬í™”"""
        compression_type = metadata
        
        # ì••ì¶• í•´ì œ
        if '+zlib' in compression_type:
            data = zlib.decompress(data)
            compression_type = compression_type.replace('+zlib', '')
        
        # ì—­ì§ë ¬í™”
        if compression_type == 'json':
            return json.loads(data.decode('utf-8'))
        elif compression_type == 'pickle':
            return pickle.loads(data)
        else:
            raise ValueError(f"Unknown compression type: {compression_type}")
    
    def set(self, key, value, timeout=300):
        """ìµœì í™”ëœ ìºì‹œ ì„¤ì •"""
        data, compression_type = self._serialize_and_compress(value)
        
        # ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ ì €ì¥
        cache_data = {
            'data': data,
            'metadata': compression_type,
            'timestamp': time.time()
        }
        
        serialized_cache_data = pickle.dumps(cache_data)
        self.redis_conn.setex(key, timeout, serialized_cache_data)
    
    def get(self, key, default=None):
        """ìµœì í™”ëœ ìºì‹œ ì¡°íšŒ"""
        try:
            cache_data = self.redis_conn.get(key)
            if cache_data is None:
                return default
            
            cache_dict = pickle.loads(cache_data)
            return self._decompress_and_deserialize(
                cache_dict['data'], 
                cache_dict['metadata']
            )
        except Exception:
            return default

# ì‚¬ìš© ì˜ˆì‹œ
optimized_cache = OptimizedRedisCache()

def cache_large_dataset(data_id):
    cache_key = f'large_dataset:{data_id}'
    data = optimized_cache.get(cache_key)
    
    if data is None:
        # ëŒ€ìš©ëŸ‰ ë°ì´í„° ìƒì„±
        data = generate_large_dataset(data_id)
        optimized_cache.set(cache_key, data, timeout=3600)
    
    return data
```

## ğŸ”§ ìš´ì˜ í™˜ê²½ ìµœì í™”

### Redis í´ëŸ¬ìŠ¤í„° ì„¤ì •

```python
# settings/production.py
CACHES = {
    'default': {
        'BACKEND': 'django_redis.cache.RedisCache',
        'LOCATION': [
            'redis://redis-node1:6379/0',
            'redis://redis-node2:6379/0',
            'redis://redis-node3:6379/0',
        ],
        'OPTIONS': {
            'CLIENT_CLASS': 'django_redis.client.ShardClient',  # ìƒ¤ë”© í´ë¼ì´ì–¸íŠ¸
            'CONNECTION_POOL_KWARGS': {
                'max_connections': 50,
                'retry_on_timeout': True,
                'health_check_interval': 30,
            },
            'SERIALIZER': 'django_redis.serializers.msgpack.MSGPackSerializer',
            'COMPRESSOR': 'django_redis.compressors.lz4.Lz4Compressor',
        }
    }
}

# Redis Sentinel ì„¤ì • (ê³ ê°€ìš©ì„±)
CACHES = {
    'default': {
        'BACKEND': 'django_redis.cache.RedisCache',
        'LOCATION': 'redis://mymaster/0',  # Sentinel ë§ˆìŠ¤í„° ì´ë¦„
        'OPTIONS': {
            'CLIENT_CLASS': 'django_redis.client.SentinelClient',
            'CONNECTION_POOL_KWARGS': {
                'service_name': 'mymaster',
                'sentinels': [
                    ('sentinel1', 26379),
                    ('sentinel2', 26379),
                    ('sentinel3', 26379),
                ],
            },
        }
    }
}
```

### ìºì‹œ ê³„ì¸µí™” ì „ëµ

```python
from django.core.cache import caches

class TieredCache:
    """ë‹¤ë‹¨ê³„ ìºì‹œ êµ¬í˜„"""
    
    def __init__(self):
        self.l1_cache = caches['l1']  # ë¡œì»¬ ë©”ëª¨ë¦¬ ìºì‹œ
        self.l2_cache = caches['l2']  # Redis ìºì‹œ
    
    def get(self, key, default=None):
        """L1 -> L2 ìˆœì„œë¡œ ìºì‹œ ì¡°íšŒ"""
        # L1 ìºì‹œì—ì„œ ë¨¼ì € ì¡°íšŒ
        value = self.l1_cache.get(key)
        if value is not None:
            return value
        
        # L2 ìºì‹œì—ì„œ ì¡°íšŒ
        value = self.l2_cache.get(key)
        if value is not None:
            # L1 ìºì‹œì— ë³µì‚¬ (ì‘ì€ TTL)
            self.l1_cache.set(key, value, timeout=60)
            return value
        
        return default
    
    def set(self, key, value, timeout=300):
        """ë‘ ë ˆë²¨ ëª¨ë‘ì— ìºì‹œ ì„¤ì •"""
        self.l2_cache.set(key, value, timeout)
        # L1ì€ ì§§ì€ ì‹œê°„ë§Œ ìœ ì§€
        self.l1_cache.set(key, value, timeout=min(60, timeout))
    
    def delete(self, key):
        """ë‘ ë ˆë²¨ ëª¨ë‘ì—ì„œ ì‚­ì œ"""
        self.l1_cache.delete(key)
        self.l2_cache.delete(key)

# settings.pyì—ì„œ ë‹¤ì¤‘ ìºì‹œ ì„¤ì •
CACHES = {
    'l1': {
        'BACKEND': 'django.core.cache.backends.locmem.LocMemCache',
        'LOCATION': 'unique-snowflake',
        'OPTIONS': {
            'MAX_ENTRIES': 1000,
            'CULL_FREQUENCY': 3,
        }
    },
    'l2': {
        'BACKEND': 'django_redis.cache.RedisCache',
        'LOCATION': 'redis://127.0.0.1:6379/1',
        'OPTIONS': {
            'CLIENT_CLASS': 'django_redis.client.DefaultClient',
        }
    }
}
```

### ìºì‹œ ë°±ì—… ë° ë³µêµ¬

```python
from django.core.management.base import BaseCommand
from django_redis import get_redis_connection
import json
import gzip

class Command(BaseCommand):
    help = 'Backup and restore Redis cache data'
    
    def add_arguments(self, parser):
        parser.add_argument('action', choices=['backup', 'restore'])
        parser.add_argument('--file', required=True, help='Backup file path')
        parser.add_argument('--pattern', default='*', help='Key pattern to backup')
    
    def handle(self, *args, **options):
        redis_conn = get_redis_connection('default')
        
        if options['action'] == 'backup':
            self.backup_cache(redis_conn, options['file'], options['pattern'])
        else:
            self.restore_cache(redis_conn, options['file'])
    
    def backup_cache(self, redis_conn, file_path, pattern):
        """ìºì‹œ ë°ì´í„° ë°±ì—…"""
        keys = redis_conn.keys(pattern)
        backup_data = {}
        
        self.stdout.write(f'Backing up {len(keys)} keys...')
        
        for key in keys:
            try:
                # í‚¤ íƒ€ì…ì— ë”°ë¼ ë‹¤ë¥´ê²Œ ì²˜ë¦¬
                key_type = redis_conn.type(key)
                ttl = redis_conn.ttl(key)
                
                if key_type == b'string':
                    value = redis_conn.get(key)
                elif key_type == b'hash':
                    value = redis_conn.hgetall(key)
                elif key_type == b'list':
                    value = redis_conn.lrange(key, 0, -1)
                elif key_type == b'set':
                    value = list(redis_conn.smembers(key))
                elif key_type == b'zset':
                    value = redis_conn.zrange(key, 0, -1, withscores=True)
                else:
                    continue
                
                backup_data[key.decode()] = {
                    'type': key_type.decode(),
                    'value': value,
                    'ttl': ttl if ttl > 0 else None
                }
            except Exception as e:
                self.stdout.write(f'Error backing up key {key}: {e}')
        
        # ì••ì¶•í•˜ì—¬ ì €ì¥
        with gzip.open(file_path, 'wt', encoding='utf-8') as f:
            json.dump(backup_data, f, default=str)
        
        self.stdout.write(
            self.style.SUCCESS(f'Backup completed: {file_path}')
        )
    
    def restore_cache(self, redis_conn, file_path):
        """ìºì‹œ ë°ì´í„° ë³µêµ¬"""
        try:
            with gzip.open(file_path, 'rt', encoding='utf-8') as f:
                backup_data = json.load(f)
        except FileNotFoundError:
            self.stdout.write(
                self.style.ERROR(f'Backup file not found: {file_path}')
            )
            return
        
        self.stdout.write(f'Restoring {len(backup_data)} keys...')
        
        for key, data in backup_data.items():
            try:
                key_type = data['type']
                value = data['value']
                ttl = data['ttl']
                
                if key_type == 'string':
                    redis_conn.set(key, value)
                elif key_type == 'hash':
                    redis_conn.hmset(key, value)
                elif key_type == 'list':
                    redis_conn.delete(key)
                    redis_conn.lpush(key, *value)
                elif key_type == 'set':
                    redis_conn.delete(key)
                    redis_conn.sadd(key, *value)
                elif key_type == 'zset':
                    redis_conn.delete(key)
                    for member, score in value:
                        redis_conn.zadd(key, {member: score})
                
                # TTL ì„¤ì •
                if ttl:
                    redis_conn.expire(key, ttl)
                    
            except Exception as e:
                self.stdout.write(f'Error restoring key {key}: {e}')
        
        self.stdout.write(
            self.style.SUCCESS('Restore completed')
        )
```

## ğŸ¯ ë§ˆë¬´ë¦¬: Redis ìºì‹œ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤

### âœ… êµ¬í˜„ ì²´í¬ë¦¬ìŠ¤íŠ¸

**ê¸°ë³¸ ì„¤ì •:**
- [ ] Django-Redis íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° ì„¤ì •
- [ ] ì ì ˆí•œ ì§ë ¬í™” ë°©ì‹ ì„ íƒ (JSON vs MessagePack vs Pickle)
- [ ] ì••ì¶• ì„¤ì •ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”
- [ ] ì—°ê²° í’€ í¬ê¸° ì ì ˆíˆ ì„¤ì •

**ìºì‹œ ì „ëµ:**
- [ ] ìºì‹œ ë ˆë²¨ë³„ ì ìš© ë²”ìœ„ ê²°ì •
- [ ] ì ì ˆí•œ TTL ì„¤ì • (ë°ì´í„° íŠ¹ì„±ì— ë”°ë¼)
- [ ] ìºì‹œ í‚¤ ë„¤ì´ë° ì»¨ë²¤ì…˜ ìˆ˜ë¦½
- [ ] ìºì‹œ ë¬´íš¨í™” ì „ëµ êµ¬í˜„

**ì„±ëŠ¥ ìµœì í™”:**
- [ ] ìºì‹œ íˆíŠ¸ìœ¨ ëª¨ë‹ˆí„°ë§ êµ¬í˜„
- [ ] ìºì‹œ ì›Œë°ì—… ì „ëµ ìˆ˜ë¦½
- [ ] ë¶„ì‚° ë½ìœ¼ë¡œ ì¤‘ë³µ ê³„ì‚° ë°©ì§€
- [ ] ê³„ì¸µí™”ëœ ìºì‹œ êµ¬ì¡° ê³ ë ¤

**ìš´ì˜ í™˜ê²½:**
- [ ] Redis í´ëŸ¬ìŠ¤í„°/ì„¼í‹°ë„¬ ì„¤ì • (ê³ ê°€ìš©ì„±)
- [ ] ìºì‹œ ë°±ì—… ë° ë³µêµ¬ ê³„íš ìˆ˜ë¦½
- [ ] ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼ ì‹œìŠ¤í…œ êµ¬ì¶•
- [ ] ì¥ì•  ëŒ€ì‘ ë§¤ë‰´ì–¼ ì‘ì„±

### âš¡ ì„±ëŠ¥ í–¥ìƒ íŒ

1. **ì ì ˆí•œ TTL ì„¤ì •**: ë°ì´í„° ì—…ë°ì´íŠ¸ ë¹ˆë„ì— ë§ì¶° ì„¤ì •
2. **ìºì‹œ í‚¤ ì„¤ê³„**: ì¶©ëŒì„ í”¼í•˜ê³  ì˜ë¯¸ ìˆëŠ” ë„¤ì´ë°
3. **ì••ì¶• í™œìš©**: í° ë°ì´í„°ëŠ” ì••ì¶•ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½
4. **ë°°ì¹˜ ì²˜ë¦¬**: ì—¬ëŸ¬ í‚¤ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬í•˜ëŠ” `get_many`, `set_many` í™œìš©
5. **ëª¨ë‹ˆí„°ë§**: ì •ê¸°ì ì¸ ì„±ëŠ¥ ì¸¡ì • ë° ìµœì í™”

### ğŸ”’ ì£¼ì˜ì‚¬í•­

- **ìºì‹œ ì¼ê´€ì„±**: ë°ì´í„° ë³€ê²½ ì‹œ ë°˜ë“œì‹œ ê´€ë ¨ ìºì‹œ ë¬´íš¨í™”
- **ë©”ëª¨ë¦¬ ê´€ë¦¬**: Redis ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì§€ì†ì  ëª¨ë‹ˆí„°ë§
- **ì¥ì•  ëŒ€ì‘**: ìºì‹œ ì¥ì•  ì‹œì—ë„ ì„œë¹„ìŠ¤ê°€ ë™ì‘í•˜ë„ë¡ ì„¤ê³„
- **ë³´ì•ˆ**: ì¤‘ìš”í•œ ë°ì´í„°ëŠ” ìºì‹œí•˜ì§€ ì•Šê±°ë‚˜ ì•”í˜¸í™”

Redisë¥¼ í™œìš©í•œ Django ìºì‹œ ì‹œìŠ¤í…œì€ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ì„±ëŠ¥ì„ ê·¹ì ìœ¼ë¡œ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆëŠ” ê°•ë ¥í•œ ë„êµ¬ì…ë‹ˆë‹¤. ì´ ê°€ì´ë“œë¥¼ í†µí•´ ì—¬ëŸ¬ë¶„ì˜ Django ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ë”ìš± ë¹ ë¥´ê³  íš¨ìœ¨ì ìœ¼ë¡œ ë™ì‘í•˜ê¸°ë¥¼ ë°”ëë‹ˆë‹¤.

## ğŸ“š ì¶”ê°€ í•™ìŠµ ìë£Œ

- [Django ìºì‹œ í”„ë ˆì„ì›Œí¬ ê³µì‹ ë¬¸ì„œ](https://docs.djangoproject.com/en/stable/topics/cache/)
- [Django-Redis ê³µì‹ ë¬¸ì„œ](https://django-redis.readthedocs.io/)
- [Redis ê³µì‹ ë¬¸ì„œ](https://redis.io/documentation)
- [Redis ì„±ëŠ¥ ìµœì í™” ê°€ì´ë“œ](https://redis.io/docs/manual/optimization/)

---

ğŸ’¡ **íŒ**: ìºì‹œ êµ¬í˜„ í›„ì—ëŠ” ë°˜ë“œì‹œ ë¶€í•˜ í…ŒìŠ¤íŠ¸ë¥¼ í†µí•´ ì‹¤ì œ ì„±ëŠ¥ í–¥ìƒì„ ì¸¡ì •í•´ë³´ì„¸ìš”!
