---
layout: post
title: "YOLO v10 GPU í™˜ê²½ êµ¬ì„± ì™„ë²½ ê°€ì´ë“œ: CUDA, PyTorch, ê°€ìƒí™˜ê²½ ì„¤ì •ë¶€í„° íŠ¸ëŸ¬ë¸”ìŠˆíŒ…ê¹Œì§€"
date: 2025-07-24 10:00:00 +0900
categories: [AI, Computer Vision, Setup]
tags: [YOLO, YOLOv10, GPU, CUDA, PyTorch, Environment, Setup, Troubleshooting, í™˜ê²½êµ¬ì„±, GPUì„¤ì •, ê°€ìƒí™˜ê²½]
---

**YOLO v10**ì„ GPUì—ì„œ íš¨ìœ¨ì ìœ¼ë¡œ ì‹¤í–‰í•˜ê¸° ìœ„í•œ í™˜ê²½ êµ¬ì„±ì€ ìƒê°ë³´ë‹¤ ë³µì¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. CUDA ë²„ì „ í˜¸í™˜ì„±, PyTorch ì„¤ì¹˜, ê°€ìƒí™˜ê²½ ì„¤ì • ë“± ì—¬ëŸ¬ ë‹¨ê³„ì—ì„œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ë¬¸ì œë“¤ê³¼ í•´ê²° ë°©ë²•ì„ ì‹¤ì œ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ í™˜ê²½ êµ¬ì„± ê°œìš”

YOLO v10 GPU í™˜ê²½ì„ êµ¬ì„±í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ì£¼ìš” ì»´í¬ë„ŒíŠ¸ë“¤ì…ë‹ˆë‹¤:

```
ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­
â”œâ”€â”€ NVIDIA GPU (RTX 2060 ì´ìƒ ê¶Œì¥)
â”œâ”€â”€ CUDA 11.8+ / 12.x
â”œâ”€â”€ Python 3.8-3.11
â”œâ”€â”€ PyTorch 2.0+
â””â”€â”€ YOLOv10 íŒ¨í‚¤ì§€
```

## ğŸ”§ ë‹¨ê³„ë³„ í™˜ê²½ êµ¬ì„±

### 1. NVIDIA ë“œë¼ì´ë²„ ë° CUDA ì„¤ì¹˜

ë¨¼ì € ì‹œìŠ¤í…œì— ì„¤ì¹˜ëœ NVIDIA ë“œë¼ì´ë²„ì™€ CUDA ë²„ì „ì„ í™•ì¸í•©ë‹ˆë‹¤:

```bash
# NVIDIA ë“œë¼ì´ë²„ í™•ì¸
nvidia-smi

# CUDA ë²„ì „ í™•ì¸
nvcc --version
cat /usr/local/cuda/version.txt
```

**ê¶Œì¥ ë²„ì „:**
- NVIDIA Driver: 535.xx ì´ìƒ
- CUDA: 11.8 ë˜ëŠ” 12.1

### 2. Python ê°€ìƒí™˜ê²½ ìƒì„±

ê°€ìƒí™˜ê²½ì„ ì‚¬ìš©í•˜ì—¬ íŒ¨í‚¤ì§€ ì¶©ëŒì„ ë°©ì§€í•©ë‹ˆë‹¤:

```bash
# conda í™˜ê²½ ìƒì„± (ê¶Œì¥)
conda create -n yolov10 python=3.10
conda activate yolov10

# ë˜ëŠ” venv ì‚¬ìš©
python -m venv yolov10_env
source yolov10_env/bin/activate  # Linux/Mac
# yolov10_env\Scripts\activate  # Windows
```

### 3. PyTorch GPU ë²„ì „ ì„¤ì¹˜

CUDA ë²„ì „ì— ë§ëŠ” PyTorchë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤:

```bash
# CUDA 11.8ìš©
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# CUDA 12.1ìš©
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# ì„¤ì¹˜ í™•ì¸
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}'); print(f'CUDA version: {torch.version.cuda}')"
```

### 4. YOLO v10 ì„¤ì¹˜

```bash
# ê³µì‹ YOLOv10 ì„¤ì¹˜
pip install ultralytics

# ë˜ëŠ” GitHubì—ì„œ ìµœì‹  ë²„ì „ ì„¤ì¹˜
git clone https://github.com/THU-MIG/yolov10.git
cd yolov10
pip install -e .

# ì¶”ê°€ ì˜ì¡´ì„± íŒ¨í‚¤ì§€
pip install opencv-python pillow matplotlib seaborn
```

## ğŸš¨ ì£¼ìš” íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ë¬¸ì œ 1: CUDA Version Mismatch

**ì¦ìƒ:**
```
RuntimeError: The detected CUDA version (12.1) mismatches the version that was used to compile PyTorch (11.8)
```

**í•´ê²°ë°©ë²•:**
```bash
# í˜„ì¬ PyTorch ì œê±°
pip uninstall torch torchvision torchaudio

# CUDA ë²„ì „ì— ë§ëŠ” PyTorch ì¬ì„¤ì¹˜
nvidia-smi  # CUDA ë²„ì „ í™•ì¸ í›„
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

### ë¬¸ì œ 2: cuDNN ë¼ì´ë¸ŒëŸ¬ë¦¬ ì˜¤ë¥˜

**ì¦ìƒ:**
```
OSError: libcudnn.so.8: cannot open shared object file
```

**í•´ê²°ë°©ë²•:**
```bash
# cuDNN ì„¤ì¹˜ (conda í™˜ê²½)
conda install cudnn

# ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ ì„¤ì •
export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH
```

### ë¬¸ì œ 3: ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜¤ë¥˜

**ì¦ìƒ:**
```
RuntimeError: CUDA out of memory
```

**í•´ê²°ë°©ë²•:**
```python
# ë°°ì¹˜ ì‚¬ì´ì¦ˆ ì¤„ì´ê¸°
model = YOLO('yolov10n.pt')
results = model.train(data='coco128.yaml', batch=8)  # 16 â†’ 8ë¡œ ê°ì†Œ

# ë˜ëŠ” Mixed Precision ì‚¬ìš©
results = model.train(data='coco128.yaml', amp=True)
```

### ë¬¸ì œ 4: ê°€ìƒí™˜ê²½ ì¸ì‹ ì˜¤ë¥˜

**ì¦ìƒ:**
- ê°€ìƒí™˜ê²½ í™œì„±í™” í›„ì—ë„ ì‹œìŠ¤í…œ Python ì‚¬ìš©
- íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ

**í•´ê²°ë°©ë²•:**
```bash
# ê°€ìƒí™˜ê²½ ê²½ë¡œ í™•ì¸
which python
which pip

# conda í™˜ê²½ ì¬ìƒì„±
conda deactivate
conda remove -n yolov10 --all
conda create -n yolov10 python=3.10
conda activate yolov10
```

### ë¬¸ì œ 5: _lzma ëª¨ë“ˆ ì˜¤ë¥˜

**ì¦ìƒ:**
```
ModuleNotFoundError: No module named '_lzma'
```

**ì›ì¸:** Pythonì´ ì‹œìŠ¤í…œì˜ lzma ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ì´ ì»´íŒŒì¼ë˜ì—ˆê±°ë‚˜, í•„ìš”í•œ ì••ì¶• ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ëˆ„ë½ëœ ê²½ìš°

**í•´ê²°ë°©ë²•:**
```bash
# Ubuntu/Debian ê³„ì—´
sudo apt-get update
sudo apt-get install liblzma-dev python3-lzma

# CentOS/RHEL ê³„ì—´
sudo yum install xz-devel
# ë˜ëŠ”
sudo dnf install xz-devel

# Python ì¬ì„¤ì¹˜ (pyenv ì‚¬ìš© ì‹œ)
pyenv uninstall 3.10.0
env PYTHON_CONFIGURE_OPTS="--enable-shared" pyenv install 3.10.0

# conda í™˜ê²½ì—ì„œì˜ í•´ê²°ë°©ë²•
conda install lzma
# ë˜ëŠ”
conda install python-lzma
```

### ë¬¸ì œ 6: libcudnn_cnn_infer.so.8 ë¼ì´ë¸ŒëŸ¬ë¦¬ ì˜¤ë¥˜

**ì¦ìƒ:**
```
Could not load library libcudnn_cnn_infer.so.8. Error: libcuda.so: cannot open shared object file: No such file or directory
```

**ì›ì¸:** NVIDIA ë“œë¼ì´ë²„ ë˜ëŠ” CUDA ë¼ì´ë¸ŒëŸ¬ë¦¬ ê²½ë¡œ ë¬¸ì œ

**í•´ê²°ë°©ë²•:**
```bash
# 1. NVIDIA ë“œë¼ì´ë²„ ìƒíƒœ í™•ì¸
nvidia-smi
# ë§Œì•½ "NVIDIA-SMI has failed" ì˜¤ë¥˜ê°€ ë‚˜ë©´ ë“œë¼ì´ë²„ ì¬ì„¤ì¹˜ í•„ìš”

# 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ê²½ë¡œ í™•ì¸ ë° ì„¤ì •
find /usr -name "libcuda.so*" 2>/dev/null
find /usr/local/cuda* -name "libcudnn*" 2>/dev/null

# 3. í™˜ê²½ë³€ìˆ˜ ì„¤ì • (bashrc ë˜ëŠ” bash_profileì— ì¶”ê°€)
export LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH
export CUDA_HOME=/usr/local/cuda
export PATH=$CUDA_HOME/bin:$PATH

# 4. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë§í¬ ìƒì„±
sudo ldconfig /usr/local/cuda/lib64

# 5. Docker í™˜ê²½ì—ì„œì˜ í•´ê²°ë°©ë²•
# NVIDIA Container Toolkit ì„¤ì¹˜
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list

sudo apt-get update && sudo apt-get install -y nvidia-docker2
sudo systemctl restart docker

# 6. ì™„ì „í•œ CUDA ì¬ì„¤ì¹˜ê°€ í•„ìš”í•œ ê²½ìš°
wget https://developer.download.nvidia.com/compute/cuda/12.1.1/local_installers/cuda_12.1.1_530.30.02_linux.run
sudo sh cuda_12.1.1_530.30.02_linux.run
```

## ğŸ’¡ ìµœì í™” íŒ

### 1. GPU ë©”ëª¨ë¦¬ ìµœì í™”

```python
import torch

# GPU ë©”ëª¨ë¦¬ ì •ë¦¬
torch.cuda.empty_cache()

# ë©”ëª¨ë¦¬ ë¶„í•  ìµœì í™”
torch.cuda.set_per_process_memory_fraction(0.8)

# Mixed Precision í•™ìŠµ
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()
```

### 2. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹

```python
from ultralytics import YOLO
import time

# ëª¨ë¸ ë¡œë“œ ë° GPU í• ë‹¹
model = YOLO('yolov10n.pt')
model.to('cuda')

# ì¶”ë¡  ì†ë„ ì¸¡ì •
start_time = time.time()
results = model('image.jpg')
inference_time = time.time() - start_time

print(f"ì¶”ë¡  ì‹œê°„: {inference_time:.3f}ì´ˆ")
print(f"FPS: {1/inference_time:.1f}")
```

### 3. ë©€í‹° GPU ì„¤ì •

```python
# ë©€í‹° GPU í•™ìŠµ
model = YOLO('yolov10n.pt')
results = model.train(
    data='coco128.yaml',
    device=[0, 1],  # GPU 0, 1 ì‚¬ìš©
    batch=32,
    epochs=100
)
```

## ğŸ” í™˜ê²½ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸

ì„¤ì¹˜ê°€ ì™„ë£Œë˜ë©´ ë‹¤ìŒ ìŠ¤í¬ë¦½íŠ¸ë¡œ í™˜ê²½ì„ ê²€ì¦í•˜ì„¸ìš”:

```python
import torch
import cv2
from ultralytics import YOLO
import subprocess
import os

def verify_environment():
    print("=== YOLO v10 GPU í™˜ê²½ ê²€ì¦ ===")
    
    # 1. Python ëª¨ë“ˆ ì˜ì¡´ì„± í™•ì¸
    try:
        import lzma
        print("âœ… lzma ëª¨ë“ˆ ì‚¬ìš© ê°€ëŠ¥")
    except ImportError:
        print("âŒ lzma ëª¨ë“ˆ ëˆ„ë½ - 'sudo apt-get install liblzma-dev python3-lzma' ì‹¤í–‰ í•„ìš”")
    
    # 2. NVIDIA ë“œë¼ì´ë²„ í™•ì¸
    try:
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ… NVIDIA ë“œë¼ì´ë²„ ì •ìƒ")
        else:
            print("âŒ NVIDIA ë“œë¼ì´ë²„ ë¬¸ì œ")
    except FileNotFoundError:
        print("âŒ nvidia-smi ëª…ë ¹ì–´ ì—†ìŒ - NVIDIA ë“œë¼ì´ë²„ ì„¤ì¹˜ í•„ìš”")
    
    # 3. CUDA ë¼ì´ë¸ŒëŸ¬ë¦¬ ê²½ë¡œ í™•ì¸
    cuda_lib_paths = [
        "/usr/local/cuda/lib64",
        "/usr/lib/x86_64-linux-gnu",
        "/usr/local/cuda-12.1/lib64",
        "/usr/local/cuda-11.8/lib64"
    ]
    
    libcuda_found = False
    for path in cuda_lib_paths:
        if os.path.exists(f"{path}/libcuda.so") or os.path.exists(f"{path}/libcuda.so.1"):
            print(f"âœ… libcuda.so ë°œê²¬: {path}")
            libcuda_found = True
            break
    
    if not libcuda_found:
        print("âŒ libcuda.so ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ - LD_LIBRARY_PATH ì„¤ì • ë˜ëŠ” CUDA ì¬ì„¤ì¹˜ í•„ìš”")
    
    # 4. PyTorch GPU í™•ì¸
    print(f"PyTorch ë²„ì „: {torch.__version__}")
    print(f"CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"CUDA ë²„ì „: {torch.version.cuda}")
        print(f"GPU ê°œìˆ˜: {torch.cuda.device_count()}")
        print(f"í˜„ì¬ GPU: {torch.cuda.get_device_name()}")
        print(f"GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB")
        
        # 5. cuDNN ë¼ì´ë¸ŒëŸ¬ë¦¬ í…ŒìŠ¤íŠ¸
        try:
            x = torch.randn(1, 3, 224, 224).cuda()
            conv = torch.nn.Conv2d(3, 64, 3).cuda()
            y = conv(x)
            print("âœ… cuDNN ë¼ì´ë¸ŒëŸ¬ë¦¬ ì •ìƒ ì‘ë™")
        except Exception as e:
            print(f"âŒ cuDNN ì˜¤ë¥˜: {e}")
    
    # 6. YOLO v10 ëª¨ë¸ í…ŒìŠ¤íŠ¸
    try:
        model = YOLO('yolov10n.pt')
        print("âœ… YOLO v10 ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
        
        # GPUì—ì„œ ì¶”ë¡  í…ŒìŠ¤íŠ¸
        if torch.cuda.is_available():
            model.to('cuda')
            # ë”ë¯¸ ì´ë¯¸ì§€ë¡œ í…ŒìŠ¤íŠ¸
            import numpy as np
            dummy_img = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)
            results = model(dummy_img, verbose=False)
            print("âœ… GPU ì¶”ë¡  í…ŒìŠ¤íŠ¸ ì„±ê³µ")
        
    except Exception as e:
        print(f"âŒ YOLO v10 ì˜¤ë¥˜: {e}")
    
    # 7. í™˜ê²½ë³€ìˆ˜ í™•ì¸
    env_vars = ['LD_LIBRARY_PATH', 'CUDA_HOME', 'PATH']
    for var in env_vars:
        value = os.environ.get(var, 'Not set')
        print(f"{var}: {value}")

if __name__ == "__main__":
    verify_environment()
```

## ğŸ“Š ì„±ëŠ¥ ë¹„êµ

ë‹¤ì–‘í•œ GPUì—ì„œì˜ YOLO v10 ì„±ëŠ¥ ë¹„êµ:

| GPU ëª¨ë¸ | VRAM | FPS (640x640) | ë°°ì¹˜ í¬ê¸° |
|----------|------|---------------|-----------|
| RTX 4090 | 24GB | 180+ | 32 |
| RTX 4080 | 16GB | 150+ | 24 |
| RTX 3080 | 10GB | 120+ | 16 |
| RTX 3060 | 12GB | 90+ | 12 |

## ğŸ¯ ê²°ë¡ 

YOLO v10 GPU í™˜ê²½ êµ¬ì„±ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ê²ƒì€ **CUDAì™€ PyTorch ë²„ì „ í˜¸í™˜ì„±**ì…ë‹ˆë‹¤. ì„¤ì¹˜ ì „ ë°˜ë“œì‹œ ë²„ì „ì„ í™•ì¸í•˜ê³ , ë¬¸ì œ ë°œìƒ ì‹œ ê°€ìƒí™˜ê²½ì„ ìƒˆë¡œ ìƒì„±í•˜ëŠ” ê²ƒì´ ê°€ì¥ í™•ì‹¤í•œ í•´ê²° ë°©ë²•ì…ë‹ˆë‹¤.

### í•µì‹¬ ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] NVIDIA ë“œë¼ì´ë²„ ìµœì‹  ë²„ì „ ì„¤ì¹˜
- [ ] CUDA ë²„ì „ í™•ì¸ ë° PyTorch í˜¸í™˜ì„± ê²€ì¦
- [ ] ì‹œìŠ¤í…œ ì˜ì¡´ì„± íŒ¨í‚¤ì§€ ì„¤ì¹˜ (liblzma-dev, python3-lzma)
- [ ] CUDA ë¼ì´ë¸ŒëŸ¬ë¦¬ ê²½ë¡œ ì„¤ì • (LD_LIBRARY_PATH)
- [ ] ê¹¨ë—í•œ ê°€ìƒí™˜ê²½ ìƒì„±
- [ ] ìˆœì„œëŒ€ë¡œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ (PyTorch â†’ YOLO v10)
- [ ] í™˜ê²½ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰

### ìì£¼ ë°œìƒí•˜ëŠ” ì˜¤ë¥˜ ìš”ì•½
1. **ModuleNotFoundError: No module named '_lzma'** â†’ ì‹œìŠ¤í…œ lzma ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
2. **libcudnn_cnn_infer.so.8 ì˜¤ë¥˜** â†’ CUDA ë¼ì´ë¸ŒëŸ¬ë¦¬ ê²½ë¡œ ì„¤ì • ë° ë“œë¼ì´ë²„ í™•ì¸
3. **CUDA version mismatch** â†’ PyTorch CUDA ë²„ì „ ë§ì¶¤ ì¬ì„¤ì¹˜
4. **CUDA out of memory** â†’ ë°°ì¹˜ í¬ê¸° ì¡°ì • ë° Mixed Precision ì‚¬ìš©

ì˜¬ë°”ë¥¸ í™˜ê²½ êµ¬ì„±ìœ¼ë¡œ YOLO v10ì˜ ê°•ë ¥í•œ GPU ê°€ì† ì„±ëŠ¥ì„ ìµœëŒ€í•œ í™œìš©í•´ë³´ì„¸ìš”! ğŸš€
