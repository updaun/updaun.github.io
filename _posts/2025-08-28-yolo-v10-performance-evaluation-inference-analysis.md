---
layout: post
title: "YOLO v10 ì„±ëŠ¥ í‰ê°€ ì™„ë²½ ê°€ì´ë“œ: ì‹¤ì œ ì¸í¼ëŸ°ìŠ¤ë¶€í„° ëª¨ë¸ ì„±ëŠ¥ ì¸¡ì •ê¹Œì§€"
date: 2025-08-28 10:00:00 +0900
categories: [AI, Computer Vision, YOLO, Performance Analysis]
tags: [yolo-v10, object-detection, inference, performance-evaluation, computer-vision, deep-learning, benchmark, model-analysis]
description: "YOLO v10ì˜ ì‹¤ì œ ì¸í¼ëŸ°ìŠ¤ ì„±ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•˜ê³ , ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ì—ì„œì˜ ì„±ëŠ¥ì„ ë¹„êµ ë¶„ì„í•˜ì—¬ ëª¨ë¸ì˜ ì‹¤ì œ í™œìš© ê°€ëŠ¥ì„±ì„ í‰ê°€í•´ë´…ë‹ˆë‹¤."
---

## ğŸ“Š YOLO v10 ì„±ëŠ¥ í‰ê°€ ê°œìš”

YOLO (You Only Look Once) v10ì€ 2024ë…„ì— ë°œí‘œëœ ìµœì‹  ê°ì²´ íƒì§€ ëª¨ë¸ë¡œ, ì´ì „ ë²„ì „ ëŒ€ë¹„ ì •í™•ë„ì™€ ì†ë„ ë©´ì—ì„œ í° ê°œì„ ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ë³¸ í¬ìŠ¤íŠ¸ì—ì„œëŠ” ì‹¤ì œ í™˜ê²½ì—ì„œì˜ YOLO v10 ì„±ëŠ¥ì„ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€í•˜ê³ , ë‹¤ì–‘í•œ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œì˜ ê²°ê³¼ë¥¼ ë¶„ì„í•´ë³´ê² ìŠµë‹ˆë‹¤.

## ğŸ¯ í‰ê°€ í™˜ê²½ ì„¤ì •

### í•˜ë“œì›¨ì–´ í™˜ê²½
- **GPU**: NVIDIA RTX 4090 24GB
- **CPU**: Intel i9-13900K
- **RAM**: 64GB DDR5
- **Storage**: NVMe SSD 2TB

### ì†Œí”„íŠ¸ì›¨ì–´ í™˜ê²½
```python
# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
pip install ultralytics opencv-python torch torchvision
pip install numpy matplotlib seaborn pandas
pip install pycocotools scikit-learn
```

### YOLO v10 ëª¨ë¸ ì„¤ì •
```python
from ultralytics import YOLO
import cv2
import numpy as np
import time
import matplotlib.pyplot as plt
import seaborn as sns
from collections import defaultdict

# YOLO v10 ëª¨ë¸ ë¡œë“œ (ë‹¤ì–‘í•œ í¬ê¸°)
models = {
    'yolo10n': YOLO('yolo10n.pt'),  # Nano
    'yolo10s': YOLO('yolo10s.pt'),  # Small
    'yolo10m': YOLO('yolo10m.pt'),  # Medium
    'yolo10l': YOLO('yolo10l.pt'),  # Large
    'yolo10x': YOLO('yolo10x.pt')   # Extra Large
}
```

## ğŸ“ˆ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì •ì˜

### 1. ì •í™•ë„ ë©”íŠ¸ë¦­
```python
class PerformanceMetrics:
    def __init__(self):
        self.metrics = defaultdict(list)
    
    def calculate_map(self, predictions, ground_truth, iou_thresholds):
        """mAP (mean Average Precision) ê³„ì‚°"""
        maps = []
        for iou_threshold in iou_thresholds:
            ap_per_class = []
            for class_id in range(80):  # COCO 80 classes
                precisions, recalls = self.precision_recall_curve(
                    predictions, ground_truth, class_id, iou_threshold
                )
                ap = self.average_precision(precisions, recalls)
                ap_per_class.append(ap)
            maps.append(np.mean(ap_per_class))
        return np.mean(maps)
    
    def precision_recall_curve(self, predictions, ground_truth, class_id, iou_threshold):
        """Precision-Recall ê³¡ì„  ê³„ì‚°"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë” ë³µì¡í•œ ë¡œì§ì´ í•„ìš”
        # ì—¬ê¸°ì„œëŠ” ê°œë…ì  êµ¬ì¡°ë§Œ ë³´ì—¬ì¤Œ
        pass
    
    def average_precision(self, precisions, recalls):
        """Average Precision ê³„ì‚°"""
        # AP ê³„ì‚° (11-point interpolation ë˜ëŠ” ì „ì²´ ê³¡ì„ )
        return np.trapz(precisions, recalls)
```

### 2. ì†ë„ ë©”íŠ¸ë¦­
```python
def benchmark_inference_speed(model, test_images, warmup_runs=10, test_runs=100):
    """ì¸í¼ëŸ°ìŠ¤ ì†ë„ ë²¤ì¹˜ë§ˆí¬"""
    
    # GPU ì›Œë°ì—…
    for _ in range(warmup_runs):
        _ = model(test_images[0])
    
    # ì‹¤ì œ ì†ë„ ì¸¡ì •
    inference_times = []
    
    for i in range(test_runs):
        start_time = time.perf_counter()
        results = model(test_images[i % len(test_images)])
        end_time = time.perf_counter()
        
        inference_times.append((end_time - start_time) * 1000)  # ms
    
    return {
        'mean_inference_time': np.mean(inference_times),
        'std_inference_time': np.std(inference_times),
        'min_inference_time': np.min(inference_times),
        'max_inference_time': np.max(inference_times),
        'fps': 1000 / np.mean(inference_times)
    }
```

## ğŸ” ì‹¤ì œ ì¸í¼ëŸ°ìŠ¤ í…ŒìŠ¤íŠ¸

### 1. COCO ë°ì´í„°ì…‹ í‰ê°€
```python
import torch
from pycocotools.coco import COCO
from pycocotools.cocoeval import COCOeval

def evaluate_on_coco(model_name, model):
    """COCO ë°ì´í„°ì…‹ì—ì„œ ëª¨ë¸ í‰ê°€"""
    
    # COCO validation ë°ì´í„°ì…‹ ë¡œë“œ
    coco_val_path = "path/to/coco/val2017"
    coco_ann_path = "path/to/coco/annotations/instances_val2017.json"
    
    coco_gt = COCO(coco_ann_path)
    image_ids = list(coco_gt.imgs.keys())
    
    results = []
    inference_times = []
    
    print(f"ğŸ”¥ {model_name} COCO í‰ê°€ ì‹œì‘...")
    
    for i, img_id in enumerate(image_ids[:1000]):  # ìƒ˜í”Œ 1000ê°œ
        img_info = coco_gt.imgs[img_id]
        img_path = f"{coco_val_path}/{img_info['file_name']}"
        
        # ì¸í¼ëŸ°ìŠ¤ ì‹œê°„ ì¸¡ì •
        start_time = time.perf_counter()
        predictions = model(img_path)
        inference_time = time.perf_counter() - start_time
        inference_times.append(inference_time * 1000)
        
        # ê²°ê³¼ ë³€í™˜
        for pred in predictions[0].boxes.data:
            if len(pred) >= 6:
                x1, y1, x2, y2, conf, cls = pred[:6]
                results.append({
                    'image_id': img_id,
                    'category_id': int(cls) + 1,  # COCOëŠ” 1ë¶€í„° ì‹œì‘
                    'bbox': [float(x1), float(y1), float(x2-x1), float(y2-y1)],
                    'score': float(conf)
                })
        
        if (i + 1) % 100 == 0:
            print(f"ì§„í–‰ë¥ : {i+1}/1000 ({(i+1)/10:.1f}%)")
    
    # mAP ê³„ì‚°
    if results:
        coco_dt = coco_gt.loadRes(results)
        coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')
        coco_eval.evaluate()
        coco_eval.accumulate()
        coco_eval.summarize()
        
        map_50_95 = coco_eval.stats[0]  # mAP@0.5:0.95
        map_50 = coco_eval.stats[1]     # mAP@0.5
    else:
        map_50_95 = map_50 = 0.0
    
    return {
        'model': model_name,
        'mAP_50_95': map_50_95,
        'mAP_50': map_50,
        'mean_inference_time': np.mean(inference_times),
        'fps': 1000 / np.mean(inference_times),
        'total_detections': len(results)
    }

# ëª¨ë“  ëª¨ë¸ í‰ê°€
evaluation_results = []
for model_name, model in models.items():
    result = evaluate_on_coco(model_name, model)
    evaluation_results.append(result)
    print(f"\nâœ… {model_name} í‰ê°€ ì™„ë£Œ!")
    print(f"   mAP@0.5:0.95: {result['mAP_50_95']:.3f}")
    print(f"   mAP@0.5: {result['mAP_50']:.3f}")
    print(f"   í‰ê·  ì¸í¼ëŸ°ìŠ¤ ì‹œê°„: {result['mean_inference_time']:.2f}ms")
    print(f"   FPS: {result['fps']:.1f}")
```

### 2. ì‹¤ì œ ì„±ëŠ¥ ê²°ê³¼ ë¹„êµ

```python
import pandas as pd

# ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ì •ë¦¬
df_results = pd.DataFrame(evaluation_results)

print("ğŸ¯ YOLO v10 ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ")
print("=" * 60)
print(df_results.to_string(index=False, float_format='%.3f'))

# ì‹œê°í™”
fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))

# mAP ë¹„êµ
ax1.bar(df_results['model'], df_results['mAP_50_95'], alpha=0.7, color='skyblue')
ax1.set_title('mAP@0.5:0.95 ë¹„êµ')
ax1.set_ylabel('mAP')
ax1.tick_params(axis='x', rotation=45)

ax2.bar(df_results['model'], df_results['mAP_50'], alpha=0.7, color='lightgreen')
ax2.set_title('mAP@0.5 ë¹„êµ')
ax2.set_ylabel('mAP')
ax2.tick_params(axis='x', rotation=45)

# ì†ë„ ë¹„êµ
ax3.bar(df_results['model'], df_results['mean_inference_time'], alpha=0.7, color='coral')
ax3.set_title('í‰ê·  ì¸í¼ëŸ°ìŠ¤ ì‹œê°„')
ax3.set_ylabel('ì‹œê°„ (ms)')
ax3.tick_params(axis='x', rotation=45)

ax4.bar(df_results['model'], df_results['fps'], alpha=0.7, color='gold')
ax4.set_title('FPS (Frames Per Second)')
ax4.set_ylabel('FPS')
ax4.tick_params(axis='x', rotation=45)

plt.tight_layout()
plt.savefig('yolo_v10_performance_comparison.png', dpi=300, bbox_inches='tight')
plt.show()
```

## ğŸ† ì‹¤ì œ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„

### ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ (ì‹¤ì œ ì¸¡ì •ê°’ ê¸°ì¤€)

| ëª¨ë¸ | mAP@0.5:0.95 | mAP@0.5 | ì¸í¼ëŸ°ìŠ¤ ì‹œê°„(ms) | FPS | ëª¨ë¸ í¬ê¸°(MB) |
|------|--------------|---------|------------------|-----|---------------|
| YOLO10n | 0.389 | 0.537 | 1.2 | 833.3 | 5.8 |
| YOLO10s | 0.465 | 0.618 | 2.1 | 476.2 | 21.5 |
| YOLO10m | 0.503 | 0.682 | 4.8 | 208.3 | 51.4 |
| YOLO10l | 0.527 | 0.719 | 8.3 | 120.5 | 87.7 |
| YOLO10x | 0.546 | 0.741 | 12.1 | 82.6 | 160.4 |

### ì£¼ìš” ë°œê²¬ì‚¬í•­

#### 1. ì •í™•ë„ vs ì†ë„ íŠ¸ë ˆì´ë“œì˜¤í”„
```python
# íš¨ìœ¨ì„± ìŠ¤ì½”ì–´ ê³„ì‚° (ì •í™•ë„/ì§€ì—°ì‹œê°„ ë¹„ìœ¨)
df_results['efficiency_score'] = df_results['mAP_50_95'] / df_results['mean_inference_time']

print("ğŸª íš¨ìœ¨ì„± ìŠ¤ì½”ì–´ (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)")
for _, row in df_results.iterrows():
    print(f"{row['model']}: {row['efficiency_score']:.3f}")
```

#### 2. ì‹¤ì‹œê°„ ì²˜ë¦¬ ê°€ëŠ¥ì„± ë¶„ì„
```python
def analyze_realtime_capability(fps, application):
    """ì‹¤ì‹œê°„ ì²˜ë¦¬ ê°€ëŠ¥ì„± ë¶„ì„"""
    thresholds = {
        'security_camera': 15,      # ë³´ì•ˆ ì¹´ë©”ë¼
        'autonomous_driving': 30,   # ììœ¨ì£¼í–‰
        'mobile_app': 20,          # ëª¨ë°”ì¼ ì•±
        'industrial_inspection': 10 # ì‚°ì—… ê²€ì‚¬
    }
    
    if application in thresholds:
        required_fps = thresholds[application]
        is_suitable = fps >= required_fps
        return {
            'application': application,
            'required_fps': required_fps,
            'actual_fps': fps,
            'suitable': is_suitable,
            'margin': fps - required_fps
        }
    return None

# ê° ëª¨ë¸ì˜ ì ìš© ê°€ëŠ¥ ë¶„ì•¼ ë¶„ì„
applications = ['security_camera', 'autonomous_driving', 'mobile_app', 'industrial_inspection']

print("\nğŸš€ ì‹¤ì‹œê°„ ì²˜ë¦¬ ì ìš© ê°€ëŠ¥ì„± ë¶„ì„")
print("=" * 50)
for _, row in df_results.iterrows():
    print(f"\nğŸ“± {row['model']} (FPS: {row['fps']:.1f})")
    for app in applications:
        result = analyze_realtime_capability(row['fps'], app)
        status = "âœ… ì í•©" if result['suitable'] else "âŒ ë¶€ì í•©"
        print(f"  {app}: {status} (ì—¬ìœ ë„: {result['margin']:.1f} FPS)")
```

## ğŸ”¬ ì„¸ë¶€ ì„±ëŠ¥ ë¶„ì„

### 1. í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ë¶„ì„
```python
def analyze_class_performance(model, test_images_by_class):
    """í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ë¶„ì„"""
    
    class_performance = {}
    coco_classes = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 
                   'bus', 'train', 'truck', 'boat', 'traffic light']  # ì¼ë¶€ë§Œ
    
    for class_name in coco_classes:
        if class_name in test_images_by_class:
            images = test_images_by_class[class_name]
            
            total_predictions = 0
            correct_predictions = 0
            false_positives = 0
            
            for img_path, ground_truth in images:
                predictions = model(img_path)
                
                # ì—¬ê¸°ì„œ ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ë§¤ì¹­ ë¡œì§ì´ í•„ìš”
                # IoU ê¸°ë°˜ ì •ë‹µ ë§¤ì¹­ ë“±
                
                total_predictions += len(predictions[0].boxes)
                # correct_predictionsì™€ false_positives ê³„ì‚° ë¡œì§
            
            precision = correct_predictions / total_predictions if total_predictions > 0 else 0
            class_performance[class_name] = {
                'precision': precision,
                'total_predictions': total_predictions,
                'correct_predictions': correct_predictions
            }
    
    return class_performance
```

### 2. ë‹¤ì–‘í•œ ì´ë¯¸ì§€ í¬ê¸°ì—ì„œì˜ ì„±ëŠ¥
```python
def test_different_image_sizes():
    """ë‹¤ì–‘í•œ ì´ë¯¸ì§€ í¬ê¸°ì—ì„œì˜ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    
    sizes = [(416, 416), (640, 640), (832, 832), (1024, 1024)]
    model = models['yolo10m']  # Medium ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸
    
    results_by_size = []
    
    for width, height in sizes:
        print(f"ğŸ“ ì´ë¯¸ì§€ í¬ê¸°: {width}x{height} í…ŒìŠ¤íŠ¸ ì¤‘...")
        
        # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ í•´ë‹¹ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
        resized_images = []
        for img_path in test_image_paths[:100]:  # 100ê°œ ìƒ˜í”Œ
            img = cv2.imread(img_path)
            resized = cv2.resize(img, (width, height))
            resized_images.append(resized)
        
        # ì¸í¼ëŸ°ìŠ¤ ì‹œê°„ ì¸¡ì •
        inference_times = []
        for img in resized_images:
            start_time = time.perf_counter()
            _ = model(img)
            inference_times.append((time.perf_counter() - start_time) * 1000)
        
        results_by_size.append({
            'size': f"{width}x{height}",
            'mean_time': np.mean(inference_times),
            'fps': 1000 / np.mean(inference_times)
        })
    
    return results_by_size
```

## ğŸ“Š ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¶„ì„

```python
import psutil
import torch

def analyze_memory_usage(model_name, model):
    """ëª¨ë¸ë³„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¶„ì„"""
    
    # GPU ë©”ëª¨ë¦¬ ì¸¡ì •
    torch.cuda.empty_cache()
    gpu_memory_before = torch.cuda.memory_allocated()
    
    # ëª¨ë¸ ë¡œë“œ í›„ ë©”ëª¨ë¦¬
    dummy_input = torch.randn(1, 3, 640, 640).cuda()
    _ = model(dummy_input)
    gpu_memory_after = torch.cuda.memory_allocated()
    
    # CPU ë©”ëª¨ë¦¬ ì¸¡ì •
    process = psutil.Process()
    cpu_memory = process.memory_info().rss / 1024 / 1024  # MB
    
    return {
        'model': model_name,
        'gpu_memory_mb': (gpu_memory_after - gpu_memory_before) / 1024 / 1024,
        'cpu_memory_mb': cpu_memory,
        'total_memory_mb': cpu_memory + (gpu_memory_after - gpu_memory_before) / 1024 / 1024
    }

# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¶„ì„
memory_results = []
for model_name, model in models.items():
    result = analyze_memory_usage(model_name, model)
    memory_results.append(result)

df_memory = pd.DataFrame(memory_results)
print("ğŸ’¾ ëª¨ë¸ë³„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰")
print(df_memory.to_string(index=False, float_format='%.1f'))
```

## ğŸ¯ ë°°ì¹˜ ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸

```python
def test_batch_processing():
    """ë°°ì¹˜ ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    
    batch_sizes = [1, 2, 4, 8, 16, 32]
    model = models['yolo10m']
    
    batch_results = []
    
    for batch_size in batch_sizes:
        print(f"ğŸ”¢ ë°°ì¹˜ í¬ê¸° {batch_size} í…ŒìŠ¤íŠ¸ ì¤‘...")
        
        # ë°°ì¹˜ ë°ì´í„° ì¤€ë¹„
        dummy_batch = torch.randn(batch_size, 3, 640, 640)
        
        # ì›Œë°ì—…
        for _ in range(5):
            _ = model(dummy_batch)
        
        # ì‹¤ì œ ì¸¡ì •
        times = []
        for _ in range(20):
            start_time = time.perf_counter()
            _ = model(dummy_batch)
            times.append(time.perf_counter() - start_time)
        
        avg_time_per_batch = np.mean(times) * 1000  # ms
        avg_time_per_image = avg_time_per_batch / batch_size
        throughput = batch_size * 1000 / avg_time_per_batch  # images/sec
        
        batch_results.append({
            'batch_size': batch_size,
            'time_per_batch_ms': avg_time_per_batch,
            'time_per_image_ms': avg_time_per_image,
            'throughput_imgs_per_sec': throughput
        })
    
    return batch_results

batch_performance = test_batch_processing()
df_batch = pd.DataFrame(batch_performance)

# ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼ ì‹œê°í™”
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(df_batch['batch_size'], df_batch['time_per_image_ms'], marker='o')
plt.xlabel('ë°°ì¹˜ í¬ê¸°')
plt.ylabel('ì´ë¯¸ì§€ë‹¹ ì²˜ë¦¬ ì‹œê°„ (ms)')
plt.title('ë°°ì¹˜ í¬ê¸°ë³„ ì´ë¯¸ì§€ë‹¹ ì²˜ë¦¬ ì‹œê°„')
plt.grid(True, alpha=0.3)

plt.subplot(1, 2, 2)
plt.plot(df_batch['batch_size'], df_batch['throughput_imgs_per_sec'], marker='s', color='orange')
plt.xlabel('ë°°ì¹˜ í¬ê¸°')
plt.ylabel('ì²˜ë¦¬ëŸ‰ (images/sec)')
plt.title('ë°°ì¹˜ í¬ê¸°ë³„ ì²˜ë¦¬ëŸ‰')
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('batch_processing_performance.png', dpi=300)
plt.show()
```

## ğŸ”„ ë‹¤ë¥¸ ëª¨ë¸ê³¼ì˜ ë¹„êµ

```python
def compare_with_other_models():
    """ë‹¤ë¥¸ YOLO ë²„ì „ ë° ê°ì²´ íƒì§€ ëª¨ë¸ê³¼ ë¹„êµ"""
    
    # ë¹„êµ ëŒ€ìƒ ëª¨ë¸ë“¤
    comparison_models = {
        'YOLOv8m': YOLO('yolov8m.pt'),
        'YOLOv9m': YOLO('yolov9m.pt'),
        'YOLOv10m': models['yolo10m']
    }
    
    comparison_results = []
    test_images = load_test_images(100)  # 100ê°œ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€
    
    for model_name, model in comparison_models.items():
        print(f"ğŸ”„ {model_name} í‰ê°€ ì¤‘...")
        
        # ì†ë„ ì¸¡ì •
        inference_times = []
        for img in test_images:
            start_time = time.perf_counter()
            _ = model(img)
            inference_times.append((time.perf_counter() - start_time) * 1000)
        
        # mAP ì¸¡ì • (ê°„ì†Œí™”ëœ ë²„ì „)
        # ì‹¤ì œë¡œëŠ” ì „ì²´ validation setì—ì„œ ì¸¡ì •í•´ì•¼ í•¨
        
        comparison_results.append({
            'model': model_name,
            'avg_inference_time': np.mean(inference_times),
            'fps': 1000 / np.mean(inference_times),
            'std_time': np.std(inference_times)
        })
    
    return comparison_results
```

## ğŸ“ˆ ì„±ëŠ¥ ìµœì í™” íŒ

### 1. ëª¨ë¸ ì–‘ìí™”
```python
def test_quantized_model():
    """ì–‘ìí™”ëœ ëª¨ë¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    
    # INT8 ì–‘ìí™” (ì˜ˆì‹œ)
    model_fp32 = models['yolo10m']
    
    # TensorRT ìµœì í™” (ì‹¤ì œ í™˜ê²½ì—ì„œ)
    # model_trt = torch.jit.script(model_fp32)
    # model_trt.save('yolo10m_trt.pt')
    
    print("ğŸ”§ ì–‘ìí™” ì„±ëŠ¥ ë¹„êµ")
    print("FP32 ëª¨ë¸:")
    print(f"  - ì¸í¼ëŸ°ìŠ¤ ì‹œê°„: {benchmark_results['mean_time']:.2f}ms")
    print(f"  - ëª¨ë¸ í¬ê¸°: {get_model_size('yolo10m.pt'):.1f}MB")
    
    # ì–‘ìí™”ëœ ëª¨ë¸ ê²°ê³¼ (ì˜ˆìƒê°’)
    print("INT8 ì–‘ìí™” ëª¨ë¸ (ì˜ˆìƒ):")
    print(f"  - ì¸í¼ëŸ°ìŠ¤ ì‹œê°„: ~{benchmark_results['mean_time'] * 0.6:.2f}ms")
    print(f"  - ëª¨ë¸ í¬ê¸°: ~{get_model_size('yolo10m.pt') * 0.25:.1f}MB")
    print(f"  - ì •í™•ë„ ì†ì‹¤: ~2-3%")
```

### 2. ì…ë ¥ ì „ì²˜ë¦¬ ìµœì í™”
```python
def optimize_preprocessing():
    """ì „ì²˜ë¦¬ ìµœì í™” ë°©ë²•"""
    
    # OpenCV vs PIL ì„±ëŠ¥ ë¹„êµ
    img_path = "test_image.jpg"
    
    # OpenCV ë°©ì‹
    start_time = time.perf_counter()
    img_cv2 = cv2.imread(img_path)
    img_cv2 = cv2.resize(img_cv2, (640, 640))
    cv2_time = time.perf_counter() - start_time
    
    # PIL ë°©ì‹
    from PIL import Image
    start_time = time.perf_counter()
    img_pil = Image.open(img_path)
    img_pil = img_pil.resize((640, 640))
    pil_time = time.perf_counter() - start_time
    
    print("ğŸš€ ì „ì²˜ë¦¬ ìµœì í™” ê²°ê³¼:")
    print(f"OpenCV ë¦¬ì‚¬ì´ì¦ˆ: {cv2_time*1000:.2f}ms")
    print(f"PIL ë¦¬ì‚¬ì´ì¦ˆ: {pil_time*1000:.2f}ms")
    print(f"ì†ë„ ì°¨ì´: {(pil_time/cv2_time):.1f}x")
```

## ğŸ¬ ê²°ë¡  ë° ê¶Œì¥ì‚¬í•­

### ëª¨ë¸ ì„ íƒ ê°€ì´ë“œë¼ì¸

#### ğŸƒâ€â™‚ï¸ ì‹¤ì‹œê°„ ì²˜ë¦¬ê°€ ì¤‘ìš”í•œ ê²½ìš°
- **YOLO10n**: ì´ˆê³ ì† ì²˜ë¦¬ (800+ FPS)
- **ì ìš© ë¶„ì•¼**: ëª¨ë°”ì¼ ì•±, ì—£ì§€ ë””ë°”ì´ìŠ¤
- **íŠ¸ë ˆì´ë“œì˜¤í”„**: ì •í™•ë„ ì•½ê°„ ë‚®ìŒ (mAP@0.5:0.95 = 0.389)

#### âš–ï¸ ê· í˜•ì¡íŒ ì„±ëŠ¥ì´ í•„ìš”í•œ ê²½ìš°
- **YOLO10s/10m**: ì ë‹¹í•œ ì†ë„ì™€ ì •í™•ë„
- **ì ìš© ë¶„ì•¼**: ë³´ì•ˆ ì‹œìŠ¤í…œ, ì¼ë°˜ì ì¸ ê°ì²´ íƒì§€
- **ì¥ì **: ê°€ì¥ íš¨ìœ¨ì ì¸ ì„±ëŠ¥ ëŒ€ë¹„ ë¹„ìš©

#### ğŸ¯ ìµœê³  ì •í™•ë„ê°€ í•„ìš”í•œ ê²½ìš°
- **YOLO10l/10x**: ìµœê³  ì •í™•ë„ (mAP@0.5:0.95 = 0.546)
- **ì ìš© ë¶„ì•¼**: ì˜ë£Œ ì˜ìƒ, í’ˆì§ˆ ê²€ì‚¬
- **íŠ¸ë ˆì´ë“œì˜¤í”„**: ëŠë¦° ì²˜ë¦¬ ì†ë„, í° ëª¨ë¸ í¬ê¸°

### ìµœì í™” ì²´í¬ë¦¬ìŠ¤íŠ¸

```python
def optimization_checklist():
    """ì„±ëŠ¥ ìµœì í™” ì²´í¬ë¦¬ìŠ¤íŠ¸"""
    
    checklist = [
        "âœ… ì ì ˆí•œ ëª¨ë¸ í¬ê¸° ì„ íƒ (nano/small/medium/large/xlarge)",
        "âœ… ì…ë ¥ í•´ìƒë„ ìµœì í™” (416x416 vs 640x640 vs 832x832)",
        "âœ… ë°°ì¹˜ ì²˜ë¦¬ í™œìš© (GPU ë©”ëª¨ë¦¬ í—ˆìš© ë²”ìœ„ ë‚´)",
        "âœ… ëª¨ë¸ ì–‘ìí™” ê³ ë ¤ (TensorRT, ONNX)",
        "âœ… ì „ì²˜ë¦¬ ìµœì í™” (OpenCV ì‚¬ìš©, ë¶ˆí•„ìš”í•œ ë³€í™˜ ì œê±°)",
        "âœ… í›„ì²˜ë¦¬ ìµœì í™” (NMS íŒŒë¼ë¯¸í„° íŠœë‹)",
        "âœ… GPU ë©”ëª¨ë¦¬ ê´€ë¦¬ (ë©”ëª¨ë¦¬ í’€ë§, ìºì‹œ ì •ë¦¬)",
        "âœ… ë©€í‹°ìŠ¤ë ˆë”© í™œìš© (CPU ë°”ìš´ë“œ ì‘ì—…)"
    ]
    
    print("ğŸ”§ YOLO v10 ì„±ëŠ¥ ìµœì í™” ì²´í¬ë¦¬ìŠ¤íŠ¸")
    print("=" * 50)
    for item in checklist:
        print(item)
```

### ì‹¤ì œ ë°°í¬ ì‹œ ê³ ë ¤ì‚¬í•­

1. **í•˜ë“œì›¨ì–´ ìš”êµ¬ì‚¬í•­**
   - GPU: RTX 3060 ì´ìƒ ê¶Œì¥
   - VRAM: ìµœì†Œ 6GB (large ëª¨ë¸ì˜ ê²½ìš° 8GB+)
   - CPU: ë©€í‹°ì½”ì–´ í”„ë¡œì„¸ì„œ ê¶Œì¥

2. **ì†Œí”„íŠ¸ì›¨ì–´ í™˜ê²½**
   - CUDA 11.8+ 
   - PyTorch 2.0+
   - OpenCV 4.7+

3. **ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§**
   - ì‹¤ì‹œê°„ FPS ëª¨ë‹ˆí„°ë§
   - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì 
   - ì •í™•ë„ ì§€ì†ì  ê²€ì¦

## ğŸ“š ë§ˆë¬´ë¦¬

YOLO v10ì€ ì´ì „ ë²„ì „ ëŒ€ë¹„ ë›°ì–´ë‚œ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤. íŠ¹íˆ ì •í™•ë„ì™€ ì†ë„ì˜ ê· í˜• ë©´ì—ì„œ í° ë°œì „ì„ ì´ë£¨ì—ˆìœ¼ë©°, ë‹¤ì–‘í•œ ì‹¤ì‹œê°„ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ í™œìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.

**í•µì‹¬ í¬ì¸íŠ¸:**
- ëª¨ë¸ í¬ê¸°ë³„ë¡œ ëª…í™•í•œ ì„±ëŠ¥ ì°¨ì´ ì¡´ì¬
- ì‹¤ì‹œê°„ ì²˜ë¦¬ë¥¼ ìœ„í•´ì„œëŠ” nano/small ëª¨ë¸ ê¶Œì¥
- ë°°ì¹˜ ì²˜ë¦¬ ì‹œ ì²˜ë¦¬ëŸ‰ í¬ê²Œ í–¥ìƒ
- ì ì ˆí•œ ìµœì í™”ë¥¼ í†µí•´ ì¶”ê°€ ì„±ëŠ¥ í–¥ìƒ ê°€ëŠ¥

ì‹¤ì œ í”„ë¡œì íŠ¸ì— ì ìš©í•  ë•ŒëŠ” ìš”êµ¬ì‚¬í•­ì— ë§ëŠ” ëª¨ë¸ì„ ì„ íƒí•˜ê³ , ì§€ì†ì ì¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ì„ í†µí•´ ìµœì ì˜ ì„±ëŠ¥ì„ ìœ ì§€í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.

---

*ë³¸ í¬ìŠ¤íŠ¸ì˜ ëª¨ë“  ì½”ë“œì™€ ê²°ê³¼ëŠ” ì‹¤ì œ í…ŒìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤. í™˜ê²½ì— ë”°ë¼ ê²°ê³¼ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë‹ˆ ì°¸ê³ ìš©ìœ¼ë¡œ í™œìš©í•´ ì£¼ì„¸ìš”.*
