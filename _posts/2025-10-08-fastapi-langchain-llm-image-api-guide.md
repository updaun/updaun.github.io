---
layout: post
title: "FastAPI + LangChainìœ¼ë¡œ LLM ì´ë¯¸ì§€ ì§ˆë¬¸ API êµ¬ì¶•í•˜ê¸°: ì™„ì „ ê°€ì´ë“œ"
date: 2025-10-08 10:00:00 +0900
categories: [FastAPI, LangChain, LLM, Computer-Vision]
tags: [FastAPI, LangChain, OpenAI, GPT-4V, Vision, API-Design, Python, Machine-Learning]
author: "updaun"
image: "/assets/img/posts/2025-10-08-fastapi-langchain-llm-image-api-guide.webp"
---

ë©€í‹°ëª¨ë‹¬ AIì˜ ë°œì „ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ì´í•´í•˜ê³  ë¶„ì„í•  ìˆ˜ ìˆëŠ” LLMì´ ë“±ì¥í–ˆìŠµë‹ˆë‹¤. ì´ ê¸€ì—ì„œëŠ” FastAPIì™€ LangChainì„ í™œìš©í•˜ì—¬ ì´ë¯¸ì§€ì— ëŒ€í•´ ì§ˆë¬¸í•˜ê³  ë‹µë³€ì„ ë°›ì„ ìˆ˜ ìˆëŠ” ê°•ë ¥í•œ APIë¥¼ ë‹¨ê³„ë³„ë¡œ êµ¬ì¶•í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.

## ğŸ¯ í”„ë¡œì íŠ¸ ê°œìš”

### ëª©í‘œ
- ì´ë¯¸ì§€ ì—…ë¡œë“œ ë° ì§ˆë¬¸ ì²˜ë¦¬ê°€ ê°€ëŠ¥í•œ REST API êµ¬ì¶•
- GPT-4V ë˜ëŠ” ë‹¤ë¥¸ ë©€í‹°ëª¨ë‹¬ LLM í™œìš©
- í™•ì¥ ê°€ëŠ¥í•˜ê³  ìœ ì§€ë³´ìˆ˜ê°€ ìš©ì´í•œ ì•„í‚¤í…ì²˜ ì„¤ê³„
- ì—ëŸ¬ ì²˜ë¦¬ ë° ë¡œê¹… ì‹œìŠ¤í…œ êµ¬í˜„

### ê¸°ìˆ  ìŠ¤íƒ
- **FastAPI**: ê³ ì„±ëŠ¥ ì›¹ í”„ë ˆì„ì›Œí¬
- **LangChain**: LLM í†µí•© ë° ì²´ì¸ ê´€ë¦¬
- **OpenAI GPT-4V**: ë©€í‹°ëª¨ë‹¬ ì–¸ì–´ ëª¨ë¸
- **Pydantic**: ë°ì´í„° ê²€ì¦ ë° ì§ë ¬í™”
- **Pillow**: ì´ë¯¸ì§€ ì²˜ë¦¬
- **python-multipart**: íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬

## ğŸ“‹ Step 1: í”„ë¡œì íŠ¸ ì„¤ì • ë° ì˜ì¡´ì„± ì„¤ì¹˜

### 1.1 í”„ë¡œì íŠ¸ êµ¬ì¡° ìƒì„±

```bash
mkdir fastapi-llm-image-api
cd fastapi-llm-image-api

# ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# í”„ë¡œì íŠ¸ êµ¬ì¡° ìƒì„±
mkdir -p {app/{api,core,models,services,utils},uploads,logs}
touch app/__init__.py app/api/__init__.py app/core/__init__.py
touch app/models/__init__.py app/services/__init__.py app/utils/__init__.py
```

### 1.2 í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
# requirements.txt ìƒì„±
cat > requirements.txt << EOF
fastapi==0.104.1
uvicorn[standard]==0.24.0
langchain==0.0.350
langchain-openai==0.0.2
python-multipart==0.0.6
pillow==10.1.0
pydantic==2.5.0
python-dotenv==1.0.0
aiofiles==23.2.1
httpx==0.25.2
pytest==7.4.3
pytest-asyncio==0.21.1
EOF

# íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt
```

### 1.3 í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

```bash
# .env íŒŒì¼ ìƒì„±
cat > .env << EOF
OPENAI_API_KEY=your_openai_api_key_here
MAX_FILE_SIZE=10485760  # 10MB
ALLOWED_EXTENSIONS=jpg,jpeg,png,gif,bmp,webp
LOG_LEVEL=INFO
EOF
```

## ğŸ“‹ Step 2: í•µì‹¬ ì„¤ì • ë° ëª¨ë¸ ì •ì˜

### 2.1 ì„¤ì • ê´€ë¦¬ì êµ¬í˜„

```python
# app/core/config.py
from pydantic_settings import BaseSettings
from typing import List
import os

class Settings(BaseSettings):
    # API ì„¤ì •
    app_name: str = "FastAPI LLM Image API"
    debug: bool = False
    version: str = "1.0.0"
    
    # OpenAI ì„¤ì •
    openai_api_key: str
    
    # íŒŒì¼ ì—…ë¡œë“œ ì„¤ì •
    max_file_size: int = 10 * 1024 * 1024  # 10MB
    allowed_extensions: List[str] = ["jpg", "jpeg", "png", "gif", "bmp", "webp"]
    upload_path: str = "uploads"
    
    # ë¡œê¹… ì„¤ì •
    log_level: str = "INFO"
    log_file: str = "logs/app.log"
    
    class Config:
        env_file = ".env"

settings = Settings()

# ì—…ë¡œë“œ ë””ë ‰í† ë¦¬ ìƒì„±
os.makedirs(settings.upload_path, exist_ok=True)
os.makedirs("logs", exist_ok=True)
```

### 2.2 Pydantic ëª¨ë¸ ì •ì˜

```python
# app/models/schemas.py
from pydantic import BaseModel, Field, validator
from typing import Optional, List, Dict, Any
from datetime import datetime
import base64

class ImageAnalysisRequest(BaseModel):
    """ì´ë¯¸ì§€ ë¶„ì„ ìš”ì²­ ëª¨ë¸"""
    question: str = Field(..., min_length=1, max_length=1000, description="ì´ë¯¸ì§€ì— ëŒ€í•œ ì§ˆë¬¸")
    image_base64: Optional[str] = Field(None, description="Base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€")
    
    @validator('question')
    def validate_question(cls, v):
        if not v.strip():
            raise ValueError("ì§ˆë¬¸ì€ ë¹„ì–´ìˆì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return v.strip()

class ImageAnalysisResponse(BaseModel):
    """ì´ë¯¸ì§€ ë¶„ì„ ì‘ë‹µ ëª¨ë¸"""
    success: bool
    answer: str
    confidence: Optional[float] = None
    processing_time: float
    timestamp: datetime
    metadata: Optional[Dict[str, Any]] = None

class ErrorResponse(BaseModel):
    """ì—ëŸ¬ ì‘ë‹µ ëª¨ë¸"""
    success: bool = False
    error: str
    error_code: str
    timestamp: datetime

class HealthCheck(BaseModel):
    """í—¬ìŠ¤ì²´í¬ ì‘ë‹µ ëª¨ë¸"""
    status: str
    timestamp: datetime
    version: str
```

## ğŸ“‹ Step 3: LangChain ì„œë¹„ìŠ¤ êµ¬í˜„

### 3.1 ì´ë¯¸ì§€ ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹°

```python
# app/utils/image_utils.py
from PIL import Image
import base64
import io
from typing import Tuple, Optional
import logging

logger = logging.getLogger(__name__)

class ImageProcessor:
    """ì´ë¯¸ì§€ ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤"""
    
    @staticmethod
    def validate_image(file_content: bytes, max_size: int) -> Tuple[bool, Optional[str]]:
        """ì´ë¯¸ì§€ íŒŒì¼ ê²€ì¦"""
        try:
            if len(file_content) > max_size:
                return False, f"íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. ìµœëŒ€ {max_size // 1024 // 1024}MBê¹Œì§€ í—ˆìš©ë©ë‹ˆë‹¤."
            
            # PILë¡œ ì´ë¯¸ì§€ ì—´ê¸° ì‹œë„
            image = Image.open(io.BytesIO(file_content))
            image.verify()  # ì´ë¯¸ì§€ ë¬´ê²°ì„± ê²€ì¦
            
            return True, None
            
        except Exception as e:
            logger.error(f"ì´ë¯¸ì§€ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False, "ìœ íš¨í•˜ì§€ ì•Šì€ ì´ë¯¸ì§€ íŒŒì¼ì…ë‹ˆë‹¤."
    
    @staticmethod
    def resize_image(image_content: bytes, max_width: int = 1024, max_height: int = 1024) -> bytes:
        """ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •"""
        try:
            image = Image.open(io.BytesIO(image_content))
            
            # RGBA ì´ë¯¸ì§€ë¥¼ RGBë¡œ ë³€í™˜ (JPEG ì €ì¥ì„ ìœ„í•´)
            if image.mode in ('RGBA', 'LA'):
                background = Image.new('RGB', image.size, (255, 255, 255))
                background.paste(image, mask=image.split()[-1] if image.mode == 'RGBA' else None)
                image = background
            
            # í¬ê¸° ì¡°ì •
            image.thumbnail((max_width, max_height), Image.Resampling.LANCZOS)
            
            # ë°”ì´íŠ¸ë¡œ ë³€í™˜
            output = io.BytesIO()
            image.save(output, format='JPEG', quality=85)
            return output.getvalue()
            
        except Exception as e:
            logger.error(f"ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • ì‹¤íŒ¨: {e}")
            raise
    
    @staticmethod
    def image_to_base64(image_content: bytes) -> str:
        """ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©"""
        return base64.b64encode(image_content).decode('utf-8')
```

### 3.2 LangChain LLM ì„œë¹„ìŠ¤

```python
# app/services/llm_service.py
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage
from langchain.callbacks import get_openai_callback
import logging
import time
from typing import Dict, Any, Optional
import base64

logger = logging.getLogger(__name__)

class LLMImageService:
    """LLMì„ í™œìš©í•œ ì´ë¯¸ì§€ ë¶„ì„ ì„œë¹„ìŠ¤"""
    
    def __init__(self, api_key: str, model_name: str = "gpt-4-vision-preview"):
        self.model = ChatOpenAI(
            model=model_name,
            openai_api_key=api_key,
            max_tokens=500,
            temperature=0.1
        )
    
    async def analyze_image(self, image_base64: str, question: str) -> Dict[str, Any]:
        """ì´ë¯¸ì§€ ë¶„ì„ ìˆ˜í–‰"""
        start_time = time.time()
        
        try:
            # ë©”ì‹œì§€ êµ¬ì„±
            message = HumanMessage(
                content=[
                    {
                        "type": "text",
                        "text": f"ë‹¤ìŒ ì´ë¯¸ì§€ë¥¼ ë³´ê³  ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”: {question}"
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{image_base64}"
                        }
                    }
                ]
            )
            
            # LLM í˜¸ì¶œ
            with get_openai_callback() as cb:
                response = await self.model.ainvoke([message])
                
            processing_time = time.time() - start_time
            
            return {
                "answer": response.content,
                "processing_time": processing_time,
                "token_usage": {
                    "total_tokens": cb.total_tokens,
                    "prompt_tokens": cb.prompt_tokens,
                    "completion_tokens": cb.completion_tokens,
                    "total_cost": cb.total_cost
                }
            }
            
        except Exception as e:
            logger.error(f"LLM ë¶„ì„ ì‹¤íŒ¨: {e}")
            raise
    
    async def analyze_image_with_context(
        self, 
        image_base64: str, 
        question: str, 
        context: Optional[str] = None
    ) -> Dict[str, Any]:
        """ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ ì´ë¯¸ì§€ ë¶„ì„"""
        start_time = time.time()
        
        try:
            # ì»¨í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ê²½ìš° ì§ˆë¬¸ì— í¬í•¨
            enhanced_question = question
            if context:
                enhanced_question = f"ì»¨í…ìŠ¤íŠ¸: {context}\n\nì§ˆë¬¸: {question}"
            
            message = HumanMessage(
                content=[
                    {
                        "type": "text",
                        "text": f"""ë‹¤ìŒ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê³  ì§ˆë¬¸ì— ëŒ€í•´ ìƒì„¸íˆ ë‹µë³€í•´ì£¼ì„¸ìš”.

{enhanced_question}

ë‹µë³€ ì‹œ ë‹¤ìŒ ì‚¬í•­ì„ ê³ ë ¤í•´ì£¼ì„¸ìš”:
1. ì´ë¯¸ì§€ì—ì„œ ê´€ì°°ë˜ëŠ” ì£¼ìš” ìš”ì†Œë“¤
2. ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ êµ¬ì²´ì ì¸ ì •ë³´
3. ê°€ëŠ¥í•œ í•œ ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ ì œê³µ"""
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{image_base64}"
                        }
                    }
                ]
            )
            
            with get_openai_callback() as cb:
                response = await self.model.ainvoke([message])
                
            processing_time = time.time() - start_time
            
            return {
                "answer": response.content,
                "processing_time": processing_time,
                "token_usage": {
                    "total_tokens": cb.total_tokens,
                    "prompt_tokens": cb.prompt_tokens,
                    "completion_tokens": cb.completion_tokens,
                    "total_cost": cb.total_cost
                }
            }
            
        except Exception as e:
            logger.error(f"ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ LLM ë¶„ì„ ì‹¤íŒ¨: {e}")
            raise
```

## ğŸ“‹ Step 4: FastAPI ë¼ìš°í„° êµ¬í˜„

### 4.1 ì—ëŸ¬ í•¸ë“¤ëŸ¬ ë° ë¯¸ë“¤ì›¨ì–´

```python
# app/core/exceptions.py
from fastapi import HTTPException
from typing import Any, Dict, Optional

class ImageProcessingError(HTTPException):
    def __init__(self, detail: str, status_code: int = 400):
        super().__init__(status_code=status_code, detail=detail)

class LLMServiceError(HTTPException):
    def __init__(self, detail: str, status_code: int = 500):
        super().__init__(status_code=status_code, detail=detail)

class FileTooLargeError(ImageProcessingError):
    def __init__(self, max_size: int):
        super().__init__(f"íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. ìµœëŒ€ {max_size // 1024 // 1024}MBê¹Œì§€ í—ˆìš©ë©ë‹ˆë‹¤.")

class InvalidImageError(ImageProcessingError):
    def __init__(self, detail: str = "ìœ íš¨í•˜ì§€ ì•Šì€ ì´ë¯¸ì§€ íŒŒì¼ì…ë‹ˆë‹¤."):
        super().__init__(detail)
```

### 4.2 ë©”ì¸ API ë¼ìš°í„°

```python
# app/api/image_analysis.py
from fastapi import APIRouter, UploadFile, File, Form, HTTPException, Depends
from fastapi.responses import JSONResponse
import aiofiles
import os
from datetime import datetime
from typing import Optional
import logging

from app.models.schemas import ImageAnalysisResponse, ErrorResponse
from app.services.llm_service import LLMImageService
from app.utils.image_utils import ImageProcessor
from app.core.config import settings
from app.core.exceptions import ImageProcessingError, LLMServiceError

router = APIRouter()
logger = logging.getLogger(__name__)

# LLM ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
llm_service = LLMImageService(api_key=settings.openai_api_key)

@router.post("/analyze", response_model=ImageAnalysisResponse)
async def analyze_image(
    file: UploadFile = File(..., description="ë¶„ì„í•  ì´ë¯¸ì§€ íŒŒì¼"),
    question: str = Form(..., description="ì´ë¯¸ì§€ì— ëŒ€í•œ ì§ˆë¬¸")
):
    """ì´ë¯¸ì§€ ì—…ë¡œë“œ ë° ì§ˆë¬¸ ë¶„ì„ API"""
    start_time = datetime.now()
    
    try:
        # íŒŒì¼ í™•ì¥ì ê²€ì¦
        file_extension = file.filename.split('.')[-1].lower()
        if file_extension not in settings.allowed_extensions:
            raise ImageProcessingError(
                f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. í—ˆìš©ëœ í˜•ì‹: {', '.join(settings.allowed_extensions)}"
            )
        
        # íŒŒì¼ ë‚´ìš© ì½ê¸°
        file_content = await file.read()
        
        # íŒŒì¼ í¬ê¸° ë° ìœ íš¨ì„± ê²€ì¦
        is_valid, error_msg = ImageProcessor.validate_image(file_content, settings.max_file_size)
        if not is_valid:
            raise ImageProcessingError(error_msg)
        
        # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
        processed_image = ImageProcessor.resize_image(file_content)
        
        # Base64 ì¸ì½”ë”©
        image_base64 = ImageProcessor.image_to_base64(processed_image)
        
        # LLM ë¶„ì„ ìˆ˜í–‰
        result = await llm_service.analyze_image(image_base64, question)
        
        processing_time = (datetime.now() - start_time).total_seconds()
        
        return ImageAnalysisResponse(
            success=True,
            answer=result["answer"],
            processing_time=processing_time,
            timestamp=datetime.now(),
            metadata={
                "file_name": file.filename,
                "file_size": len(file_content),
                "token_usage": result.get("token_usage")
            }
        )
        
    except ImageProcessingError as e:
        logger.error(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì—ëŸ¬: {e.detail}")
        raise e
    except Exception as e:
        logger.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬: {str(e)}")
        raise LLMServiceError("ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

@router.post("/analyze-with-context", response_model=ImageAnalysisResponse)
async def analyze_image_with_context(
    file: UploadFile = File(..., description="ë¶„ì„í•  ì´ë¯¸ì§€ íŒŒì¼"),
    question: str = Form(..., description="ì´ë¯¸ì§€ì— ëŒ€í•œ ì§ˆë¬¸"),
    context: Optional[str] = Form(None, description="ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ì •ë³´")
):
    """ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ ì´ë¯¸ì§€ ë¶„ì„ API"""
    start_time = datetime.now()
    
    try:
        # ê¸°ë³¸ ê²€ì¦ ë¡œì§ (ìœ„ì™€ ë™ì¼)
        file_extension = file.filename.split('.')[-1].lower()
        if file_extension not in settings.allowed_extensions:
            raise ImageProcessingError(
                f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. í—ˆìš©ëœ í˜•ì‹: {', '.join(settings.allowed_extensions)}"
            )
        
        file_content = await file.read()
        is_valid, error_msg = ImageProcessor.validate_image(file_content, settings.max_file_size)
        if not is_valid:
            raise ImageProcessingError(error_msg)
        
        processed_image = ImageProcessor.resize_image(file_content)
        image_base64 = ImageProcessor.image_to_base64(processed_image)
        
        # ì»¨í…ìŠ¤íŠ¸ í¬í•¨ ë¶„ì„
        result = await llm_service.analyze_image_with_context(image_base64, question, context)
        
        processing_time = (datetime.now() - start_time).total_seconds()
        
        return ImageAnalysisResponse(
            success=True,
            answer=result["answer"],
            processing_time=processing_time,
            timestamp=datetime.now(),
            metadata={
                "file_name": file.filename,
                "file_size": len(file_content),
                "context_provided": context is not None,
                "token_usage": result.get("token_usage")
            }
        )
        
    except ImageProcessingError as e:
        logger.error(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì—ëŸ¬: {e.detail}")
        raise e
    except Exception as e:
        logger.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬: {str(e)}")
        raise LLMServiceError("ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
```

## ğŸ“‹ Step 5: ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ë° ì„¤ì •

### 5.1 ë¡œê¹… ì„¤ì •

```python
# app/core/logging.py
import logging
import sys
from pathlib import Path
from app.core.config import settings

def setup_logging():
    """ë¡œê¹… ì„¤ì •"""
    # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
    log_file = Path(settings.log_file)
    log_file.parent.mkdir(exist_ok=True)
    
    # ë¡œê¹… í¬ë§·
    log_format = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    
    # ê¸°ë³¸ ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=getattr(logging, settings.log_level),
        format=log_format,
        handlers=[
            logging.FileHandler(settings.log_file),
            logging.StreamHandler(sys.stdout)
        ]
    )
    
    # ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œê·¸ ë ˆë²¨ ì¡°ì •
    logging.getLogger("uvicorn").setLevel(logging.INFO)
    logging.getLogger("httpx").setLevel(logging.WARNING)
```

### 5.2 ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜

```python
# app/main.py
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from datetime import datetime
import logging

from app.core.config import settings
from app.core.logging import setup_logging
from app.core.exceptions import ImageProcessingError, LLMServiceError
from app.api import image_analysis
from app.models.schemas import HealthCheck, ErrorResponse

# ë¡œê¹… ì„¤ì •
setup_logging()
logger = logging.getLogger(__name__)

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title=settings.app_name,
    version=settings.version,
    description="FastAPIì™€ LangChainì„ í™œìš©í•œ LLM ì´ë¯¸ì§€ ì§ˆë¬¸ API",
    debug=settings.debug
)

# CORS ë¯¸ë“¤ì›¨ì–´ ì¶”ê°€
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # í”„ë¡œë•ì…˜ì—ì„œëŠ” íŠ¹ì • ë„ë©”ì¸ìœ¼ë¡œ ì œí•œ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ë¼ìš°í„° ë“±ë¡
app.include_router(image_analysis.router, prefix="/api/v1/image", tags=["Image Analysis"])

# ì „ì—­ ì˜ˆì™¸ í•¸ë“¤ëŸ¬
@app.exception_handler(ImageProcessingError)
async def image_processing_exception_handler(request, exc):
    return JSONResponse(
        status_code=exc.status_code,
        content=ErrorResponse(
            error=exc.detail,
            error_code="IMAGE_PROCESSING_ERROR",
            timestamp=datetime.now()
        ).dict()
    )

@app.exception_handler(LLMServiceError)
async def llm_service_exception_handler(request, exc):
    return JSONResponse(
        status_code=exc.status_code,
        content=ErrorResponse(
            error=exc.detail,
            error_code="LLM_SERVICE_ERROR",
            timestamp=datetime.now()
        ).dict()
    )

@app.exception_handler(Exception)
async def global_exception_handler(request, exc):
    logger.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬: {str(exc)}")
    return JSONResponse(
        status_code=500,
        content=ErrorResponse(
            error="ë‚´ë¶€ ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            error_code="INTERNAL_SERVER_ERROR",
            timestamp=datetime.now()
        ).dict()
    )

# í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸
@app.get("/health", response_model=HealthCheck)
async def health_check():
    """API í—¬ìŠ¤ì²´í¬"""
    return HealthCheck(
        status="healthy",
        timestamp=datetime.now(),
        version=settings.version
    )

@app.get("/")
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "message": "FastAPI LLM Image API",
        "version": settings.version,
        "docs": "/docs",
        "health": "/health"
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "app.main:app",
        host="0.0.0.0",
        port=8000,
        reload=settings.debug,
        log_level=settings.log_level.lower()
    )
```

## ğŸ“‹ Step 6: í…ŒìŠ¤íŠ¸ ì½”ë“œ ì‘ì„±

### 6.1 ë‹¨ìœ„ í…ŒìŠ¤íŠ¸

```python
# tests/test_image_utils.py
import pytest
import io
from PIL import Image
from app.utils.image_utils import ImageProcessor

class TestImageProcessor:
    
    def create_test_image(self, format="JPEG", size=(100, 100)):
        """í…ŒìŠ¤íŠ¸ìš© ì´ë¯¸ì§€ ìƒì„±"""
        image = Image.new('RGB', size, color='red')
        img_bytes = io.BytesIO()
        image.save(img_bytes, format=format)
        return img_bytes.getvalue()
    
    def test_validate_image_success(self):
        """ìœ íš¨í•œ ì´ë¯¸ì§€ ê²€ì¦ í…ŒìŠ¤íŠ¸"""
        image_content = self.create_test_image()
        is_valid, error = ImageProcessor.validate_image(image_content, 10 * 1024 * 1024)
        assert is_valid is True
        assert error is None
    
    def test_validate_image_too_large(self):
        """í° ì´ë¯¸ì§€ ê²€ì¦ í…ŒìŠ¤íŠ¸"""
        image_content = self.create_test_image()
        is_valid, error = ImageProcessor.validate_image(image_content, 100)  # 100 bytes ì œí•œ
        assert is_valid is False
        assert "íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤" in error
    
    def test_resize_image(self):
        """ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • í…ŒìŠ¤íŠ¸"""
        original_image = self.create_test_image(size=(2000, 2000))
        resized_image = ImageProcessor.resize_image(original_image, 1024, 1024)
        
        # í¬ê¸°ê°€ ì¤„ì–´ë“¤ì—ˆëŠ”ì§€ í™•ì¸
        assert len(resized_image) < len(original_image)
        
        # ì´ë¯¸ì§€ê°€ ì—¬ì „íˆ ìœ íš¨í•œì§€ í™•ì¸
        resized_pil = Image.open(io.BytesIO(resized_image))
        assert resized_pil.size[0] <= 1024
        assert resized_pil.size[1] <= 1024
```

### 6.2 í†µí•© í…ŒìŠ¤íŠ¸

```python
# tests/test_api.py
import pytest
from fastapi.testclient import TestClient
from app.main import app
import io
from PIL import Image

client = TestClient(app)

class TestImageAnalysisAPI:
    
    def create_test_image_file(self):
        """í…ŒìŠ¤íŠ¸ìš© ì´ë¯¸ì§€ íŒŒì¼ ìƒì„±"""
        image = Image.new('RGB', (100, 100), color='blue')
        img_bytes = io.BytesIO()
        image.save(img_bytes, format='JPEG')
        img_bytes.seek(0)
        return img_bytes
    
    def test_health_check(self):
        """í—¬ìŠ¤ì²´í¬ í…ŒìŠ¤íŠ¸"""
        response = client.get("/health")
        assert response.status_code == 200
        data = response.json()
        assert data["status"] == "healthy"
    
    @pytest.mark.asyncio
    async def test_analyze_image_success(self):
        """ì´ë¯¸ì§€ ë¶„ì„ ì„±ê³µ í…ŒìŠ¤íŠ¸"""
        image_file = self.create_test_image_file()
        
        response = client.post(
            "/api/v1/image/analyze",
            files={"file": ("test.jpg", image_file, "image/jpeg")},
            data={"question": "ì´ ì´ë¯¸ì§€ì— ë¬´ì—‡ì´ ë³´ì´ë‚˜ìš”?"}
        )
        
        # OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì€ ê²½ìš° ìŠ¤í‚µ
        if response.status_code == 500:
            pytest.skip("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
        
        assert response.status_code == 200
        data = response.json()
        assert data["success"] is True
        assert "answer" in data
    
    def test_analyze_image_invalid_format(self):
        """ì˜ëª»ëœ í˜•ì‹ íŒŒì¼ í…ŒìŠ¤íŠ¸"""
        response = client.post(
            "/api/v1/image/analyze",
            files={"file": ("test.txt", io.StringIO("not an image"), "text/plain")},
            data={"question": "ì´ ì´ë¯¸ì§€ì— ë¬´ì—‡ì´ ë³´ì´ë‚˜ìš”?"}
        )
        
        assert response.status_code == 400
        data = response.json()
        assert data["success"] is False
```

## ğŸ“‹ Step 7: ì‹¤í–‰ ë° ë°°í¬

### 7.1 ë¡œì»¬ ì‹¤í–‰

```bash
# ê°œë°œ ì„œë²„ ì‹¤í–‰
python -m app.main

# ë˜ëŠ” uvicorn ì§ì ‘ ì‹¤í–‰
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

### 7.2 Docker ë°°í¬

```dockerfile
# Dockerfile
FROM python:3.11-slim

WORKDIR /app

# ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
RUN apt-get update && apt-get install -y \
    gcc \
    && rm -rf /var/lib/apt/lists/*

# Python ì˜ì¡´ì„± ì„¤ì¹˜
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œ ë³µì‚¬
COPY . .

# í¬íŠ¸ ë…¸ì¶œ
EXPOSE 8000

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

```yaml
# docker-compose.yml
version: '3.8'

services:
  fastapi-llm-api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - LOG_LEVEL=INFO
    volumes:
      - ./uploads:/app/uploads
      - ./logs:/app/logs
    restart: unless-stopped
```

### 7.3 API í…ŒìŠ¤íŠ¸

```bash
# í—¬ìŠ¤ì²´í¬
curl -X GET "http://localhost:8000/health"

# ì´ë¯¸ì§€ ë¶„ì„ í…ŒìŠ¤íŠ¸
curl -X POST "http://localhost:8000/api/v1/image/analyze" \
  -F "file=@test_image.jpg" \
  -F "question=ì´ ì´ë¯¸ì§€ì—ì„œ ë¬´ì—‡ì„ ë³¼ ìˆ˜ ìˆë‚˜ìš”?"
```

## ğŸš€ ì¶”ê°€ ê¸°ëŠ¥ êµ¬í˜„ ì•„ì´ë””ì–´

### 1. ìºì‹± ì‹œìŠ¤í…œ
```python
# Redisë¥¼ í™œìš©í•œ ê²°ê³¼ ìºì‹±
import redis
import hashlib
import json

class CacheService:
    def __init__(self, redis_url: str):
        self.redis_client = redis.from_url(redis_url)
    
    def generate_cache_key(self, image_base64: str, question: str) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        content = f"{image_base64}:{question}"
        return hashlib.md5(content.encode()).hexdigest()
    
    async def get_cached_result(self, cache_key: str) -> Optional[Dict]:
        """ìºì‹œëœ ê²°ê³¼ ì¡°íšŒ"""
        try:
            cached = self.redis_client.get(cache_key)
            return json.loads(cached) if cached else None
        except Exception:
            return None
    
    async def cache_result(self, cache_key: str, result: Dict, ttl: int = 3600):
        """ê²°ê³¼ ìºì‹±"""
        try:
            self.redis_client.setex(cache_key, ttl, json.dumps(result))
        except Exception:
            pass  # ìºì‹± ì‹¤íŒ¨ëŠ” ë¬´ì‹œ
```

### 2. ë°°ì¹˜ ì²˜ë¦¬ ì§€ì›
```python
# ì—¬ëŸ¬ ì´ë¯¸ì§€ ë™ì‹œ ì²˜ë¦¬
@router.post("/analyze-batch")
async def analyze_batch_images(
    files: List[UploadFile] = File(...),
    questions: List[str] = Form(...)
):
    """ë°°ì¹˜ ì´ë¯¸ì§€ ë¶„ì„"""
    tasks = []
    for file, question in zip(files, questions):
        task = analyze_single_image(file, question)
        tasks.append(task)
    
    results = await asyncio.gather(*tasks, return_exceptions=True)
    return {"results": results}
```

### 3. ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
```python
# ì‹¤ì‹œê°„ ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë°
from fastapi.responses import StreamingResponse

@router.post("/analyze-stream")
async def analyze_image_stream(file: UploadFile, question: str):
    """ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µìœ¼ë¡œ ì´ë¯¸ì§€ ë¶„ì„"""
    async def generate_response():
        # ì´ë¯¸ì§€ ì²˜ë¦¬
        yield "data: {'status': 'processing_image'}\n\n"
        
        # LLM í˜¸ì¶œ ë° ìŠ¤íŠ¸ë¦¬ë°
        yield "data: {'status': 'analyzing'}\n\n"
        
        # ìµœì¢… ê²°ê³¼
        yield f"data: {json.dumps(result)}\n\n"
    
    return StreamingResponse(
        generate_response(),
        media_type="text/plain"
    )
```

## ğŸ›¡ï¸ ë³´ì•ˆ ë° ìµœì í™” ê³ ë ¤ì‚¬í•­

### 1. ë³´ì•ˆ ê°•í™”
- API í‚¤ ê´€ë¦¬ ë° ì¸ì¦ ì‹œìŠ¤í…œ êµ¬í˜„
- íŒŒì¼ ì—…ë¡œë“œ ë³´ì•ˆ ê²€ì¦ ê°•í™”
- Rate limiting ì ìš©
- Input sanitization

### 2. ì„±ëŠ¥ ìµœì í™”
- ì´ë¯¸ì§€ ì••ì¶• ë° ìµœì í™”
- ë¹„ë™ê¸° ì²˜ë¦¬ í™œìš©
- ì»¤ë„¥ì…˜ í’€ë§
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§

### 3. ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…
- Prometheus ë©”íŠ¸ë¦­ ìˆ˜ì§‘
- êµ¬ì¡°í™”ëœ ë¡œê¹…
- ì—ëŸ¬ ì¶”ì  ì‹œìŠ¤í…œ
- ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

## ğŸ“ ë§ˆë¬´ë¦¬

ì´ ê°€ì´ë“œë¥¼ í†µí•´ FastAPIì™€ LangChainì„ í™œìš©í•œ ê°•ë ¥í•œ ì´ë¯¸ì§€ ì§ˆë¬¸ APIë¥¼ êµ¬ì¶•í–ˆìŠµë‹ˆë‹¤. í•µì‹¬ í¬ì¸íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

1. **ëª¨ë“ˆí™”ëœ ì•„í‚¤í…ì²˜**: ê° ê¸°ëŠ¥ë³„ë¡œ ë¶„ë¦¬ëœ êµ¬ì¡°ë¡œ ìœ ì§€ë³´ìˆ˜ì„± í–¥ìƒ
2. **ê²¬ê³ í•œ ì—ëŸ¬ ì²˜ë¦¬**: ë‹¤ì–‘í•œ ì˜ˆì™¸ ìƒí™©ì— ëŒ€í•œ ì ì ˆí•œ ì²˜ë¦¬
3. **í™•ì¥ ê°€ëŠ¥í•œ ì„¤ê³„**: ìƒˆë¡œìš´ ê¸°ëŠ¥ ì¶”ê°€ê°€ ìš©ì´í•œ êµ¬ì¡°
4. **í…ŒìŠ¤íŠ¸ ì½”ë“œ**: ì•ˆì •ì ì¸ ì„œë¹„ìŠ¤ ìš´ì˜ì„ ìœ„í•œ í…ŒìŠ¤íŠ¸ í™˜ê²½

ì´ì œ ì—¬ëŸ¬ë¶„ë§Œì˜ ì°½ì˜ì ì¸ ì´ë¯¸ì§€ ë¶„ì„ ì„œë¹„ìŠ¤ë¥¼ êµ¬ì¶•í•´ë³´ì„¸ìš”! ğŸ¯