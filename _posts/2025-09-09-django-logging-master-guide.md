---
layout: post
title: "Django ë¡œê·¸ ë§ˆìŠ¤í„°í•˜ê¸°: ê¸°ì´ˆë¶€í„° ì „ë¬¸ê°€ ìˆ˜ì¤€ê¹Œì§€"
date: 2025-09-09 10:00:00 +0900
categories: [Django, Python, DevOps, Monitoring]
tags: [Django, Python, Logging, Monitoring, Debugging, Production, Performance]
---

Django ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìš´ì˜í•˜ë©´ì„œ ë¡œê·¸ë§Œí¼ ì¤‘ìš”í•œ ê²ƒì€ ì—†ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ë§ì€ ê°œë°œìë“¤ì´ ë¡œê·¸ì˜ ì§„ì •í•œ ê°€ì¹˜ë¥¼ ëª¨ë¥´ê±°ë‚˜, ë‹¨ìˆœí•œ print ë¬¸ìœ¼ë¡œ ë””ë²„ê¹…ì„ ëë‚´ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. ì´ ê¸€ì—ì„œëŠ” Django ë¡œê·¸ì˜ ì¤‘ìš”ì„±ë¶€í„° ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ ë¡œê·¸ ì‹œìŠ¤í…œ êµ¬ì¶•ê¹Œì§€ ë‹¨ê³„ë³„ë¡œ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.

## ğŸ¯ ë¡œê·¸ê°€ ì¤‘ìš”í•œ ì´ìœ 

### 1. ì¥ì•  ëŒ€ì‘ì˜ í•µì‹¬

```python
# ë¡œê·¸ ì—†ì´ ì¥ì•  ìƒí™©
def transfer_money(from_account, to_account, amount):
    try:
        # ë³µì¡í•œ ê¸ˆìœµ ë¡œì§...
        result = process_transfer(from_account, to_account, amount)
        return result
    except Exception as e:
        # ë¬´ì—‡ì´ ì˜ëª»ë˜ì—ˆëŠ”ì§€ ì•Œ ìˆ˜ ì—†ìŒ
        return {"error": "Transfer failed"}

# ì ì ˆí•œ ë¡œê·¸ê°€ ìˆëŠ” ê²½ìš°
import logging

logger = logging.getLogger(__name__)

def transfer_money(from_account, to_account, amount):
    logger.info(f"Transfer initiated: {from_account} -> {to_account}, amount: {amount}")
    
    try:
        # ê° ë‹¨ê³„ë³„ ë¡œê·¸
        logger.debug(f"Validating accounts: {from_account}, {to_account}")
        validate_accounts(from_account, to_account)
        
        logger.debug(f"Checking balance for account: {from_account}")
        if not check_sufficient_balance(from_account, amount):
            logger.warning(f"Insufficient balance: {from_account}, required: {amount}")
            return {"error": "Insufficient balance"}
        
        logger.info(f"Processing transfer: {amount}")
        result = process_transfer(from_account, to_account, amount)
        
        logger.info(f"Transfer completed successfully: {result['transaction_id']}")
        return result
        
    except ValidationError as e:
        logger.error(f"Validation failed: {e}, accounts: {from_account}, {to_account}")
        return {"error": "Invalid account"}
    except DatabaseError as e:
        logger.critical(f"Database error during transfer: {e}, rolling back")
        return {"error": "System error"}
    except Exception as e:
        logger.critical(f"Unexpected error: {e}, context: {locals()}")
        return {"error": "Transfer failed"}
```

### 2. ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ

```python
# ì‚¬ìš©ì í–‰ë™ ë¶„ì„ì„ ìœ„í•œ ë¡œê·¸
import structlog

# êµ¬ì¡°í™”ëœ ë¡œê±° ì„¤ì •
logger = structlog.get_logger()

def product_view(request, product_id):
    """ìƒí’ˆ ì¡°íšŒ ë¡œê·¸ - ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ì„ìš©"""
    
    logger.info(
        "product_viewed",
        user_id=request.user.id if request.user.is_authenticated else None,
        product_id=product_id,
        session_id=request.session.session_key,
        user_agent=request.META.get('HTTP_USER_AGENT'),
        referrer=request.META.get('HTTP_REFERER'),
        ip_address=get_client_ip(request),
        timestamp=timezone.now().isoformat(),
        # ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­
        product_category=product.category,
        product_price=float(product.price),
        is_mobile=is_mobile_request(request),
    )
    
    # ìƒí’ˆ ì¡°íšŒ ë¡œì§...
    return render(request, 'product.html', {'product': product})

def purchase_completed(request, order):
    """êµ¬ë§¤ ì™„ë£Œ ë¡œê·¸ - ë§¤ì¶œ ë¶„ì„ìš©"""
    
    logger.info(
        "purchase_completed",
        user_id=request.user.id,
        order_id=order.id,
        order_value=float(order.total_amount),
        payment_method=order.payment_method,
        products=[{
            'id': item.product.id,
            'name': item.product.name,
            'quantity': item.quantity,
            'price': float(item.price)
        } for item in order.items.all()],
        discount_applied=float(order.discount_amount) if order.discount_amount else 0,
        timestamp=timezone.now().isoformat(),
    )
```

### 3. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

```python
import time
import functools

def performance_log(func):
    """ì„±ëŠ¥ ì¸¡ì • ë°ì½”ë ˆì´í„°"""
    
    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        
        logger.info(f"Function {func.__name__} started", extra={
            'function': func.__name__,
            'args_count': len(args),
            'kwargs_count': len(kwargs),
        })
        
        try:
            result = func(*args, **kwargs)
            execution_time = time.time() - start_time
            
            logger.info(f"Function {func.__name__} completed", extra={
                'function': func.__name__,
                'execution_time': execution_time,
                'success': True,
            })
            
            # ì„±ëŠ¥ ì„ê³„ê°’ ì²´í¬
            if execution_time > 1.0:  # 1ì´ˆ ì´ìƒ
                logger.warning(f"Slow function detected: {func.__name__}", extra={
                    'function': func.__name__,
                    'execution_time': execution_time,
                    'threshold_exceeded': True,
                })
            
            return result
            
        except Exception as e:
            execution_time = time.time() - start_time
            logger.error(f"Function {func.__name__} failed", extra={
                'function': func.__name__,
                'execution_time': execution_time,
                'error': str(e),
                'success': False,
            })
            raise
    
    return wrapper

# ì‚¬ìš© ì˜ˆ
@performance_log
def complex_data_processing(data):
    # ë³µì¡í•œ ë°ì´í„° ì²˜ë¦¬...
    return processed_data
```

## ğŸ”§ ê¸°ì´ˆì ì¸ Django ë¡œê·¸ ì„¤ì •

### 1. ê¸°ë³¸ ë¡œê·¸ ì„¤ì •

```python
# settings.py - ê¸°ë³¸ ë¡œê·¸ ì„¤ì •

import os

LOGGING = {
    'version': 1,
    'disable_existing_loggers': False,
    
    # ë¡œê·¸ í¬ë§· ì •ì˜
    'formatters': {
        'verbose': {
            'format': '{levelname} {asctime} {module} {process:d} {thread:d} {message}',
            'style': '{',
        },
        'simple': {
            'format': '{levelname} {message}',
            'style': '{',
        },
        'json': {
            'format': '{"level": "%(levelname)s", "time": "%(asctime)s", "module": "%(module)s", "message": "%(message)s"}',
        },
    },
    
    # ë¡œê·¸ í•¸ë“¤ëŸ¬ ì •ì˜
    'handlers': {
        'console': {
            'class': 'logging.StreamHandler',
            'formatter': 'verbose',
        },
        'file': {
            'class': 'logging.FileHandler',
            'filename': os.path.join(BASE_DIR, 'logs', 'django.log'),
            'formatter': 'verbose',
        },
        'error_file': {
            'class': 'logging.FileHandler',
            'filename': os.path.join(BASE_DIR, 'logs', 'error.log'),
            'level': 'ERROR',
            'formatter': 'verbose',
        },
    },
    
    # ë£¨íŠ¸ ë¡œê±° ì„¤ì •
    'root': {
        'level': 'INFO',
        'handlers': ['console', 'file'],
    },
    
    # Django ê´€ë ¨ ë¡œê±°
    'loggers': {
        'django': {
            'handlers': ['console', 'file'],
            'level': 'INFO',
            'propagate': False,
        },
        'django.request': {
            'handlers': ['error_file'],
            'level': 'ERROR',
            'propagate': False,
        },
        'django.db.backends': {
            'handlers': ['console'],
            'level': 'DEBUG',
            'propagate': False,
        },
        # ì»¤ìŠ¤í…€ ì•± ë¡œê±°
        'myapp': {
            'handlers': ['console', 'file'],
            'level': 'DEBUG',
            'propagate': False,
        },
    },
}

# ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
import os
os.makedirs(os.path.join(BASE_DIR, 'logs'), exist_ok=True)
```

### 2. ë·°ì—ì„œ ë¡œê·¸ ì‚¬ìš©í•˜ê¸°

```python
# views.py - ê¸°ë³¸ì ì¸ ë¡œê·¸ ì‚¬ìš©

import logging
from django.shortcuts import render, get_object_or_404
from django.http import JsonResponse
from django.views.decorators.http import require_http_methods

# ë¡œê±° ìƒì„±
logger = logging.getLogger('myapp')

def user_profile(request, user_id):
    """ì‚¬ìš©ì í”„ë¡œí•„ ì¡°íšŒ"""
    
    logger.info(f"User profile requested for user_id: {user_id}")
    
    try:
        user = get_object_or_404(User, id=user_id)
        logger.debug(f"User found: {user.username}")
        
        return render(request, 'profile.html', {'user': user})
        
    except Exception as e:
        logger.error(f"Error retrieving user profile: {e}")
        return JsonResponse({'error': 'User not found'}, status=404)

@require_http_methods(["POST"])
def create_post(request):
    """ê²Œì‹œë¬¼ ìƒì„±"""
    
    logger.info("Post creation requested", extra={
        'user_id': request.user.id,
        'user_ip': get_client_ip(request),
    })
    
    try:
        title = request.POST.get('title')
        content = request.POST.get('content')
        
        if not title or not content:
            logger.warning("Post creation failed: missing required fields")
            return JsonResponse({'error': 'Title and content required'}, status=400)
        
        post = Post.objects.create(
            title=title,
            content=content,
            author=request.user
        )
        
        logger.info(f"Post created successfully: {post.id}")
        return JsonResponse({'post_id': post.id, 'status': 'created'})
        
    except Exception as e:
        logger.error(f"Error creating post: {e}", extra={
            'user_id': request.user.id,
            'error_type': type(e).__name__,
        })
        return JsonResponse({'error': 'Post creation failed'}, status=500)
```

### 3. ëª¨ë¸ì—ì„œ ë¡œê·¸ ì‚¬ìš©í•˜ê¸°

```python
# models.py - ëª¨ë¸ ë ˆë²¨ ë¡œê¹…

import logging
from django.db import models
from django.contrib.auth.models import User

logger = logging.getLogger('myapp.models')

class Post(models.Model):
    title = models.CharField(max_length=200)
    content = models.TextField()
    author = models.ForeignKey(User, on_delete=models.CASCADE)
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    
    def save(self, *args, **kwargs):
        """ì €ì¥ ì‹œ ë¡œê·¸ ê¸°ë¡"""
        
        is_new = self.pk is None
        
        if is_new:
            logger.info(f"Creating new post: {self.title[:50]}...")
        else:
            logger.info(f"Updating post: {self.pk}")
        
        try:
            super().save(*args, **kwargs)
            
            if is_new:
                logger.info(f"Post created successfully: {self.pk}")
            else:
                logger.info(f"Post updated successfully: {self.pk}")
                
        except Exception as e:
            logger.error(f"Error saving post: {e}", extra={
                'post_title': self.title,
                'author_id': self.author.id if self.author else None,
            })
            raise
    
    def delete(self, *args, **kwargs):
        """ì‚­ì œ ì‹œ ë¡œê·¸ ê¸°ë¡"""
        
        logger.warning(f"Deleting post: {self.pk} - {self.title}")
        
        try:
            super().delete(*args, **kwargs)
            logger.info(f"Post deleted successfully: {self.pk}")
            
        except Exception as e:
            logger.error(f"Error deleting post: {e}")
            raise
```

## ğŸš€ ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ ë¡œê·¸ ì‹œìŠ¤í…œ

### 1. êµ¬ì¡°í™”ëœ ë¡œê¹… (Structured Logging)

```python
# structured_logging.py - êµ¬ì¡°í™”ëœ ë¡œê¹… ì„¤ì •

import structlog
import logging.config
from django.conf import settings

def configure_structlog():
    """structlog ì„¤ì •"""
    
    structlog.configure(
        processors=[
            structlog.stdlib.filter_by_level,
            structlog.stdlib.add_logger_name,
            structlog.stdlib.add_log_level,
            structlog.stdlib.PositionalArgumentsFormatter(),
            structlog.processors.StackInfoRenderer(),
            structlog.processors.format_exc_info,
            structlog.processors.UnicodeDecoder(),
            structlog.processors.JSONRenderer()
        ],
        context_class=dict,
        logger_factory=structlog.stdlib.LoggerFactory(),
        wrapper_class=structlog.stdlib.BoundLogger,
        cache_logger_on_first_use=True,
    )

# settings.pyì—ì„œ í˜¸ì¶œ
configure_structlog()

# ì‚¬ìš© ì˜ˆ
import structlog

logger = structlog.get_logger()

def process_payment(user_id, amount, payment_method):
    """ê²°ì œ ì²˜ë¦¬ - êµ¬ì¡°í™”ëœ ë¡œê¹…"""
    
    # ì»¨í…ìŠ¤íŠ¸ ë¡œê±° ìƒì„±
    payment_logger = logger.bind(
        user_id=user_id,
        amount=amount,
        payment_method=payment_method,
        transaction_id=generate_transaction_id(),
    )
    
    payment_logger.info("Payment processing started")
    
    try:
        # ê²°ì œ ê²€ì¦
        payment_logger.debug("Validating payment information")
        validate_payment_info(user_id, amount, payment_method)
        
        # ê²°ì œ ì²˜ë¦¬
        payment_logger.info("Processing payment with gateway")
        result = process_with_gateway(amount, payment_method)
        
        payment_logger.info("Payment completed successfully", 
                          gateway_response=result)
        
        return result
        
    except PaymentValidationError as e:
        payment_logger.error("Payment validation failed", 
                           error=str(e), error_type="validation")
        raise
    except GatewayError as e:
        payment_logger.error("Gateway error occurred", 
                           error=str(e), error_type="gateway")
        raise
    except Exception as e:
        payment_logger.critical("Unexpected payment error", 
                               error=str(e), error_type="unknown")
        raise
```

### 2. ë¡œê·¸ ìˆ˜ì§‘ ë° ì¤‘ì•™í™”

```python
# log_collectors.py - ë¡œê·¸ ìˆ˜ì§‘ ì‹œìŠ¤í…œ

import json
import requests
import threading
from queue import Queue
from datetime import datetime

class LogCollector:
    """ë¡œê·¸ë¥¼ ì™¸ë¶€ ì‹œìŠ¤í…œìœ¼ë¡œ ì „ì†¡í•˜ëŠ” ìˆ˜ì§‘ê¸°"""
    
    def __init__(self, endpoint, api_key, batch_size=100):
        self.endpoint = endpoint
        self.api_key = api_key
        self.batch_size = batch_size
        self.log_queue = Queue()
        self.worker_thread = threading.Thread(target=self._worker, daemon=True)
        self.worker_thread.start()
    
    def send_log(self, level, message, extra=None):
        """ë¡œê·¸ë¥¼ íì— ì¶”ê°€"""
        log_entry = {
            'timestamp': datetime.utcnow().isoformat(),
            'level': level,
            'message': message,
            'extra': extra or {},
            'service': 'django-app',
            'environment': settings.ENVIRONMENT,
        }
        self.log_queue.put(log_entry)
    
    def _worker(self):
        """ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë¡œê·¸ ì „ì†¡"""
        logs_batch = []
        
        while True:
            try:
                # íì—ì„œ ë¡œê·¸ ìˆ˜ì§‘
                log_entry = self.log_queue.get(timeout=5)
                logs_batch.append(log_entry)
                
                # ë°°ì¹˜ í¬ê¸°ì— ë„ë‹¬í•˜ë©´ ì „ì†¡
                if len(logs_batch) >= self.batch_size:
                    self._send_batch(logs_batch)
                    logs_batch = []
                    
            except:
                # íƒ€ì„ì•„ì›ƒ ë˜ëŠ” ì—ëŸ¬ ì‹œ í˜„ì¬ ë°°ì¹˜ ì „ì†¡
                if logs_batch:
                    self._send_batch(logs_batch)
                    logs_batch = []
    
    def _send_batch(self, logs_batch):
        """ë¡œê·¸ ë°°ì¹˜ë¥¼ ì™¸ë¶€ ì‹œìŠ¤í…œìœ¼ë¡œ ì „ì†¡"""
        try:
            response = requests.post(
                self.endpoint,
                json={'logs': logs_batch},
                headers={'Authorization': f'Bearer {self.api_key}'},
                timeout=10
            )
            response.raise_for_status()
            
        except Exception as e:
            # ë¡œê·¸ ì „ì†¡ ì‹¤íŒ¨ëŠ” ì¡°ìš©íˆ ì²˜ë¦¬ (ë¬´í•œ ë£¨í”„ ë°©ì§€)
            print(f"Failed to send logs: {e}")

# ì „ì—­ ë¡œê·¸ ìˆ˜ì§‘ê¸° ì¸ìŠ¤í„´ìŠ¤
log_collector = LogCollector(
    endpoint=settings.LOG_ENDPOINT,
    api_key=settings.LOG_API_KEY
)

class ExternalLogHandler(logging.Handler):
    """ì™¸ë¶€ ë¡œê·¸ ì‹œìŠ¤í…œ ì—°ë™ í•¸ë“¤ëŸ¬"""
    
    def emit(self, record):
        """ë¡œê·¸ ë ˆì½”ë“œë¥¼ ì™¸ë¶€ ì‹œìŠ¤í…œìœ¼ë¡œ ì „ì†¡"""
        try:
            # ë¡œê·¸ ë©”ì‹œì§€ í¬ë§·íŒ…
            message = self.format(record)
            
            # ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘
            extra = {
                'module': record.module,
                'function': record.funcName,
                'line': record.lineno,
                'thread': record.thread,
                'process': record.process,
            }
            
            # ì»¤ìŠ¤í…€ í•„ë“œ ì¶”ê°€
            if hasattr(record, 'user_id'):
                extra['user_id'] = record.user_id
            if hasattr(record, 'request_id'):
                extra['request_id'] = record.request_id
            
            # ì™¸ë¶€ ì‹œìŠ¤í…œìœ¼ë¡œ ì „ì†¡
            log_collector.send_log(record.levelname, message, extra)
            
        except Exception:
            # ë¡œê·¸ ì²˜ë¦¬ ì‹¤íŒ¨í•´ë„ ì• í”Œë¦¬ì¼€ì´ì…˜ì€ ê³„ì† ì‹¤í–‰
            pass
```

### 3. ê³ ê¸‰ ë¡œê·¸ ë¯¸ë“¤ì›¨ì–´

```python
# middleware.py - ê³ ê¸‰ ë¡œê·¸ ë¯¸ë“¤ì›¨ì–´

import time
import uuid
import logging
from django.utils.deprecation import MiddlewareMixin
from django.urls import resolve

logger = logging.getLogger('django.request')

class AdvancedLoggingMiddleware(MiddlewareMixin):
    """ê³ ê¸‰ ë¡œê¹… ë¯¸ë“¤ì›¨ì–´"""
    
    def process_request(self, request):
        """ìš”ì²­ ì‹œì‘ ì‹œ ì²˜ë¦¬"""
        
        # ê³ ìœ  ìš”ì²­ ID ìƒì„±
        request.id = str(uuid.uuid4())
        request.start_time = time.time()
        
        # URL íŒ¨í„´ ì •ë³´
        try:
            url_match = resolve(request.path_info)
            view_name = url_match.view_name
            view_args = url_match.args
            view_kwargs = url_match.kwargs
        except:
            view_name = 'unknown'
            view_args = ()
            view_kwargs = {}
        
        # ìš”ì²­ ì •ë³´ ë¡œê¹…
        logger.info("Request started", extra={
            'request_id': request.id,
            'method': request.method,
            'path': request.path,
            'view_name': view_name,
            'view_args': view_args,
            'view_kwargs': view_kwargs,
            'user_id': request.user.id if hasattr(request, 'user') and request.user.is_authenticated else None,
            'ip_address': self.get_client_ip(request),
            'user_agent': request.META.get('HTTP_USER_AGENT', ''),
            'referer': request.META.get('HTTP_REFERER', ''),
            'content_type': request.content_type,
            'content_length': request.META.get('CONTENT_LENGTH', 0),
        })
    
    def process_response(self, request, response):
        """ì‘ë‹µ ì™„ë£Œ ì‹œ ì²˜ë¦¬"""
        
        if hasattr(request, 'start_time'):
            duration = time.time() - request.start_time
            
            # ì‘ë‹µ ì •ë³´ ë¡œê¹…
            logger.info("Request completed", extra={
                'request_id': getattr(request, 'id', 'unknown'),
                'status_code': response.status_code,
                'duration': duration,
                'response_size': len(response.content) if hasattr(response, 'content') else 0,
                'cache_hit': response.get('X-Cache-Status', 'unknown'),
            })
            
            # ì„±ëŠ¥ ê²½ê³ 
            if duration > 1.0:  # 1ì´ˆ ì´ìƒ
                logger.warning("Slow request detected", extra={
                    'request_id': getattr(request, 'id', 'unknown'),
                    'duration': duration,
                    'path': request.path,
                    'method': request.method,
                })
        
        return response
    
    def process_exception(self, request, exception):
        """ì˜ˆì™¸ ë°œìƒ ì‹œ ì²˜ë¦¬"""
        
        duration = time.time() - request.start_time if hasattr(request, 'start_time') else 0
        
        logger.error("Request failed with exception", extra={
            'request_id': getattr(request, 'id', 'unknown'),
            'exception_type': type(exception).__name__,
            'exception_message': str(exception),
            'duration': duration,
            'path': request.path,
            'method': request.method,
            'user_id': request.user.id if hasattr(request, 'user') and request.user.is_authenticated else None,
        }, exc_info=True)
    
    def get_client_ip(self, request):
        """í´ë¼ì´ì–¸íŠ¸ IP ì£¼ì†Œ ì¶”ì¶œ"""
        x_forwarded_for = request.META.get('HTTP_X_FORWARDED_FOR')
        if x_forwarded_for:
            ip = x_forwarded_for.split(',')[0]
        else:
            ip = request.META.get('REMOTE_ADDR')
        return ip
```

### 4. ë¡œê·¸ ë¶„ì„ ë° ì•Œë¦¼ ì‹œìŠ¤í…œ

```python
# log_analysis.py - ë¡œê·¸ ë¶„ì„ ì‹œìŠ¤í…œ

import re
import time
import smtplib
from collections import defaultdict, deque
from email.mime.text import MimeText
from datetime import datetime, timedelta
from threading import Lock

class LogAnalyzer:
    """ì‹¤ì‹œê°„ ë¡œê·¸ ë¶„ì„ ë° ì•Œë¦¼ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.error_counts = defaultdict(int)
        self.recent_errors = deque(maxlen=1000)
        self.alert_thresholds = {
            'error_rate': 10,  # ë¶„ë‹¹ ì—ëŸ¬ ìˆ˜
            'critical_errors': 1,  # í¬ë¦¬í‹°ì»¬ ì—ëŸ¬ëŠ” ì¦‰ì‹œ ì•Œë¦¼
            'slow_requests': 50,  # ë¶„ë‹¹ ëŠë¦° ìš”ì²­ ìˆ˜
        }
        self.lock = Lock()
        self.last_alert_time = {}
        self.alert_cooldown = 300  # 5ë¶„ ì¿¨ë‹¤ìš´
    
    def analyze_log(self, record):
        """ë¡œê·¸ ë ˆì½”ë“œ ë¶„ì„"""
        
        with self.lock:
            current_time = time.time()
            
            # ì—ëŸ¬ ë ˆë²¨ ë¶„ì„
            if record.levelno >= logging.ERROR:
                self.error_counts[record.levelname] += 1
                self.recent_errors.append({
                    'timestamp': current_time,
                    'level': record.levelname,
                    'message': record.getMessage(),
                    'module': record.module,
                })
                
                # í¬ë¦¬í‹°ì»¬ ì—ëŸ¬ëŠ” ì¦‰ì‹œ ì•Œë¦¼
                if record.levelno >= logging.CRITICAL:
                    self.send_immediate_alert(record)
            
            # ì„±ëŠ¥ ë¶„ì„
            if hasattr(record, 'duration') and record.duration > 1.0:
                self.analyze_performance(record)
            
            # ì£¼ê¸°ì  ë¶„ì„
            self.periodic_analysis()
    
    def analyze_performance(self, record):
        """ì„±ëŠ¥ ë¶„ì„"""
        
        slow_request_count = sum(1 for error in self.recent_errors 
                               if time.time() - error['timestamp'] < 60 
                               and 'slow' in error.get('message', '').lower())
        
        if slow_request_count > self.alert_thresholds['slow_requests']:
            self.send_performance_alert(slow_request_count)
    
    def periodic_analysis(self):
        """ì£¼ê¸°ì  ë¶„ì„ (1ë¶„ë§ˆë‹¤)"""
        
        current_time = time.time()
        one_minute_ago = current_time - 60
        
        # ìµœê·¼ 1ë¶„ê°„ ì—ëŸ¬ ìˆ˜ ê³„ì‚°
        recent_error_count = sum(1 for error in self.recent_errors 
                               if error['timestamp'] > one_minute_ago)
        
        if recent_error_count > self.alert_thresholds['error_rate']:
            self.send_error_rate_alert(recent_error_count)
    
    def send_immediate_alert(self, record):
        """ì¦‰ì‹œ ì•Œë¦¼ ì „ì†¡"""
        
        alert_key = f"critical_{record.module}"
        current_time = time.time()
        
        if (alert_key not in self.last_alert_time or 
            current_time - self.last_alert_time[alert_key] > self.alert_cooldown):
            
            subject = f"ğŸš¨ CRITICAL ERROR in {record.module}"
            body = f"""
            Critical error detected:
            
            Time: {datetime.now()}
            Module: {record.module}
            Function: {record.funcName}
            Line: {record.lineno}
            Message: {record.getMessage()}
            
            Please investigate immediately.
            """
            
            self.send_email_alert(subject, body)
            self.last_alert_time[alert_key] = current_time
    
    def send_error_rate_alert(self, error_count):
        """ì—ëŸ¬ ë°œìƒë¥  ì•Œë¦¼"""
        
        alert_key = "error_rate"
        current_time = time.time()
        
        if (alert_key not in self.last_alert_time or 
            current_time - self.last_alert_time[alert_key] > self.alert_cooldown):
            
            subject = f"âš ï¸ High Error Rate: {error_count} errors/minute"
            body = f"""
            High error rate detected:
            
            Error count (last minute): {error_count}
            Threshold: {self.alert_thresholds['error_rate']}
            
            Recent errors:
            {self.format_recent_errors()}
            """
            
            self.send_email_alert(subject, body)
            self.last_alert_time[alert_key] = current_time
    
    def format_recent_errors(self):
        """ìµœê·¼ ì—ëŸ¬ í¬ë§·íŒ…"""
        
        recent = list(self.recent_errors)[-10:]  # ìµœê·¼ 10ê°œ
        formatted = []
        
        for error in recent:
            timestamp = datetime.fromtimestamp(error['timestamp'])
            formatted.append(f"[{timestamp}] {error['level']}: {error['message']}")
        
        return '\n'.join(formatted)
    
    def send_email_alert(self, subject, body):
        """ì´ë©”ì¼ ì•Œë¦¼ ì „ì†¡"""
        
        try:
            msg = MimeText(body)
            msg['Subject'] = subject
            msg['From'] = settings.ALERT_EMAIL_FROM
            msg['To'] = settings.ALERT_EMAIL_TO
            
            server = smtplib.SMTP(settings.SMTP_SERVER, settings.SMTP_PORT)
            server.starttls()
            server.login(settings.SMTP_USERNAME, settings.SMTP_PASSWORD)
            server.send_message(msg)
            server.quit()
            
        except Exception as e:
            # ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨ëŠ” ë³„ë„ ë¡œê·¸ì— ê¸°ë¡
            print(f"Failed to send alert email: {e}")

# ì „ì—­ ë¡œê·¸ ë¶„ì„ê¸°
log_analyzer = LogAnalyzer()

class AnalysisLogHandler(logging.Handler):
    """ë¡œê·¸ ë¶„ì„ í•¸ë“¤ëŸ¬"""
    
    def emit(self, record):
        """ë¡œê·¸ ë ˆì½”ë“œë¥¼ ë¶„ì„ê¸°ë¡œ ì „ë‹¬"""
        try:
            log_analyzer.analyze_log(record)
        except Exception:
            # ë¶„ì„ ì‹¤íŒ¨í•´ë„ ì• í”Œë¦¬ì¼€ì´ì…˜ì€ ê³„ì† ì‹¤í–‰
            pass
```

### 5. í”„ë¡œë•ì…˜ ë¡œê·¸ ì„¤ì •

```python
# settings/production.py - í”„ë¡œë•ì…˜ ë¡œê·¸ ì„¤ì •

import os
from .base import *

# ë¡œê·¸ ë””ë ‰í† ë¦¬ ì„¤ì •
LOG_DIR = os.path.join(BASE_DIR, 'logs')
os.makedirs(LOG_DIR, exist_ok=True)

LOGGING = {
    'version': 1,
    'disable_existing_loggers': False,
    
    # í¬ë§·í„°
    'formatters': {
        'verbose': {
            'format': '{levelname} {asctime} {module} {process:d} {thread:d} {message}',
            'style': '{',
        },
        'json': {
            '()': 'pythonjsonlogger.jsonlogger.JsonFormatter',
            'format': '%(asctime)s %(name)s %(levelname)s %(message)s %(pathname)s %(lineno)d'
        },
        'syslog': {
            'format': 'django[%(process)d]: %(levelname)s %(name)s: %(message)s'
        },
    },
    
    # í•¸ë“¤ëŸ¬
    'handlers': {
        # ì½˜ì†” ì¶œë ¥ (Docker/Kubernetes í™˜ê²½)
        'console': {
            'class': 'logging.StreamHandler',
            'formatter': 'json',
            'level': 'INFO',
        },
        
        # ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œê·¸ íŒŒì¼
        'app_file': {
            'class': 'logging.handlers.RotatingFileHandler',
            'filename': os.path.join(LOG_DIR, 'application.log'),
            'maxBytes': 50 * 1024 * 1024,  # 50MB
            'backupCount': 10,
            'formatter': 'json',
            'level': 'INFO',
        },
        
        # ì—ëŸ¬ ë¡œê·¸ íŒŒì¼
        'error_file': {
            'class': 'logging.handlers.RotatingFileHandler',
            'filename': os.path.join(LOG_DIR, 'error.log'),
            'maxBytes': 50 * 1024 * 1024,  # 50MB
            'backupCount': 5,
            'formatter': 'json',
            'level': 'ERROR',
        },
        
        # ë³´ì•ˆ ë¡œê·¸ íŒŒì¼
        'security_file': {
            'class': 'logging.handlers.RotatingFileHandler',
            'filename': os.path.join(LOG_DIR, 'security.log'),
            'maxBytes': 50 * 1024 * 1024,
            'backupCount': 10,
            'formatter': 'json',
            'level': 'WARNING',
        },
        
        # ì™¸ë¶€ ë¡œê·¸ ì‹œìŠ¤í…œ ì—°ë™
        'external': {
            '()': 'myapp.logging.ExternalLogHandler',
            'level': 'WARNING',
        },
        
        # ë¡œê·¸ ë¶„ì„ ì‹œìŠ¤í…œ
        'analyzer': {
            '()': 'myapp.logging.AnalysisLogHandler',
            'level': 'ERROR',
        },
        
        # Syslog (ì‹œìŠ¤í…œ ë¡œê·¸)
        'syslog': {
            'class': 'logging.handlers.SysLogHandler',
            'address': '/dev/log',
            'facility': 'local0',
            'formatter': 'syslog',
            'level': 'ERROR',
        },
    },
    
    # ë¡œê±° ì„¤ì •
    'loggers': {
        # Django í”„ë ˆì„ì›Œí¬ ë¡œê·¸
        'django': {
            'handlers': ['console', 'app_file'],
            'level': 'INFO',
            'propagate': False,
        },
        
        # Django ìš”ì²­ ë¡œê·¸
        'django.request': {
            'handlers': ['console', 'error_file', 'external'],
            'level': 'ERROR',
            'propagate': False,
        },
        
        # Django ë³´ì•ˆ ë¡œê·¸
        'django.security': {
            'handlers': ['console', 'security_file', 'external'],
            'level': 'WARNING',
            'propagate': False,
        },
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ë¡œê·¸ (ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ìš©)
        'django.db.backends': {
            'handlers': ['app_file'],
            'level': 'WARNING',  # í”„ë¡œë•ì…˜ì—ì„œëŠ” WARNING ì´ìƒë§Œ
            'propagate': False,
        },
        
        # ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œê·¸
        'myapp': {
            'handlers': ['console', 'app_file', 'analyzer'],
            'level': 'INFO',
            'propagate': False,
        },
        
        # ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œê·¸ (ë¶„ì„ìš©)
        'myapp.business': {
            'handlers': ['console', 'app_file', 'external'],
            'level': 'INFO',
            'propagate': False,
        },
        
        # ë³´ì•ˆ ê´€ë ¨ ë¡œê·¸
        'myapp.security': {
            'handlers': ['security_file', 'external', 'syslog'],
            'level': 'WARNING',
            'propagate': False,
        },
    },
    
    # ë£¨íŠ¸ ë¡œê±°
    'root': {
        'level': 'WARNING',
        'handlers': ['console', 'error_file'],
    },
}

# ë¡œê·¸ ê´€ë ¨ ì„¤ì •
LOG_ENDPOINT = os.environ.get('LOG_ENDPOINT')
LOG_API_KEY = os.environ.get('LOG_API_KEY')
ALERT_EMAIL_FROM = os.environ.get('ALERT_EMAIL_FROM')
ALERT_EMAIL_TO = os.environ.get('ALERT_EMAIL_TO')
SMTP_SERVER = os.environ.get('SMTP_SERVER')
SMTP_PORT = int(os.environ.get('SMTP_PORT', '587'))
SMTP_USERNAME = os.environ.get('SMTP_USERNAME')
SMTP_PASSWORD = os.environ.get('SMTP_PASSWORD')
```

## ğŸ“Š ë¡œê·¸ ëª¨ë‹ˆí„°ë§ ë° ë¶„ì„ ë„êµ¬

### 1. ë¡œê·¸ ëŒ€ì‹œë³´ë“œ

```python
# dashboard.py - ë¡œê·¸ ëŒ€ì‹œë³´ë“œ

import json
import sqlite3
from datetime import datetime, timedelta
from django.http import JsonResponse
from django.shortcuts import render

class LogDashboard:
    """ë¡œê·¸ ëŒ€ì‹œë³´ë“œ ë°ì´í„° ì œê³µ"""
    
    def __init__(self, log_file_path):
        self.log_file_path = log_file_path
    
    def get_error_statistics(self, hours=24):
        """ì—ëŸ¬ í†µê³„ ì¡°íšŒ"""
        
        end_time = datetime.now()
        start_time = end_time - timedelta(hours=hours)
        
        error_counts = {
            'ERROR': 0,
            'CRITICAL': 0,
            'WARNING': 0,
        }
        
        error_timeline = []
        
        try:
            with open(self.log_file_path, 'r') as f:
                for line in f:
                    try:
                        log_entry = json.loads(line)
                        log_time = datetime.fromisoformat(log_entry['asctime'])
                        
                        if start_time <= log_time <= end_time:
                            level = log_entry.get('levelname')
                            if level in error_counts:
                                error_counts[level] += 1
                                
                                error_timeline.append({
                                    'time': log_time.isoformat(),
                                    'level': level,
                                    'message': log_entry.get('message', '')[:100],
                                })
                    except (json.JSONDecodeError, KeyError, ValueError):
                        continue
        
        except FileNotFoundError:
            pass
        
        return {
            'error_counts': error_counts,
            'error_timeline': error_timeline[-100:],  # ìµœê·¼ 100ê°œ
            'total_errors': sum(error_counts.values()),
        }
    
    def get_performance_metrics(self, hours=24):
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¡°íšŒ"""
        
        response_times = []
        slow_requests = []
        
        try:
            with open(self.log_file_path, 'r') as f:
                for line in f:
                    try:
                        log_entry = json.loads(line)
                        
                        if 'duration' in log_entry:
                            duration = float(log_entry['duration'])
                            response_times.append(duration)
                            
                            if duration > 1.0:  # 1ì´ˆ ì´ìƒ
                                slow_requests.append({
                                    'time': log_entry.get('asctime'),
                                    'duration': duration,
                                    'path': log_entry.get('path', ''),
                                    'method': log_entry.get('method', ''),
                                })
                    except (json.JSONDecodeError, KeyError, ValueError):
                        continue
        
        except FileNotFoundError:
            pass
        
        # í†µê³„ ê³„ì‚°
        if response_times:
            avg_response_time = sum(response_times) / len(response_times)
            max_response_time = max(response_times)
            p95_response_time = sorted(response_times)[int(len(response_times) * 0.95)]
        else:
            avg_response_time = max_response_time = p95_response_time = 0
        
        return {
            'avg_response_time': avg_response_time,
            'max_response_time': max_response_time,
            'p95_response_time': p95_response_time,
            'slow_requests_count': len(slow_requests),
            'slow_requests': slow_requests[-20:],  # ìµœê·¼ 20ê°œ
        }

def dashboard_view(request):
    """ëŒ€ì‹œë³´ë“œ ë·°"""
    
    dashboard = LogDashboard('/app/logs/application.log')
    
    error_stats = dashboard.get_error_statistics()
    performance_stats = dashboard.get_performance_metrics()
    
    context = {
        'error_stats': error_stats,
        'performance_stats': performance_stats,
        'last_updated': datetime.now().isoformat(),
    }
    
    return render(request, 'dashboard.html', context)

def dashboard_api(request):
    """ëŒ€ì‹œë³´ë“œ API (Ajaxìš©)"""
    
    dashboard = LogDashboard('/app/logs/application.log')
    
    data = {
        'errors': dashboard.get_error_statistics(),
        'performance': dashboard.get_performance_metrics(),
        'timestamp': datetime.now().isoformat(),
    }
    
    return JsonResponse(data)
```

### 2. ë¡œê·¸ ê²€ìƒ‰ ë° í•„í„°ë§

```python
# log_search.py - ë¡œê·¸ ê²€ìƒ‰ ì‹œìŠ¤í…œ

import re
import json
from datetime import datetime, timedelta
from django.core.paginator import Paginator
from django.http import JsonResponse

class LogSearch:
    """ê³ ê¸‰ ë¡œê·¸ ê²€ìƒ‰ ì‹œìŠ¤í…œ"""
    
    def __init__(self, log_file_path):
        self.log_file_path = log_file_path
    
    def search(self, query=None, level=None, start_time=None, end_time=None, 
               module=None, user_id=None, limit=100):
        """ë¡œê·¸ ê²€ìƒ‰"""
        
        results = []
        
        try:
            with open(self.log_file_path, 'r') as f:
                for line in f:
                    try:
                        log_entry = json.loads(line)
                        
                        # í•„í„° ì¡°ê±´ í™•ì¸
                        if not self._matches_filters(log_entry, query, level, 
                                                   start_time, end_time, module, user_id):
                            continue
                        
                        results.append(log_entry)
                        
                        if len(results) >= limit:
                            break
                    
                    except (json.JSONDecodeError, KeyError):
                        continue
        
        except FileNotFoundError:
            pass
        
        return results
    
    def _matches_filters(self, log_entry, query, level, start_time, end_time, module, user_id):
        """í•„í„° ì¡°ê±´ í™•ì¸"""
        
        # í…ìŠ¤íŠ¸ ê²€ìƒ‰
        if query:
            message = log_entry.get('message', '').lower()
            if query.lower() not in message:
                return False
        
        # ë¡œê·¸ ë ˆë²¨ í•„í„°
        if level and log_entry.get('levelname') != level:
            return False
        
        # ì‹œê°„ ë²”ìœ„ í•„í„°
        if start_time or end_time:
            try:
                log_time = datetime.fromisoformat(log_entry.get('asctime', ''))
                if start_time and log_time < start_time:
                    return False
                if end_time and log_time > end_time:
                    return False
            except ValueError:
                return False
        
        # ëª¨ë“ˆ í•„í„°
        if module and log_entry.get('name') != module:
            return False
        
        # ì‚¬ìš©ì ID í•„í„°
        if user_id and log_entry.get('user_id') != user_id:
            return False
        
        return True
    
    def get_log_statistics(self, hours=24):
        """ë¡œê·¸ í†µê³„"""
        
        end_time = datetime.now()
        start_time = end_time - timedelta(hours=hours)
        
        stats = {
            'total_logs': 0,
            'by_level': {},
            'by_module': {},
            'by_hour': {},
        }
        
        try:
            with open(self.log_file_path, 'r') as f:
                for line in f:
                    try:
                        log_entry = json.loads(line)
                        log_time = datetime.fromisoformat(log_entry.get('asctime', ''))
                        
                        if start_time <= log_time <= end_time:
                            stats['total_logs'] += 1
                            
                            # ë ˆë²¨ë³„ í†µê³„
                            level = log_entry.get('levelname', 'UNKNOWN')
                            stats['by_level'][level] = stats['by_level'].get(level, 0) + 1
                            
                            # ëª¨ë“ˆë³„ í†µê³„
                            module = log_entry.get('name', 'unknown')
                            stats['by_module'][module] = stats['by_module'].get(module, 0) + 1
                            
                            # ì‹œê°„ë³„ í†µê³„
                            hour_key = log_time.strftime('%Y-%m-%d %H:00')
                            stats['by_hour'][hour_key] = stats['by_hour'].get(hour_key, 0) + 1
                    
                    except (json.JSONDecodeError, KeyError, ValueError):
                        continue
        
        except FileNotFoundError:
            pass
        
        return stats

def search_logs(request):
    """ë¡œê·¸ ê²€ìƒ‰ API"""
    
    # ê²€ìƒ‰ íŒŒë¼ë¯¸í„°
    query = request.GET.get('q')
    level = request.GET.get('level')
    module = request.GET.get('module')
    user_id = request.GET.get('user_id')
    hours = int(request.GET.get('hours', 24))
    page = int(request.GET.get('page', 1))
    
    # ì‹œê°„ ë²”ìœ„ ì„¤ì •
    end_time = datetime.now()
    start_time = end_time - timedelta(hours=hours)
    
    # ë¡œê·¸ ê²€ìƒ‰
    searcher = LogSearch('/app/logs/application.log')
    results = searcher.search(
        query=query,
        level=level,
        start_time=start_time,
        end_time=end_time,
        module=module,
        user_id=user_id,
        limit=1000
    )
    
    # í˜ì´ì§€ë„¤ì´ì…˜
    paginator = Paginator(results, 50)
    page_obj = paginator.get_page(page)
    
    return JsonResponse({
        'logs': list(page_obj),
        'total_count': len(results),
        'page': page,
        'total_pages': paginator.num_pages,
        'has_next': page_obj.has_next(),
        'has_previous': page_obj.has_previous(),
    })
```

## ğŸ¯ ë¡œê·¸ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤

### 1. ë¡œê·¸ ë ˆë²¨ ê°€ì´ë“œë¼ì¸

```python
# log_guidelines.py - ë¡œê·¸ ë ˆë²¨ ì‚¬ìš© ê°€ì´ë“œ

import logging

logger = logging.getLogger(__name__)

# DEBUG: ê°œë°œ ì¤‘ ìƒì„¸í•œ ì •ë³´
def process_data(data):
    logger.debug(f"Processing data with {len(data)} items")
    logger.debug(f"Data structure: {type(data).__name__}")
    
    for item in data:
        logger.debug(f"Processing item: {item['id']}")
        # ì²˜ë¦¬ ë¡œì§...

# INFO: ì¼ë°˜ì ì¸ ì •ë³´, ë¹„ì¦ˆë‹ˆìŠ¤ í”Œë¡œìš°
def user_login(user):
    logger.info(f"User login successful", extra={
        'user_id': user.id,
        'username': user.username,
        'login_method': 'password',
    })

# WARNING: ë¬¸ì œê°€ ë  ìˆ˜ ìˆëŠ” ìƒí™©
def check_disk_space():
    free_space = get_free_disk_space()
    if free_space < 1024 * 1024 * 1024:  # 1GB ë¯¸ë§Œ
        logger.warning(f"Low disk space: {free_space / 1024 / 1024:.1f}MB remaining")

# ERROR: ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì§€ë§Œ ì• í”Œë¦¬ì¼€ì´ì…˜ì€ ê³„ì† ì‹¤í–‰
def process_payment(amount):
    try:
        result = payment_gateway.charge(amount)
        return result
    except PaymentException as e:
        logger.error(f"Payment failed: {e}", extra={
            'amount': amount,
            'error_code': e.code,
        })
        return None

# CRITICAL: ì‹¬ê°í•œ ì˜¤ë¥˜, ì¦‰ì‹œ ëŒ€ì‘ í•„ìš”
def database_connection():
    try:
        connection = get_db_connection()
        return connection
    except DatabaseConnectionError as e:
        logger.critical(f"Database connection failed: {e}", extra={
            'database_host': settings.DATABASE_HOST,
            'error_details': str(e),
        })
        raise
```

### 2. ì„±ëŠ¥ì„ ê³ ë ¤í•œ ë¡œê¹…

```python
# performance_logging.py - ì„±ëŠ¥ ìµœì í™”ëœ ë¡œê¹…

import logging
from functools import wraps

logger = logging.getLogger(__name__)

# ì¡°ê±´ë¶€ ë¡œê¹… (ì„±ëŠ¥ í–¥ìƒ)
def conditional_debug_log(condition_func):
    """ì¡°ê±´ì´ ì°¸ì¼ ë•Œë§Œ DEBUG ë¡œê·¸ ì¶œë ¥"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            if logger.isEnabledFor(logging.DEBUG) and condition_func():
                logger.debug(f"Calling {func.__name__} with args={args}, kwargs={kwargs}")
            
            result = func(*args, **kwargs)
            
            if logger.isEnabledFor(logging.DEBUG) and condition_func():
                logger.debug(f"{func.__name__} returned: {type(result).__name__}")
            
            return result
        return wrapper
    return decorator

# ì§€ì—° ë¡œê·¸ í‰ê°€ (Lazy Evaluation)
class LazyLogMessage:
    """ë¬´ê±°ìš´ ë¡œê·¸ ë©”ì‹œì§€ì˜ ì§€ì—° í‰ê°€"""
    
    def __init__(self, func, *args, **kwargs):
        self.func = func
        self.args = args
        self.kwargs = kwargs
    
    def __str__(self):
        return self.func(*self.args, **self.kwargs)

def expensive_debug_info():
    """ë¬´ê±°ìš´ ë””ë²„ê·¸ ì •ë³´ ìƒì„±"""
    # ë³µì¡í•œ ê³„ì‚°ì´ë‚˜ ë°ì´í„° ì§ë ¬í™”...
    return "Very expensive debug information..."

# ì‚¬ìš© ì˜ˆ
logger.debug(LazyLogMessage(expensive_debug_info))

# ë°°ì¹˜ ë¡œê¹… (ì„±ëŠ¥ í–¥ìƒ)
class BatchLogger:
    """ë¡œê·¸ë¥¼ ëª¨ì•„ì„œ ë°°ì¹˜ë¡œ ì²˜ë¦¬"""
    
    def __init__(self, logger, batch_size=100, flush_interval=30):
        self.logger = logger
        self.batch_size = batch_size
        self.flush_interval = flush_interval
        self.log_buffer = []
        self.last_flush = time.time()
    
    def log(self, level, message, extra=None):
        """ë¡œê·¸ë¥¼ ë²„í¼ì— ì¶”ê°€"""
        self.log_buffer.append({
            'level': level,
            'message': message,
            'extra': extra,
            'timestamp': time.time(),
        })
        
        # ì¡°ê±´ì— ë”°ë¼ í”ŒëŸ¬ì‹œ
        if (len(self.log_buffer) >= self.batch_size or 
            time.time() - self.last_flush > self.flush_interval):
            self.flush()
    
    def flush(self):
        """ë²„í¼ì˜ ë¡œê·¸ë“¤ì„ ì‹¤ì œë¡œ ì¶œë ¥"""
        for log_entry in self.log_buffer:
            getattr(self.logger, log_entry['level'].lower())(
                log_entry['message'], 
                extra=log_entry['extra']
            )
        
        self.log_buffer.clear()
        self.last_flush = time.time()
```

## ğŸš€ ê²°ë¡ 

Django ë¡œê·¸ ì‹œìŠ¤í…œì„ ì œëŒ€ë¡œ êµ¬ì¶•í•˜ëŠ” ê²ƒì€ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì•ˆì •ì„±ê³¼ ìš´ì˜ íš¨ìœ¨ì„±ì— ì§ê²°ë©ë‹ˆë‹¤.

**í•µì‹¬ í¬ì¸íŠ¸:**

1. **ë¡œê·¸ëŠ” ë¹„ìš©ì´ ì•„ë‹Œ íˆ¬ì**: ì´ˆê¸° ì„¤ì •ì— ì‹œê°„ì„ íˆ¬ìí•˜ë©´ ì¥ê¸°ì ìœ¼ë¡œ ì—„ì²­ë‚œ ì‹œê°„ì„ ì ˆì•½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

2. **ë‹¨ê³„ì  ì ‘ê·¼**: ê¸°ì´ˆì ì¸ ë¡œê·¸ë¶€í„° ì‹œì‘í•´ì„œ ì ì°¨ ê³ ë„í™”í•´ ë‚˜ê°€ì„¸ìš”.

3. **êµ¬ì¡°í™”ëœ ë¡œê¹…**: JSON í˜•íƒœì˜ êµ¬ì¡°í™”ëœ ë¡œê·¸ëŠ” ë¶„ì„ê³¼ ì•Œë¦¼ ì‹œìŠ¤í…œ êµ¬ì¶•ì— í•„ìˆ˜ì…ë‹ˆë‹¤.

4. **ì„±ëŠ¥ ê³ ë ¤**: ë¡œê·¸ ìì²´ê°€ ì„±ëŠ¥ ë³‘ëª©ì´ ë˜ì§€ ì•Šë„ë¡ ìµœì í™”ê°€ ì¤‘ìš”í•©ë‹ˆë‹¤.

5. **ëª¨ë‹ˆí„°ë§ê³¼ ì•Œë¦¼**: ë¡œê·¸ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ê²ƒë¿ë§Œ ì•„ë‹ˆë¼ ì‹¤ì‹œê°„ ë¶„ì„ê³¼ ì•Œë¦¼ ì‹œìŠ¤í…œê¹Œì§€ êµ¬ì¶•í•´ì•¼ ì™„ì „í•©ë‹ˆë‹¤.

**ì¶”ì²œ ë¡œë“œë§µ:**
- **1ë‹¨ê³„**: ê¸°ë³¸ ë¡œê·¸ ì„¤ì • ë° ì ì ˆí•œ ë¡œê·¸ ë ˆë²¨ ì ìš©
- **2ë‹¨ê³„**: êµ¬ì¡°í™”ëœ ë¡œê¹… ë„ì… ë° ë¡œê·¸ ìˆ˜ì§‘ ì‹œìŠ¤í…œ êµ¬ì¶•
- **3ë‹¨ê³„**: ì‹¤ì‹œê°„ ë¶„ì„ ë° ì•Œë¦¼ ì‹œìŠ¤í…œ ê°œë°œ
- **4ë‹¨ê³„**: ë¡œê·¸ ê¸°ë°˜ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ

íš¨ê³¼ì ì¸ ë¡œê·¸ ì‹œìŠ¤í…œì€ ë‹¨ìˆœí•œ ë””ë²„ê¹… ë„êµ¬ë¥¼ ë„˜ì–´ì„œ ë¹„ì¦ˆë‹ˆìŠ¤ ì„±ì¥ì˜ í•µì‹¬ ì¸í”„ë¼ê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

**ì°¸ê³  ìë£Œ:**
- [Django ë¡œê¹… ê³µì‹ ë¬¸ì„œ](https://docs.djangoproject.com/en/stable/topics/logging/)
- [Python logging ëª¨ë“ˆ](https://docs.python.org/3/library/logging.html)
- [Structlog ë¼ì´ë¸ŒëŸ¬ë¦¬](https://www.structlog.org/)
- [ELK Stack (Elasticsearch, Logstash, Kibana)](https://www.elastic.co/elk-stack)
