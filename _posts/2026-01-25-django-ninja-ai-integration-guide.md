---
layout: post
title: "Django Ninjaë¡œ AI API ì„œë²„ êµ¬ì¶•í•˜ê¸° - OpenAI í†µí•© ì‹¤ì „ ê°€ì´ë“œ"
date: 2026-01-25
categories: [Django, AI, API]
tags: [django-ninja, openai, api, python, ai-integration]
image: "/assets/img/posts/2026-01-25-django-ninja-ai-integration-guide.webp"
---

## ì„œë¡ 

ìµœê·¼ AI ê¸°ìˆ ì˜ ë°œì „ìœ¼ë¡œ ë§ì€ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ AI ê¸°ëŠ¥ì„ í†µí•©í•˜ëŠ” ê²ƒì´ í•„ìˆ˜ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤. DjangoëŠ” ê°•ë ¥í•œ ì›¹ í”„ë ˆì„ì›Œí¬ì§€ë§Œ, REST API ê°œë°œì— ìˆì–´ì„œëŠ” Django REST Framework(DRF)ì˜ ë³µì¡ì„±ì´ ë¶€ë‹´ìŠ¤ëŸ¬ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë•Œ Django Ninjaê°€ í›Œë¥­í•œ ëŒ€ì•ˆì´ ë©ë‹ˆë‹¤.

Django NinjaëŠ” FastAPIì—ì„œ ì˜ê°ì„ ë°›ì•„ ë§Œë“¤ì–´ì§„ í”„ë ˆì„ì›Œí¬ë¡œ, íƒ€ì… íŒíŠ¸ ê¸°ë°˜ì˜ ì§ê´€ì ì¸ API ê°œë°œì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. íŠ¹íˆ AI APIë¥¼ êµ¬ì¶•í•  ë•ŒëŠ” ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘ê³¼ ëª…í™•í•œ ë°ì´í„° ê²€ì¦ì´ ì¤‘ìš”í•œë°, Django NinjaëŠ” ì´ ë‘ ê°€ì§€ë¥¼ ì™„ë²½í•˜ê²Œ ì§€ì›í•©ë‹ˆë‹¤.

ì´ ê°€ì´ë“œì—ì„œëŠ” Django Ninjaë¥¼ ì‚¬ìš©í•˜ì—¬ OpenAI APIë¥¼ í†µí•©í•˜ê³ , ì‹¤ìš©ì ì¸ AI ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” API ì„œë²„ë¥¼ êµ¬ì¶•í•˜ëŠ” ì „ì²´ ê³¼ì •ì„ ë‹¤ë£¹ë‹ˆë‹¤.

## Django Ninja í”„ë¡œì íŠ¸ ì„¤ì •

ë¨¼ì € Django Ninja í”„ë¡œì íŠ¸ë¥¼ ì„¤ì •í•˜ê³  í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.

### í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
# ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Django Ninja ë° OpenAI íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install django django-ninja openai python-dotenv
```

### Django í”„ë¡œì íŠ¸ ì´ˆê¸°í™”

```bash
# Django í”„ë¡œì íŠ¸ ìƒì„±
django-admin startproject ai_project .
python manage.py startapp ai_api

# ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
python manage.py migrate
```

### í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— `.env` íŒŒì¼ì„ ìƒì„±í•˜ì—¬ API í‚¤ë¥¼ ì•ˆì „í•˜ê²Œ ê´€ë¦¬í•©ë‹ˆë‹¤.

```env
# .env
OPENAI_API_KEY=sk-your-api-key-here
DEBUG=True
SECRET_KEY=your-django-secret-key
```

### settings.py ì„¤ì •

```python
# ai_project/settings.py
import os
from dotenv import load_dotenv
from pathlib import Path

load_dotenv()

BASE_DIR = Path(__file__).resolve().parent.parent

SECRET_KEY = os.getenv('SECRET_KEY')
DEBUG = os.getenv('DEBUG', 'False') == 'True'

INSTALLED_APPS = [
    'django.contrib.admin',
    'django.contrib.auth',
    'django.contrib.contenttypes',
    'django.contrib.sessions',
    'django.contrib.messages',
    'django.contrib.staticfiles',
    'ai_api',  # ìš°ë¦¬ê°€ ë§Œë“  ì•±
]

MIDDLEWARE = [
    'django.middleware.security.SecurityMiddleware',
    'django.contrib.sessions.middleware.SessionMiddleware',
    'django.middleware.common.CommonMiddleware',
    'django.middleware.csrf.CsrfViewMiddleware',
    'django.contrib.auth.middleware.AuthenticationMiddleware',
    'django.contrib.messages.middleware.MessageMiddleware',
    'django.middleware.clickjacking.XFrameOptionsMiddleware',
]

ROOT_URLCONF = 'ai_project.urls'

# OpenAI ì„¤ì •
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
```

ì´ì œ ê¸°ë³¸ì ì¸ Django í”„ë¡œì íŠ¸ ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. Django Ninjaì˜ ê°•ì ì€ ë³µì¡í•œ ì„¤ì • ì—†ì´ë„ ì¦‰ì‹œ API ê°œë°œì„ ì‹œì‘í•  ìˆ˜ ìˆë‹¤ëŠ” ì ì…ë‹ˆë‹¤.

## OpenAI í´ë¼ì´ì–¸íŠ¸ í†µí•©

OpenAI APIë¥¼ Django í”„ë¡œì íŠ¸ì— í†µí•©í•˜ê¸° ìœ„í•´ ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ì„œë¹„ìŠ¤ ë ˆì´ì–´ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤.

### AI ì„œë¹„ìŠ¤ ëª¨ë“ˆ ìƒì„±

`ai_api/services.py` íŒŒì¼ì„ ìƒì„±í•˜ì—¬ OpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.

```python
# ai_api/services.py
from openai import OpenAI
from django.conf import settings
from typing import Optional, List, Dict, Any
import logging

logger = logging.getLogger(__name__)

class AIService:
    """OpenAI APIë¥¼ ê´€ë¦¬í•˜ëŠ” ì„œë¹„ìŠ¤ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.client = OpenAI(api_key=settings.OPENAI_API_KEY)
    
    def generate_text(
        self,
        prompt: str,
        model: str = "gpt-4",
        max_tokens: int = 1000,
        temperature: float = 0.7
    ) -> Dict[str, Any]:
        """
        í…ìŠ¤íŠ¸ ìƒì„± API
        
        Args:
            prompt: ì‚¬ìš©ì ì…ë ¥ í”„ë¡¬í”„íŠ¸
            model: ì‚¬ìš©í•  GPT ëª¨ë¸
            max_tokens: ìµœëŒ€ í† í° ìˆ˜
            temperature: ìƒì„± ë‹¤ì–‘ì„± (0-2)
        
        Returns:
            ìƒì„±ëœ í…ìŠ¤íŠ¸ì™€ ë©”íƒ€ë°ì´í„°
        """
        try:
            response = self.client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=max_tokens,
                temperature=temperature
            )
            
            return {
                "text": response.choices[0].message.content,
                "model": response.model,
                "usage": {
                    "prompt_tokens": response.usage.prompt_tokens,
                    "completion_tokens": response.usage.completion_tokens,
                    "total_tokens": response.usage.total_tokens
                },
                "finish_reason": response.choices[0].finish_reason
            }
        
        except Exception as e:
            logger.error(f"OpenAI API Error: {str(e)}")
            raise
    
    def analyze_image(
        self,
        image_url: str,
        prompt: str = "What's in this image?"
    ) -> Dict[str, Any]:
        """
        ì´ë¯¸ì§€ ë¶„ì„ API (GPT-4 Vision)
        
        Args:
            image_url: ë¶„ì„í•  ì´ë¯¸ì§€ URL
            prompt: ë¶„ì„ ìš”ì²­ í”„ë¡¬í”„íŠ¸
        
        Returns:
            ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼
        """
        try:
            response = self.client.chat.completions.create(
                model="gpt-4-vision-preview",
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {"type": "image_url", "image_url": {"url": image_url}}
                        ]
                    }
                ],
                max_tokens=500
            )
            
            return {
                "analysis": response.choices[0].message.content,
                "usage": {
                    "prompt_tokens": response.usage.prompt_tokens,
                    "completion_tokens": response.usage.completion_tokens,
                    "total_tokens": response.usage.total_tokens
                }
            }
        
        except Exception as e:
            logger.error(f"Image Analysis Error: {str(e)}")
            raise
    
    def create_embeddings(self, texts: List[str]) -> List[List[float]]:
        """
        í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
        
        Args:
            texts: ì„ë² ë”©í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
        
        Returns:
            ì„ë² ë”© ë²¡í„° ë¦¬ìŠ¤íŠ¸
        """
        try:
            response = self.client.embeddings.create(
                model="text-embedding-3-small",
                input=texts
            )
            
            return [item.embedding for item in response.data]
        
        except Exception as e:
            logger.error(f"Embedding Error: {str(e)}")
            raise

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
ai_service = AIService()
```

ì´ ì„œë¹„ìŠ¤ ë ˆì´ì–´ëŠ” Django Ninja API ì—”ë“œí¬ì¸íŠ¸ì™€ OpenAI API ì‚¬ì´ì˜ ì¤‘ê°„ ê³„ì¸µ ì—­í• ì„ í•©ë‹ˆë‹¤. ë¡œê¹…, ì—ëŸ¬ í•¸ë“¤ë§, ê·¸ë¦¬ê³  ì¬ì‚¬ìš©ì„±ì„ ì œê³µí•©ë‹ˆë‹¤.

## Django Ninja API ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„

ì´ì œ Django Ninjaë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ API ì—”ë“œí¬ì¸íŠ¸ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.

### ìŠ¤í‚¤ë§ˆ ì •ì˜

ë¨¼ì € ìš”ì²­ê³¼ ì‘ë‹µì— ì‚¬ìš©í•  ìŠ¤í‚¤ë§ˆë¥¼ ì •ì˜í•©ë‹ˆë‹¤.

```python
# ai_api/schemas.py
from ninja import Schema
from typing import Optional, List, Dict

class TextGenerationRequest(Schema):
    """í…ìŠ¤íŠ¸ ìƒì„± ìš”ì²­ ìŠ¤í‚¤ë§ˆ"""
    prompt: str
    model: str = "gpt-4"
    max_tokens: int = 1000
    temperature: float = 0.7
    
    class Config:
        schema_extra = {
            "example": {
                "prompt": "Pythonìœ¼ë¡œ ê°„ë‹¨í•œ ì›¹ ìŠ¤í¬ë˜í¼ë¥¼ ë§Œë“œëŠ” ë°©ë²•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
                "model": "gpt-4",
                "max_tokens": 1000,
                "temperature": 0.7
            }
        }

class TextGenerationResponse(Schema):
    """í…ìŠ¤íŠ¸ ìƒì„± ì‘ë‹µ ìŠ¤í‚¤ë§ˆ"""
    text: str
    model: str
    usage: Dict[str, int]
    finish_reason: str

class ImageAnalysisRequest(Schema):
    """ì´ë¯¸ì§€ ë¶„ì„ ìš”ì²­ ìŠ¤í‚¤ë§ˆ"""
    image_url: str
    prompt: str = "What's in this image?"
    
    class Config:
        schema_extra = {
            "example": {
                "image_url": "https://example.com/image.jpg",
                "prompt": "ì´ ì´ë¯¸ì§€ì—ì„œ ì–´ë–¤ ê°ì •ì„ ëŠë‚„ ìˆ˜ ìˆë‚˜ìš”?"
            }
        }

class ImageAnalysisResponse(Schema):
    """ì´ë¯¸ì§€ ë¶„ì„ ì‘ë‹µ ìŠ¤í‚¤ë§ˆ"""
    analysis: str
    usage: Dict[str, int]

class EmbeddingRequest(Schema):
    """ì„ë² ë”© ìƒì„± ìš”ì²­ ìŠ¤í‚¤ë§ˆ"""
    texts: List[str]
    
    class Config:
        schema_extra = {
            "example": {
                "texts": [
                    "DjangoëŠ” Python ì›¹ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.",
                    "FastAPIëŠ” ë¹ ë¥¸ API ê°œë°œì— ì í•©í•©ë‹ˆë‹¤."
                ]
            }
        }

class EmbeddingResponse(Schema):
    """ì„ë² ë”© ìƒì„± ì‘ë‹µ ìŠ¤í‚¤ë§ˆ"""
    embeddings: List[List[float]]
    dimension: int
    count: int

class ErrorResponse(Schema):
    """ì—ëŸ¬ ì‘ë‹µ ìŠ¤í‚¤ë§ˆ"""
    detail: str
    error_code: Optional[str] = None
```

### API ë¼ìš°í„° êµ¬í˜„

```python
# ai_api/api.py
from ninja import NinjaAPI, Router
from typing import List
import logging

from .schemas import (
    TextGenerationRequest, TextGenerationResponse,
    ImageAnalysisRequest, ImageAnalysisResponse,
    EmbeddingRequest, EmbeddingResponse,
    ErrorResponse
)
from .services import ai_service

logger = logging.getLogger(__name__)

# NinjaAPI ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
api = NinjaAPI(
    title="AI API Server",
    version="1.0.0",
    description="Django Ninjaë¥¼ ì‚¬ìš©í•œ OpenAI í†µí•© API ì„œë²„"
)

# AI ë¼ìš°í„° ìƒì„±
ai_router = Router(tags=["AI"])

@ai_router.post(
    "/generate-text",
    response={200: TextGenerationResponse, 500: ErrorResponse},
    summary="í…ìŠ¤íŠ¸ ìƒì„±",
    description="GPT ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
)
def generate_text(request, payload: TextGenerationRequest):
    """
    í”„ë¡¬í”„íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ AI í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    - **prompt**: ìƒì„±í•  í…ìŠ¤íŠ¸ì— ëŒ€í•œ í”„ë¡¬í”„íŠ¸
    - **model**: ì‚¬ìš©í•  GPT ëª¨ë¸ (ê¸°ë³¸ê°’: gpt-4)
    - **max_tokens**: ìƒì„±í•  ìµœëŒ€ í† í° ìˆ˜
    - **temperature**: ìƒì„± ë‹¤ì–‘ì„± (0-2, ê¸°ë³¸ê°’: 0.7)
    """
    try:
        result = ai_service.generate_text(
            prompt=payload.prompt,
            model=payload.model,
            max_tokens=payload.max_tokens,
            temperature=payload.temperature
        )
        return 200, result
    except Exception as e:
        logger.error(f"Text generation failed: {str(e)}")
        return 500, {"detail": str(e), "error_code": "GENERATION_ERROR"}

@ai_router.post(
    "/analyze-image",
    response={200: ImageAnalysisResponse, 500: ErrorResponse},
    summary="ì´ë¯¸ì§€ ë¶„ì„",
    description="GPT-4 Visionì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."
)
def analyze_image(request, payload: ImageAnalysisRequest):
    """
    ì´ë¯¸ì§€ URLì„ ë°›ì•„ì„œ ë‚´ìš©ì„ ë¶„ì„í•©ë‹ˆë‹¤.
    
    - **image_url**: ë¶„ì„í•  ì´ë¯¸ì§€ì˜ ê³µê°œ URL
    - **prompt**: ë¶„ì„ ìš”ì²­ ë‚´ìš© (ì„ íƒì‚¬í•­)
    """
    try:
        result = ai_service.analyze_image(
            image_url=payload.image_url,
            prompt=payload.prompt
        )
        return 200, result
    except Exception as e:
        logger.error(f"Image analysis failed: {str(e)}")
        return 500, {"detail": str(e), "error_code": "ANALYSIS_ERROR"}

@ai_router.post(
    "/create-embeddings",
    response={200: EmbeddingResponse, 500: ErrorResponse},
    summary="í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±",
    description="í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."
)
def create_embeddings(request, payload: EmbeddingRequest):
    """
    í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    - **texts**: ì„ë² ë”©í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
    """
    try:
        embeddings = ai_service.create_embeddings(payload.texts)
        return 200, {
            "embeddings": embeddings,
            "dimension": len(embeddings[0]) if embeddings else 0,
            "count": len(embeddings)
        }
    except Exception as e:
        logger.error(f"Embedding creation failed: {str(e)}")
        return 500, {"detail": str(e), "error_code": "EMBEDDING_ERROR"}

@ai_router.get(
    "/health",
    summary="í—¬ìŠ¤ ì²´í¬",
    description="API ì„œë²„ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤."
)
def health_check(request):
    """API ì„œë²„ê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
    return {"status": "healthy", "service": "AI API"}

# ë¼ìš°í„° ë“±ë¡
api.add_router("/ai", ai_router)
```

### URL ì„¤ì •

```python
# ai_project/urls.py
from django.contrib import admin
from django.urls import path
from ai_api.api import api

urlpatterns = [
    path('admin/', admin.site.urls),
    path('api/', api.urls),  # Django Ninja API
]
```

ì´ì œ ì„œë²„ë¥¼ ì‹¤í–‰í•˜ë©´ `/api/docs`ì—ì„œ ìë™ ìƒì„±ëœ Swagger ë¬¸ì„œë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!

## ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ êµ¬í˜„

AI ì‘ë‹µì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë°í•˜ë©´ ì‚¬ìš©ì ê²½í—˜ì„ í¬ê²Œ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. Django Ninjaì—ì„œ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ êµ¬í˜„í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë´…ë‹ˆë‹¤.

### ìŠ¤íŠ¸ë¦¬ë° ì„œë¹„ìŠ¤ ì¶”ê°€

```python
# ai_api/services.pyì— ì¶”ê°€
from django.http import StreamingHttpResponse
import json

class AIService:
    # ... ê¸°ì¡´ ì½”ë“œ ...
    
    def stream_text_generation(
        self,
        prompt: str,
        model: str = "gpt-4",
        temperature: float = 0.7
    ):
        """
        ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ í…ìŠ¤íŠ¸ ìƒì„±
        
        Args:
            prompt: ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸
            model: GPT ëª¨ë¸
            temperature: ìƒì„± ë‹¤ì–‘ì„±
        
        Yields:
            í…ìŠ¤íŠ¸ ì²­í¬
        """
        try:
            stream = self.client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": prompt}
                ],
                temperature=temperature,
                stream=True  # ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”
            )
            
            for chunk in stream:
                if chunk.choices[0].delta.content is not None:
                    content = chunk.choices[0].delta.content
                    yield f"data: {json.dumps({'content': content})}\n\n"
            
            yield "data: [DONE]\n\n"
        
        except Exception as e:
            logger.error(f"Streaming Error: {str(e)}")
            yield f"data: {json.dumps({'error': str(e)})}\n\n"
```

### ìŠ¤íŠ¸ë¦¬ë° ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€

```python
# ai_api/api.pyì— ì¶”ê°€
from django.http import StreamingHttpResponse

@ai_router.post(
    "/stream-text",
    summary="í…ìŠ¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë° ìƒì„±",
    description="ì‹¤ì‹œê°„ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ ìŠ¤íŠ¸ë¦¬ë°í•©ë‹ˆë‹¤."
)
def stream_text(request, payload: TextGenerationRequest):
    """
    Server-Sent Events (SSE) ë°©ì‹ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ ìŠ¤íŠ¸ë¦¬ë°í•©ë‹ˆë‹¤.
    """
    response = StreamingHttpResponse(
        ai_service.stream_text_generation(
            prompt=payload.prompt,
            model=payload.model,
            temperature=payload.temperature
        ),
        content_type='text/event-stream'
    )
    response['Cache-Control'] = 'no-cache'
    response['X-Accel-Buffering'] = 'no'
    return response
```

### í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš© ì˜ˆì œ

```javascript
// JavaScriptì—ì„œ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬
async function streamAIResponse(prompt) {
    const response = await fetch('/api/ai/stream-text', {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json',
        },
        body: JSON.stringify({
            prompt: prompt,
            model: 'gpt-4',
            temperature: 0.7
        })
    });

    const reader = response.body.getReader();
    const decoder = new TextDecoder();

    while (true) {
        const { done, value } = await reader.read();
        if (done) break;

        const chunk = decoder.decode(value);
        const lines = chunk.split('\n');

        for (const line of lines) {
            if (line.startsWith('data: ')) {
                const data = line.slice(6);
                if (data === '[DONE]') {
                    console.log('ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ');
                    return;
                }
                
                try {
                    const json = JSON.parse(data);
                    if (json.content) {
                        // ì‹¤ì‹œê°„ìœ¼ë¡œ í…ìŠ¤íŠ¸ í‘œì‹œ
                        document.getElementById('output').innerText += json.content;
                    }
                } catch (e) {
                    console.error('JSON íŒŒì‹± ì—ëŸ¬:', e);
                }
            }
        }
    }
}

// ì‚¬ìš© ì˜ˆì œ
streamAIResponse('Pythonìœ¼ë¡œ ê°„ë‹¨í•œ ì›¹ ì„œë²„ë¥¼ ë§Œë“œëŠ” ë°©ë²•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.');
```

ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ì„ ì‚¬ìš©í•˜ë©´ ì‚¬ìš©ìê°€ ì „ì²´ ì‘ë‹µì„ ê¸°ë‹¤ë¦¬ì§€ ì•Šê³  ì¦‰ì‹œ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆì–´ í›¨ì”¬ ë” ë°˜ì‘ì„± ìˆëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ì—ëŸ¬ í•¸ë“¤ë§ ë° ë¹„ìš© ìµœì í™”

í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” ê²¬ê³ í•œ ì—ëŸ¬ í•¸ë“¤ë§ê³¼ ë¹„ìš© ìµœì í™”ê°€ í•„ìˆ˜ì ì…ë‹ˆë‹¤.

### ì»¤ìŠ¤í…€ ì˜ˆì™¸ ì²˜ë¦¬

```python
# ai_api/exceptions.py
class AIServiceException(Exception):
    """AI ì„œë¹„ìŠ¤ ê¸°ë³¸ ì˜ˆì™¸"""
    pass

class RateLimitException(AIServiceException):
    """API ìš”ì²­ ì œí•œ ì´ˆê³¼"""
    pass

class InvalidRequestException(AIServiceException):
    """ì˜ëª»ëœ ìš”ì²­"""
    pass

class InsufficientQuotaException(AIServiceException):
    """í• ë‹¹ëŸ‰ ë¶€ì¡±"""
    pass
```

### ì—ëŸ¬ í•¸ë“¤ëŸ¬ ë“±ë¡

```python
# ai_api/api.pyì— ì¶”ê°€
from ninja import NinjaAPI
from ninja.errors import ValidationError
from .exceptions import (
    AIServiceException,
    RateLimitException,
    InsufficientQuotaException
)

@api.exception_handler(RateLimitException)
def handle_rate_limit(request, exc):
    return api.create_response(
        request,
        {"detail": "API ìš”ì²­ ì œí•œì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."},
        status=429
    )

@api.exception_handler(InsufficientQuotaException)
def handle_quota_error(request, exc):
    return api.create_response(
        request,
        {"detail": "API í• ë‹¹ëŸ‰ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”."},
        status=402
    )

@api.exception_handler(ValidationError)
def handle_validation_error(request, exc):
    return api.create_response(
        request,
        {"detail": "ì…ë ¥ ë°ì´í„°ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.", "errors": exc.errors},
        status=422
    )

@api.exception_handler(AIServiceException)
def handle_ai_service_error(request, exc):
    logger.error(f"AI Service Error: {str(exc)}")
    return api.create_response(
        request,
        {"detail": "AI ì„œë¹„ìŠ¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."},
        status=500
    )
```

### ìš”ì²­ ì œí•œ (Rate Limiting)

```python
# ai_api/middleware.py
from django.core.cache import cache
from django.http import JsonResponse
import time

class RateLimitMiddleware:
    """API ìš”ì²­ ì œí•œ ë¯¸ë“¤ì›¨ì–´"""
    
    def __init__(self, get_response):
        self.get_response = get_response
        self.rate_limit = 100  # ë¶„ë‹¹ ìš”ì²­ ìˆ˜
        self.window = 60  # ì‹œê°„ ìœˆë„ìš° (ì´ˆ)
    
    def __call__(self, request):
        if request.path.startswith('/api/ai/'):
            # IP ê¸°ë°˜ ìš”ì²­ ì œí•œ
            client_ip = self.get_client_ip(request)
            cache_key = f'rate_limit:{client_ip}'
            
            requests = cache.get(cache_key, [])
            now = time.time()
            
            # ì‹œê°„ ìœˆë„ìš° ë‚´ì˜ ìš”ì²­ë§Œ ìœ ì§€
            requests = [req_time for req_time in requests 
                       if now - req_time < self.window]
            
            if len(requests) >= self.rate_limit:
                return JsonResponse(
                    {'detail': 'ìš”ì²­ ì œí•œì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.'},
                    status=429
                )
            
            requests.append(now)
            cache.set(cache_key, requests, self.window)
        
        return self.get_response(request)
    
    def get_client_ip(self, request):
        """í´ë¼ì´ì–¸íŠ¸ IP ì£¼ì†Œ ì¶”ì¶œ"""
        x_forwarded_for = request.META.get('HTTP_X_FORWARDED_FOR')
        if x_forwarded_for:
            ip = x_forwarded_for.split(',')[0]
        else:
            ip = request.META.get('REMOTE_ADDR')
        return ip
```

### ë¹„ìš© ì¶”ì  ë° ëª¨ë‹ˆí„°ë§

```python
# ai_api/models.py
from django.db import models
from django.contrib.auth.models import User

class APIUsage(models.Model):
    """API ì‚¬ìš©ëŸ‰ ì¶”ì  ëª¨ë¸"""
    
    user = models.ForeignKey(User, on_delete=models.CASCADE, null=True, blank=True)
    endpoint = models.CharField(max_length=100)
    model = models.CharField(max_length=50)
    prompt_tokens = models.IntegerField(default=0)
    completion_tokens = models.IntegerField(default=0)
    total_tokens = models.IntegerField(default=0)
    estimated_cost = models.DecimalField(max_digits=10, decimal_places=6)
    created_at = models.DateTimeField(auto_now_add=True)
    
    class Meta:
        ordering = ['-created_at']
        indexes = [
            models.Index(fields=['user', 'created_at']),
            models.Index(fields=['endpoint', 'created_at']),
        ]
    
    def __str__(self):
        return f"{self.endpoint} - {self.total_tokens} tokens"

# ai_api/services.pyì— ì¶”ê°€
class AIService:
    # ëª¨ë¸ë³„ ê°€ê²© (1000 í† í°ë‹¹ USD)
    PRICING = {
        'gpt-4': {'input': 0.03, 'output': 0.06},
        'gpt-4-turbo': {'input': 0.01, 'output': 0.03},
        'gpt-3.5-turbo': {'input': 0.0005, 'output': 0.0015},
    }
    
    def calculate_cost(self, model: str, prompt_tokens: int, completion_tokens: int) -> float:
        """í† í° ì‚¬ìš©ëŸ‰ ê¸°ë°˜ ë¹„ìš© ê³„ì‚°"""
        pricing = self.PRICING.get(model, self.PRICING['gpt-4'])
        
        input_cost = (prompt_tokens / 1000) * pricing['input']
        output_cost = (completion_tokens / 1000) * pricing['output']
        
        return input_cost + output_cost
    
    def log_usage(self, endpoint: str, model: str, usage: dict, user=None):
        """API ì‚¬ìš©ëŸ‰ ë¡œê¹…"""
        from .models import APIUsage
        
        cost = self.calculate_cost(
            model,
            usage['prompt_tokens'],
            usage['completion_tokens']
        )
        
        APIUsage.objects.create(
            user=user,
            endpoint=endpoint,
            model=model,
            prompt_tokens=usage['prompt_tokens'],
            completion_tokens=usage['completion_tokens'],
            total_tokens=usage['total_tokens'],
            estimated_cost=cost
        )
        
        return cost
```

### ìºì‹± ì „ëµ

```python
# ai_api/services.pyì— ì¶”ê°€
from django.core.cache import cache
import hashlib

class AIService:
    # ... ê¸°ì¡´ ì½”ë“œ ...
    
    def get_cached_or_generate(
        self,
        prompt: str,
        model: str = "gpt-4",
        **kwargs
    ) -> Dict[str, Any]:
        """
        ìºì‹œë¥¼ í™œìš©í•œ í…ìŠ¤íŠ¸ ìƒì„±
        ë™ì¼í•œ ìš”ì²­ì€ ìºì‹œëœ ê²°ê³¼ ë°˜í™˜
        """
        # ìºì‹œ í‚¤ ìƒì„±
        cache_key = self._generate_cache_key(prompt, model, kwargs)
        
        # ìºì‹œ í™•ì¸
        cached_result = cache.get(cache_key)
        if cached_result:
            logger.info(f"Cache hit for prompt: {prompt[:50]}...")
            return cached_result
        
        # ìºì‹œ ë¯¸ìŠ¤ - API í˜¸ì¶œ
        result = self.generate_text(prompt, model, **kwargs)
        
        # ê²°ê³¼ ìºì‹± (24ì‹œê°„)
        cache.set(cache_key, result, 60 * 60 * 24)
        
        return result
    
    def _generate_cache_key(self, prompt: str, model: str, params: dict) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        key_string = f"{prompt}:{model}:{sorted(params.items())}"
        return f"ai_cache:{hashlib.md5(key_string.encode()).hexdigest()}"
```

ì´ëŸ¬í•œ ìµœì í™”ë¥¼ í†µí•´ API ë¹„ìš©ì„ í¬ê²Œ ì ˆê°í•˜ê³  ì•ˆì •ì ì¸ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## í…ŒìŠ¤íŠ¸ ë° ë°°í¬

í”„ë¡œë•ì…˜ ë°°í¬ ì „ ì² ì €í•œ í…ŒìŠ¤íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤.

### ë‹¨ìœ„ í…ŒìŠ¤íŠ¸

```python
# ai_api/tests.py
from django.test import TestCase
from unittest.mock import patch, MagicMock
from .services import AIService
from .schemas import TextGenerationRequest

class AIServiceTestCase(TestCase):
    """AI ì„œë¹„ìŠ¤ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸"""
    
    def setUp(self):
        self.ai_service = AIService()
    
    @patch('openai.OpenAI')
    def test_generate_text_success(self, mock_openai):
        """í…ìŠ¤íŠ¸ ìƒì„± ì„±ê³µ í…ŒìŠ¤íŠ¸"""
        # Mock ì„¤ì •
        mock_response = MagicMock()
        mock_response.choices = [MagicMock()]
        mock_response.choices[0].message.content = "Test response"
        mock_response.model = "gpt-4"
        mock_response.usage.prompt_tokens = 10
        mock_response.usage.completion_tokens = 20
        mock_response.usage.total_tokens = 30
        mock_response.choices[0].finish_reason = "stop"
        
        mock_openai.return_value.chat.completions.create.return_value = mock_response
        
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        result = self.ai_service.generate_text("Test prompt")
        
        # ê²€ì¦
        self.assertEqual(result['text'], "Test response")
        self.assertEqual(result['model'], "gpt-4")
        self.assertEqual(result['usage']['total_tokens'], 30)
    
    def test_cache_key_generation(self):
        """ìºì‹œ í‚¤ ìƒì„± í…ŒìŠ¤íŠ¸"""
        key1 = self.ai_service._generate_cache_key("prompt", "gpt-4", {})
        key2 = self.ai_service._generate_cache_key("prompt", "gpt-4", {})
        key3 = self.ai_service._generate_cache_key("different", "gpt-4", {})
        
        self.assertEqual(key1, key2)
        self.assertNotEqual(key1, key3)
    
    def test_cost_calculation(self):
        """ë¹„ìš© ê³„ì‚° í…ŒìŠ¤íŠ¸"""
        cost = self.ai_service.calculate_cost("gpt-4", 1000, 1000)
        expected = (1000/1000 * 0.03) + (1000/1000 * 0.06)
        self.assertEqual(cost, expected)

class APIEndpointTestCase(TestCase):
    """API ì—”ë“œí¬ì¸íŠ¸ í†µí•© í…ŒìŠ¤íŠ¸"""
    
    @patch('ai_api.services.ai_service.generate_text')
    def test_generate_text_endpoint(self, mock_generate):
        """í…ìŠ¤íŠ¸ ìƒì„± ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸"""
        mock_generate.return_value = {
            'text': 'Generated text',
            'model': 'gpt-4',
            'usage': {'prompt_tokens': 10, 'completion_tokens': 20, 'total_tokens': 30},
            'finish_reason': 'stop'
        }
        
        response = self.client.post(
            '/api/ai/generate-text',
            data={
                'prompt': 'Test prompt',
                'model': 'gpt-4',
                'max_tokens': 1000,
                'temperature': 0.7
            },
            content_type='application/json'
        )
        
        self.assertEqual(response.status_code, 200)
        data = response.json()
        self.assertEqual(data['text'], 'Generated text')
    
    def test_health_check(self):
        """í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸"""
        response = self.client.get('/api/ai/health')
        self.assertEqual(response.status_code, 200)
        self.assertEqual(response.json()['status'], 'healthy')

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
# python manage.py test ai_api
```

### Docker ë°°í¬ ì„¤ì •

```dockerfile
# Dockerfile
FROM python:3.11-slim

# ì‘ì—… ë””ë ‰í† ë¦¬ ì„¤ì •
WORKDIR /app

# ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì—…ë°ì´íŠ¸
RUN apt-get update && apt-get install -y \
    gcc \
    postgresql-client \
    && rm -rf /var/lib/apt/lists/*

# Python ì˜ì¡´ì„± ì„¤ì¹˜
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œ ë³µì‚¬
COPY . .

# ì •ì  íŒŒì¼ ìˆ˜ì§‘
RUN python manage.py collectstatic --noinput

# Gunicornìœ¼ë¡œ ì‹¤í–‰
CMD ["gunicorn", "--bind", "0.0.0.0:8000", "--workers", "4", "ai_project.wsgi:application"]
```

```yaml
# docker-compose.yml
version: '3.8'

services:
  web:
    build: .
    command: gunicorn ai_project.wsgi:application --bind 0.0.0.0:8000 --workers 4
    volumes:
      - .:/app
      - static_volume:/app/staticfiles
    ports:
      - "8000:8000"
    env_file:
      - .env
    depends_on:
      - db
      - redis
  
  db:
    image: postgres:15
    volumes:
      - postgres_data:/var/lib/postgresql/data
    environment:
      - POSTGRES_DB=ai_api
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
  
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
  
  nginx:
    image: nginx:alpine
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - static_volume:/app/staticfiles
    ports:
      - "80:80"
    depends_on:
      - web

volumes:
  postgres_data:
  static_volume:
```

### requirements.txt

```txt
Django==5.0.1
django-ninja==1.1.0
openai==1.10.0
python-dotenv==1.0.0
gunicorn==21.2.0
psycopg2-binary==2.9.9
redis==5.0.1
django-redis==5.4.0
```

### í”„ë¡œë•ì…˜ ì„¤ì •

```python
# ai_project/settings_prod.py
from .settings import *

DEBUG = False
ALLOWED_HOSTS = ['your-domain.com', 'www.your-domain.com']

# ìºì‹œ ì„¤ì •
CACHES = {
    'default': {
        'BACKEND': 'django_redis.cache.RedisCache',
        'LOCATION': 'redis://redis:6379/1',
        'OPTIONS': {
            'CLIENT_CLASS': 'django_redis.client.DefaultClient',
        }
    }
}

# ë¡œê¹… ì„¤ì •
LOGGING = {
    'version': 1,
    'disable_existing_loggers': False,
    'formatters': {
        'verbose': {
            'format': '{levelname} {asctime} {module} {message}',
            'style': '{',
        },
    },
    'handlers': {
        'file': {
            'level': 'INFO',
            'class': 'logging.FileHandler',
            'filename': '/var/log/django/ai_api.log',
            'formatter': 'verbose',
        },
        'console': {
            'level': 'INFO',
            'class': 'logging.StreamHandler',
            'formatter': 'verbose',
        },
    },
    'root': {
        'handlers': ['console', 'file'],
        'level': 'INFO',
    },
}

# ë³´ì•ˆ ì„¤ì •
SECURE_SSL_REDIRECT = True
SESSION_COOKIE_SECURE = True
CSRF_COOKIE_SECURE = True
SECURE_BROWSER_XSS_FILTER = True
```

### ë°°í¬ ìŠ¤í¬ë¦½íŠ¸

```bash
#!/bin/bash
# deploy.sh

echo "ğŸš€ Django Ninja AI API ë°°í¬ ì‹œì‘..."

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
source .env

# Docker ì´ë¯¸ì§€ ë¹Œë“œ
echo "ğŸ“¦ Docker ì´ë¯¸ì§€ ë¹Œë“œ ì¤‘..."
docker-compose build

# ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜
echo "ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜..."
docker-compose run --rm web python manage.py migrate

# ì •ì  íŒŒì¼ ìˆ˜ì§‘
echo "ğŸ“ ì •ì  íŒŒì¼ ìˆ˜ì§‘..."
docker-compose run --rm web python manage.py collectstatic --noinput

# ì»¨í…Œì´ë„ˆ ì‹œì‘
echo "ğŸ¯ ì„œë¹„ìŠ¤ ì‹œì‘..."
docker-compose up -d

echo "âœ… ë°°í¬ ì™„ë£Œ!"
echo "API ë¬¸ì„œ: http://your-domain.com/api/docs"
```

## ê²°ë¡ 

Django Ninjaë¥¼ ì‚¬ìš©í•œ AI API ì„œë²„ êµ¬ì¶•ì˜ ì „ì²´ ê³¼ì •ì„ ì‚´í´ë³´ì•˜ìŠµë‹ˆë‹¤. ì´ ê°€ì´ë“œì—ì„œ ë‹¤ë£¬ ì£¼ìš” ë‚´ìš©ì„ ì •ë¦¬í•˜ë©´:

### í•µì‹¬ í¬ì¸íŠ¸

1. **Django Ninjaì˜ ì¥ì **
   - FastAPI ìŠ¤íƒ€ì¼ì˜ ì§ê´€ì ì¸ API ê°œë°œ
   - ìë™ ë¬¸ì„œí™” (Swagger/OpenAPI)
   - íƒ€ì… ì•ˆì •ì„±ê³¼ ë°ì´í„° ê²€ì¦
   - Django ìƒíƒœê³„ì™€ì˜ ì™„ë²½í•œ í†µí•©

2. **AI í†µí•© ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤**
   - ì„œë¹„ìŠ¤ ë ˆì´ì–´ íŒ¨í„´ìœ¼ë¡œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ë¶„ë¦¬
   - ìŠ¤í‚¤ë§ˆë¥¼ í†µí•œ ëª…í™•í•œ API ê³„ì•½
   - ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µìœ¼ë¡œ UX í–¥ìƒ
   - ì—ëŸ¬ í•¸ë“¤ë§ê³¼ ë¡œê¹…

3. **í”„ë¡œë•ì…˜ ì¤€ë¹„ì‚¬í•­**
   - Rate Limitingìœ¼ë¡œ ì„œë¹„ìŠ¤ ë³´í˜¸
   - ìºì‹±ì„ í†µí•œ ë¹„ìš© ì ˆê°
   - ì‚¬ìš©ëŸ‰ ì¶”ì  ë° ëª¨ë‹ˆí„°ë§
   - ì»¨í…Œì´ë„ˆí™” ë° ë°°í¬ ìë™í™”

### ë‹¤ìŒ ë‹¨ê³„

ì´ ê¸°ë³¸ êµ¬ì¡°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ê¸°ëŠ¥ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

- **ì¸ì¦ ë° ê¶Œí•œ ê´€ë¦¬**: JWT í† í° ê¸°ë°˜ ì¸ì¦
- **ì›¹ì†Œì¼“ í†µí•©**: ì‹¤ì‹œê°„ ì–‘ë°©í–¥ í†µì‹ 
- **ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…**: Celeryë¥¼ í†µí•œ ë¹„ë™ê¸° ì²˜ë¦¬
- **ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤**: ì„ë² ë”© ê¸°ë°˜ ê²€ìƒ‰ (Pinecone, Weaviate)
- **ë©€í‹°ëª¨ë‹¬ AI**: ì´ë¯¸ì§€ ìƒì„±, ìŒì„± ì¸ì‹ ë“±

### ì°¸ê³  ìë£Œ

- [Django Ninja ê³µì‹ ë¬¸ì„œ](https://django-ninja.rest-framework.com/)
- [OpenAI API ë¬¸ì„œ](https://platform.openai.com/docs)
- [Django ê³µì‹ ë¬¸ì„œ](https://docs.djangoproject.com/)

Django Ninjaì™€ OpenAIì˜ ì¡°í•©ì€ ë¹ ë¥´ê³  í™•ì¥ ê°€ëŠ¥í•œ AI ì• í”Œë¦¬ì¼€ì´ì…˜ì„ êµ¬ì¶•í•˜ëŠ” ë° ì´ìƒì ì¸ ì„ íƒì…ë‹ˆë‹¤. ì´ ê°€ì´ë“œê°€ ì—¬ëŸ¬ë¶„ì˜ AI í”„ë¡œì íŠ¸ì— ë„ì›€ì´ ë˜ê¸°ë¥¼ ë°”ëë‹ˆë‹¤!

---

**ê´€ë ¨ í¬ìŠ¤íŠ¸**
- [Django 5.0/5.1 ì£¼ìš” ê¸°ëŠ¥ ë¦¬ë·°]({% post_url 2025-01-17-django-5.0-5.1-major-features-review %})

**íƒœê·¸**: #Django #DjangoNinja #OpenAI #AI #API #Python #WebDevelopment

