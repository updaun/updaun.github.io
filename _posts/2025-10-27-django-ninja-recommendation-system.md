---
layout: post
title: "Django Ninjaë¡œ êµ¬ì¶•í•˜ëŠ” ì§€ëŠ¥í˜• ì¶”ì²œì‹œìŠ¤í…œ - í˜‘ì—… í•„í„°ë§ë¶€í„° ë”¥ëŸ¬ë‹ê¹Œì§€"
subtitle: "ì‹¤ì‹œê°„ ê°œì¸í™” ì¶”ì²œ ì—”ì§„ ì™„ë²½ êµ¬í˜„ ê°€ì´ë“œ"
date: 2025-10-27 10:00:00 +0900
background: '/img/posts/django-ninja-recommendation-bg.jpg'
categories: [Django, MachineLearning, AI]
tags: [django-ninja, recommendation-system, collaborative-filtering, machine-learning, personalization, fastapi]
---

# ğŸ¤– Django Ninjaë¡œ êµ¬ì¶•í•˜ëŠ” ì§€ëŠ¥í˜• ì¶”ì²œì‹œìŠ¤í…œ

í˜„ëŒ€ ì„œë¹„ìŠ¤ì—ì„œ **ê°œì¸í™” ì¶”ì²œ**ì€ ì‚¬ìš©ì ê²½í—˜ê³¼ ë¹„ì¦ˆë‹ˆìŠ¤ ì„±ê³¼ë¥¼ ê²°ì •í•˜ëŠ” í•µì‹¬ ìš”ì†Œì…ë‹ˆë‹¤. Netflixì˜ ì˜í™” ì¶”ì²œ, Amazonì˜ ìƒí’ˆ ì¶”ì²œ, Spotifyì˜ ìŒì•… ì¶”ì²œ ë“± ëª¨ë“  ì„±ê³µí•œ í”Œë«í¼ì€ ê°•ë ¥í•œ ì¶”ì²œ ì—”ì§„ì„ ë³´ìœ í•˜ê³  ìˆì£ .

ì´ë²ˆ í¬ìŠ¤íŠ¸ì—ì„œëŠ” **Django Ninja**ë¥¼ ê¸°ë°˜ìœ¼ë¡œ **ì‹¤ë¬´ì—ì„œ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì¶”ì²œì‹œìŠ¤í…œ**ì„ êµ¬ì¶•í•´ë³´ê² ìŠµë‹ˆë‹¤. ê¸°ë³¸ì ì¸ í˜‘ì—… í•„í„°ë§ë¶€í„° ìµœì‹  ë”¥ëŸ¬ë‹ ê¸°ë²•ê¹Œì§€ ë‹¨ê³„ë³„ë¡œ êµ¬í˜„í•´ë³´ê² ìŠµë‹ˆë‹¤.

## ğŸ¯ êµ¬í˜„í•  ì¶”ì²œì‹œìŠ¤í…œ ê¸°ëŠ¥

- **í˜‘ì—… í•„í„°ë§** (User-Based, Item-Based)
- **ì½˜í…ì¸  ê¸°ë°˜ í•„í„°ë§** (Content-Based Filtering)
- **í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ** (Multiple Algorithms)
- **ì‹¤ì‹œê°„ ì¶”ì²œ** (Real-time Recommendations)
- **A/B í…ŒìŠ¤íŠ¸** ì§€ì›
- **ì¶”ì²œ ì„±ê³¼ ë¶„ì„** (CTR, Conversion Rate)
- **ì½œë“œ ìŠ¤íƒ€íŠ¸ ë¬¸ì œ** í•´ê²°

---

## ğŸ“Š 1. ì¶”ì²œì‹œìŠ¤í…œ ê¸°ì´ˆ ì„¤ê³„

ë¨¼ì € ì¶”ì²œì‹œìŠ¤í…œì˜ í•µì‹¬ ê°œë…ê³¼ ì•„í‚¤í…ì²˜ë¥¼ ì´í•´í•˜ê³  í”„ë¡œì íŠ¸ êµ¬ì¡°ë¥¼ ì„¤ê³„í•´ë³´ê² ìŠµë‹ˆë‹¤.

### 1.1 ì¶”ì²œì‹œìŠ¤í…œ ìœ í˜•ë³„ íŠ¹ì§•

```python
# docs/recommendation_types.py
"""
ì¶”ì²œì‹œìŠ¤í…œ ì£¼ìš” ìœ í˜•ê³¼ íŠ¹ì§•

1. í˜‘ì—… í•„í„°ë§ (Collaborative Filtering)
   - User-Based CF: ë¹„ìŠ·í•œ ì‚¬ìš©ìë“¤ì´ ì¢‹ì•„í•œ ì•„ì´í…œ ì¶”ì²œ
   - Item-Based CF: ì‚¬ìš©ìê°€ ì¢‹ì•„í•œ ì•„ì´í…œê³¼ ìœ ì‚¬í•œ ì•„ì´í…œ ì¶”ì²œ
   
   ì¥ì : ë„ë©”ì¸ ì§€ì‹ ë¶ˆí•„ìš”, ì˜ì™¸ì„±(Serendipity) ì œê³µ
   ë‹¨ì : ì½œë“œ ìŠ¤íƒ€íŠ¸ ë¬¸ì œ, í¬ì†Œì„± ë¬¸ì œ, í™•ì¥ì„± ì´ìŠˆ

2. ì½˜í…ì¸  ê¸°ë°˜ í•„í„°ë§ (Content-Based Filtering)
   - ì•„ì´í…œì˜ ì†ì„±/íŠ¹ì§•ì„ ë¶„ì„í•˜ì—¬ ìœ ì‚¬ ì•„ì´í…œ ì¶”ì²œ
   
   ì¥ì : ì½œë“œ ìŠ¤íƒ€íŠ¸ ë¬¸ì œ í•´ê²°, íˆ¬ëª…í•œ ì¶”ì²œ ì´ìœ 
   ë‹¨ì : ê³¼ì í•©, ë‹¤ì–‘ì„± ë¶€ì¡±, ë„ë©”ì¸ ì§€ì‹ í•„ìš”

3. í•˜ì´ë¸Œë¦¬ë“œ (Hybrid)
   - ì—¬ëŸ¬ ë°©ë²•ì„ ì¡°í•©í•˜ì—¬ ê°ê°ì˜ ë‹¨ì  ë³´ì™„
   
   ë°©ì‹: Weighted, Switching, Cascade, Mixed, Feature Combination
"""

class RecommendationStrategy:
    """ì¶”ì²œ ì „ëµ ì¸í„°í˜ì´ìŠ¤"""
    
    def recommend(self, user_id: int, num_recommendations: int = 10) -> List[Dict]:
        raise NotImplementedError
    
    def explain(self, user_id: int, item_id: int) -> Dict:
        """ì¶”ì²œ ì´ìœ  ì„¤ëª…"""
        raise NotImplementedError
    
    def get_performance_metrics(self) -> Dict:
        """ì¶”ì²œ ì„±ê³¼ ì§€í‘œ"""
        raise NotImplementedError
```

### 1.2 í”„ë¡œì íŠ¸ êµ¬ì¡° ì„¤ì •

```bash
# requirements.txt
django==4.2.7
django-ninja==1.0.1
numpy==1.24.3
pandas==2.0.3
scikit-learn==1.3.0
scipy==1.11.1
redis==5.0.1
celery==5.3.4

# ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ìš©
surprise==1.1.3
implicit==0.7.2
lightfm==1.17

# ë”¥ëŸ¬ë‹ (ì„ íƒì‚¬í•­)
torch==2.0.1
sentence-transformers==2.2.2

# ë°ì´í„° ì²˜ë¦¬
sqlalchemy==2.0.19
psycopg2-binary==2.9.9

# ëª¨ë‹ˆí„°ë§
prometheus-client==0.17.1
```

```python
# config/settings/base.py
from pathlib import Path
from decouple import config

# ì¶”ì²œì‹œìŠ¤í…œ ì„¤ì •
RECOMMENDATION_SETTINGS = {
    # ê¸°ë³¸ ì„¤ì •
    'DEFAULT_ALGORITHM': 'collaborative_filtering',
    'DEFAULT_NUM_RECOMMENDATIONS': 10,
    'MAX_RECOMMENDATIONS': 50,
    
    # ì„±ëŠ¥ ì„¤ì •
    'BATCH_SIZE': 1000,
    'CACHE_TTL': 3600,  # 1ì‹œê°„
    'MODEL_UPDATE_INTERVAL': 86400,  # 24ì‹œê°„
    
    # ì•Œê³ ë¦¬ì¦˜ë³„ íŒŒë¼ë¯¸í„°
    'COLLABORATIVE_FILTERING': {
        'similarity_metric': 'cosine',
        'min_interactions': 5,
        'n_neighbors': 50,
    },
    
    'CONTENT_BASED': {
        'feature_weights': {
            'category': 0.3,
            'brand': 0.2,
            'price_range': 0.1,
            'description': 0.4,
        }
    },
    
    # A/B í…ŒìŠ¤íŠ¸ ì„¤ì •
    'AB_TEST': {
        'enabled': True,
        'test_ratio': 0.1,  # 10% ì‚¬ìš©ìê°€ í…ŒìŠ¤íŠ¸ ê·¸ë£¹
    }
}

# Redis ì„¤ì • (ìºì‹±ìš©)
REDIS_URL = config('REDIS_URL', default='redis://localhost:6379/0')
CACHES = {
    'default': {
        'BACKEND': 'django_redis.cache.RedisCache',
        'LOCATION': REDIS_URL,
        'OPTIONS': {
            'CLIENT_CLASS': 'django_redis.client.DefaultClient',
        }
    }
}

INSTALLED_APPS = [
    'django.contrib.admin',
    'django.contrib.auth',
    'django.contrib.contenttypes',
    'django.contrib.sessions',
    'django.contrib.messages',
    'django.contrib.staticfiles',
    
    # Third party
    'ninja',
    'django_extensions',
    'django_redis',
    
    # Local apps
    'apps.accounts',
    'apps.products',
    'apps.recommendations',  # ìƒˆë¡œ ìƒì„±
    'apps.analytics',        # ìƒˆë¡œ ìƒì„±
]
```

### 1.3 í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
recommendation_system/
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ recommendations/
â”‚   â”‚   â”œâ”€â”€ models.py              # ì¶”ì²œ ê´€ë ¨ ëª¨ë¸
â”‚   â”‚   â”œâ”€â”€ algorithms/            # ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ë“¤
â”‚   â”‚   â”‚   â”œâ”€â”€ collaborative.py   # í˜‘ì—… í•„í„°ë§
â”‚   â”‚   â”‚   â”œâ”€â”€ content_based.py   # ì½˜í…ì¸  ê¸°ë°˜
â”‚   â”‚   â”‚   â”œâ”€â”€ hybrid.py          # í•˜ì´ë¸Œë¦¬ë“œ
â”‚   â”‚   â”‚   â””â”€â”€ deep_learning.py   # ë”¥ëŸ¬ë‹ ê¸°ë°˜
â”‚   â”‚   â”œâ”€â”€ services.py            # ì¶”ì²œ ì„œë¹„ìŠ¤ ë¡œì§
â”‚   â”‚   â”œâ”€â”€ api.py                 # Django Ninja API
â”‚   â”‚   â”œâ”€â”€ tasks.py               # Celery ë¹„ë™ê¸° ì‘ì—…
â”‚   â”‚   â”œâ”€â”€ schemas.py             # Pydantic ìŠ¤í‚¤ë§ˆ
â”‚   â”‚   â””â”€â”€ utils/                 # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
â”‚   â”‚       â”œâ”€â”€ metrics.py         # ì„±ê³¼ ì¸¡ì •
â”‚   â”‚       â”œâ”€â”€ data_processor.py  # ë°ì´í„° ì „ì²˜ë¦¬
â”‚   â”‚       â””â”€â”€ cache_manager.py   # ìºì‹œ ê´€ë¦¬
â”‚   â”œâ”€â”€ products/
â”‚   â”‚   â””â”€â”€ models.py              # ìƒí’ˆ ëª¨ë¸
â”‚   â”œâ”€â”€ accounts/
â”‚   â”‚   â””â”€â”€ models.py              # ì‚¬ìš©ì ëª¨ë¸
â”‚   â””â”€â”€ analytics/
â”‚       â”œâ”€â”€ models.py              # ë¶„ì„ ë°ì´í„° ëª¨ë¸
â”‚       â””â”€â”€ services.py            # ë¶„ì„ ì„œë¹„ìŠ¤
â”œâ”€â”€ ml_models/                     # í›ˆë ¨ëœ ëª¨ë¸ ì €ì¥
â”œâ”€â”€ data/                          # ë°ì´í„° íŒŒì¼ë“¤
â””â”€â”€ notebooks/                     # ì£¼í”¼í„° ë…¸íŠ¸ë¶ (ì‹¤í—˜ìš©)
```

---

## ğŸ—ï¸ 2. ë°ì´í„° ëª¨ë¸ ë° ìŠ¤í‚¤ë§ˆ ì„¤ê³„

ì¶”ì²œì‹œìŠ¤í…œì˜ í•µì‹¬ì´ ë˜ëŠ” ë°ì´í„° ëª¨ë¸ë“¤ì„ ì„¤ê³„í•´ë³´ê² ìŠµë‹ˆë‹¤.

### 2.1 ê¸°ë³¸ ì—”í‹°í‹° ëª¨ë¸

```python
# apps/products/models.py
from django.db import models
from django.contrib.auth.models import User
from django.contrib.postgres.fields import ArrayField
from model_utils.models import TimeStampedModel

class Category(TimeStampedModel):
    """ìƒí’ˆ ì¹´í…Œê³ ë¦¬"""
    name = models.CharField(max_length=100, unique=True)
    parent = models.ForeignKey('self', on_delete=models.CASCADE, null=True, blank=True)
    level = models.IntegerField(default=0)
    
    def __str__(self):
        return self.name

class Brand(TimeStampedModel):
    """ë¸Œëœë“œ"""
    name = models.CharField(max_length=100, unique=True)
    description = models.TextField(blank=True)
    
    def __str__(self):
        return self.name

class Product(TimeStampedModel):
    """ìƒí’ˆ"""
    name = models.CharField(max_length=200)
    description = models.TextField()
    category = models.ForeignKey(Category, on_delete=models.PROTECT, related_name='products')
    brand = models.ForeignKey(Brand, on_delete=models.PROTECT, related_name='products')
    
    # ê°€ê²© ì •ë³´
    price = models.DecimalField(max_digits=10, decimal_places=2)
    original_price = models.DecimalField(max_digits=10, decimal_places=2, null=True, blank=True)
    
    # ì¶”ì²œì‹œìŠ¤í…œìš© ë©”íƒ€ë°ì´í„°
    tags = ArrayField(models.CharField(max_length=50), default=list, blank=True)
    attributes = models.JSONField(default=dict, blank=True)  # ìƒ‰ìƒ, ì‚¬ì´ì¦ˆ, ì†Œì¬ ë“±
    
    # í†µê³„ ì •ë³´
    view_count = models.IntegerField(default=0)
    purchase_count = models.IntegerField(default=0)
    rating_sum = models.IntegerField(default=0)
    rating_count = models.IntegerField(default=0)
    
    # ìƒí’ˆ ìƒíƒœ
    is_active = models.BooleanField(default=True)
    stock_quantity = models.IntegerField(default=0)
    
    class Meta:
        indexes = [
            models.Index(fields=['category', 'is_active']),
            models.Index(fields=['brand', 'is_active']),
            models.Index(fields=['price']),
            models.Index(fields=['view_count']),
            models.Index(fields=['purchase_count']),
        ]
    
    def __str__(self):
        return self.name
    
    @property
    def average_rating(self):
        if self.rating_count > 0:
            return self.rating_sum / self.rating_count
        return 0
    
    @property
    def discount_rate(self):
        if self.original_price:
            return (self.original_price - self.price) / self.original_price * 100
        return 0

# apps/accounts/models.py
class UserProfile(TimeStampedModel):
    """ì‚¬ìš©ì í”„ë¡œí•„ í™•ì¥"""
    user = models.OneToOneField(User, on_delete=models.CASCADE, related_name='profile')
    
    # ì¸êµ¬í†µê³„í•™ì  ì •ë³´
    age_range = models.CharField(max_length=20, blank=True)  # 20-29, 30-39 ë“±
    gender = models.CharField(max_length=10, blank=True)
    location = models.CharField(max_length=100, blank=True)
    
    # ì„ í˜¸ë„ ì •ë³´
    preferred_categories = models.ManyToManyField(Category, blank=True)
    preferred_brands = models.ManyToManyField(Brand, blank=True)
    preferred_price_range = models.JSONField(default=dict, blank=True)  # min, max
    
    # í–‰ë™ íŒ¨í„´
    shopping_frequency = models.CharField(max_length=20, blank=True)  # weekly, monthly ë“±
    preferred_shopping_time = models.CharField(max_length=20, blank=True)  # morning, evening ë“±
    
    # ê°œì¸í™” ì„¤ì •
    recommendation_enabled = models.BooleanField(default=True)
    email_recommendations = models.BooleanField(default=True)
    
    def __str__(self):
        return f"{self.user.username} Profile"
```

### 2.2 ìƒí˜¸ì‘ìš© ë° ì¶”ì²œ ëª¨ë¸

```python
# apps/recommendations/models.py
from django.db import models
from django.contrib.auth.models import User
from django.contrib.contenttypes.fields import GenericForeignKey
from django.contrib.contenttypes.models import ContentType
from model_utils.models import TimeStampedModel
from model_utils import Choices

class InteractionType(models.TextChoices):
    """ìƒí˜¸ì‘ìš© ìœ í˜•"""
    VIEW = 'view', 'ì¡°íšŒ'
    LIKE = 'like', 'ì¢‹ì•„ìš”'
    CART = 'cart', 'ì¥ë°”êµ¬ë‹ˆ ì¶”ê°€'
    PURCHASE = 'purchase', 'êµ¬ë§¤'
    RATING = 'rating', 'í‰ì '
    REVIEW = 'review', 'ë¦¬ë·°'
    SHARE = 'share', 'ê³µìœ '
    BOOKMARK = 'bookmark', 'ë¶ë§ˆí¬'

class UserInteraction(TimeStampedModel):
    """ì‚¬ìš©ì-ì•„ì´í…œ ìƒí˜¸ì‘ìš©"""
    user = models.ForeignKey(User, on_delete=models.CASCADE, related_name='interactions')
    product = models.ForeignKey('products.Product', on_delete=models.CASCADE, related_name='interactions')
    
    interaction_type = models.CharField(max_length=20, choices=InteractionType.choices)
    value = models.FloatField(null=True, blank=True)  # í‰ì , êµ¬ë§¤ ìˆ˜ëŸ‰ ë“±
    
    # ì»¨í…ìŠ¤íŠ¸ ì •ë³´
    session_id = models.CharField(max_length=100, blank=True)
    device_type = models.CharField(max_length=20, blank=True)  # mobile, desktop, tablet
    source = models.CharField(max_length=50, blank=True)  # search, recommendation, category_browse
    
    # ìœ„ì¹˜ ì •ë³´
    ip_address = models.GenericIPAddressField(null=True, blank=True)
    user_agent = models.TextField(blank=True)
    
    class Meta:
        indexes = [
            models.Index(fields=['user', 'interaction_type', 'created']),
            models.Index(fields=['product', 'interaction_type', 'created']),
            models.Index(fields=['user', 'product', 'interaction_type']),
            models.Index(fields=['session_id']),
            models.Index(fields=['created']),
        ]
        unique_together = [
            ('user', 'product', 'interaction_type', 'created'),
        ]
    
    def __str__(self):
        return f"{self.user.username} - {self.product.name} - {self.interaction_type}"

class RecommendationAlgorithm(TimeStampedModel):
    """ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ ì •ë³´"""
    name = models.CharField(max_length=100, unique=True)
    version = models.CharField(max_length=20)
    description = models.TextField()
    
    # ì„¤ì • ë° íŒŒë¼ë¯¸í„°
    parameters = models.JSONField(default=dict)
    is_active = models.BooleanField(default=True)
    
    # ì„±ëŠ¥ ì§€í‘œ
    precision = models.FloatField(null=True, blank=True)
    recall = models.FloatField(null=True, blank=True)
    f1_score = models.FloatField(null=True, blank=True)
    coverage = models.FloatField(null=True, blank=True)
    
    def __str__(self):
        return f"{self.name} v{self.version}"

class RecommendationRequest(TimeStampedModel):
    """ì¶”ì²œ ìš”ì²­ ë¡œê·¸"""
    user = models.ForeignKey(User, on_delete=models.CASCADE, related_name='recommendation_requests')
    algorithm = models.ForeignKey(RecommendationAlgorithm, on_delete=models.CASCADE)
    
    # ìš”ì²­ ì •ë³´
    num_requested = models.IntegerField(default=10)
    context = models.JSONField(default=dict)  # ì¶”ì²œ ì»¨í…ìŠ¤íŠ¸ (í˜ì´ì§€, ì‹œê°„ ë“±)
    
    # ì‘ë‹µ ì •ë³´
    num_returned = models.IntegerField(default=0)
    response_time_ms = models.IntegerField(default=0)
    
    # ì„±ê³¼ ì¶”ì 
    impressions = models.IntegerField(default=0)  # ë…¸ì¶œ ìˆ˜
    clicks = models.IntegerField(default=0)       # í´ë¦­ ìˆ˜
    conversions = models.IntegerField(default=0)   # ì „í™˜ ìˆ˜
    
    class Meta:
        indexes = [
            models.Index(fields=['user', 'created']),
            models.Index(fields=['algorithm', 'created']),
        ]

class RecommendationResult(TimeStampedModel):
    """ì¶”ì²œ ê²°ê³¼"""
    request = models.ForeignKey(RecommendationRequest, on_delete=models.CASCADE, related_name='results')
    product = models.ForeignKey('products.Product', on_delete=models.CASCADE)
    
    # ì¶”ì²œ ì •ë³´
    rank = models.IntegerField()  # ì¶”ì²œ ìˆœìœ„
    score = models.FloatField()   # ì¶”ì²œ ì ìˆ˜
    explanation = models.JSONField(default=dict)  # ì¶”ì²œ ì´ìœ 
    
    # ì„±ê³¼ ì¶”ì 
    was_viewed = models.BooleanField(default=False)
    was_clicked = models.BooleanField(default=False)
    was_purchased = models.BooleanField(default=False)
    
    # í”¼ë“œë°±
    user_feedback = models.CharField(max_length=20, blank=True)  # like, dislike, not_interested
    
    class Meta:
        indexes = [
            models.Index(fields=['request', 'rank']),
            models.Index(fields=['product']),
        ]
        unique_together = [('request', 'product')]
    
    def __str__(self):
        return f"Recommendation #{self.rank}: {self.product.name}"

class UserSimilarity(TimeStampedModel):
    """ì‚¬ìš©ì ê°„ ìœ ì‚¬ë„ (í˜‘ì—… í•„í„°ë§ìš©)"""
    user1 = models.ForeignKey(User, on_delete=models.CASCADE, related_name='similarities_as_user1')
    user2 = models.ForeignKey(User, on_delete=models.CASCADE, related_name='similarities_as_user2')
    
    similarity_score = models.FloatField()
    algorithm = models.CharField(max_length=50)  # cosine, pearson, jaccard ë“±
    
    # ê³„ì‚° ë©”íƒ€ë°ì´í„°
    common_items_count = models.IntegerField(default=0)
    last_calculated = models.DateTimeField(auto_now=True)
    
    class Meta:
        indexes = [
            models.Index(fields=['user1', 'similarity_score']),
            models.Index(fields=['user2', 'similarity_score']),
        ]
        unique_together = [('user1', 'user2', 'algorithm')]
    
    def __str__(self):
        return f"{self.user1.username} - {self.user2.username}: {self.similarity_score:.3f}"

class ItemSimilarity(TimeStampedModel):
    """ì•„ì´í…œ ê°„ ìœ ì‚¬ë„"""
    item1 = models.ForeignKey('products.Product', on_delete=models.CASCADE, related_name='similarities_as_item1')
    item2 = models.ForeignKey('products.Product', on_delete=models.CASCADE, related_name='similarities_as_item2')
    
    similarity_score = models.FloatField()
    algorithm = models.CharField(max_length=50)  # content, collaborative, hybrid
    
    # ìœ ì‚¬ë„ êµ¬ì„± ìš”ì†Œë³„ ì ìˆ˜
    category_similarity = models.FloatField(default=0)
    brand_similarity = models.FloatField(default=0)
    price_similarity = models.FloatField(default=0)
    feature_similarity = models.FloatField(default=0)
    
    last_calculated = models.DateTimeField(auto_now=True)
    
    class Meta:
        indexes = [
            models.Index(fields=['item1', 'similarity_score']),
            models.Index(fields=['item2', 'similarity_score']),
        ]
        unique_together = [('item1', 'item2', 'algorithm')]

class RecommendationCache(TimeStampedModel):
    """ì¶”ì²œ ê²°ê³¼ ìºì‹œ"""
    user = models.ForeignKey(User, on_delete=models.CASCADE)
    algorithm = models.ForeignKey(RecommendationAlgorithm, on_delete=models.CASCADE)
    
    # ìºì‹œ í‚¤ì™€ ë°ì´í„°
    cache_key = models.CharField(max_length=200, unique=True)
    recommendations = models.JSONField()  # ì¶”ì²œ ê²°ê³¼ JSON
    
    # ìºì‹œ ê´€ë¦¬
    expires_at = models.DateTimeField()
    hit_count = models.IntegerField(default=0)
    
    class Meta:
        indexes = [
            models.Index(fields=['user', 'algorithm']),
            models.Index(fields=['expires_at']),
        ]
```

### 2.3 Pydantic ìŠ¤í‚¤ë§ˆ ì •ì˜

```python
# apps/recommendations/schemas.py
from ninja import Schema, Field
from typing import List, Optional, Dict, Any
from datetime import datetime
from pydantic import validator

class InteractionCreateSchema(Schema):
    """ìƒí˜¸ì‘ìš© ìƒì„± ìŠ¤í‚¤ë§ˆ"""
    product_id: int
    interaction_type: str = Field(..., description="ìƒí˜¸ì‘ìš© ìœ í˜• (view, like, cart, purchase ë“±)")
    value: Optional[float] = Field(None, description="ìƒí˜¸ì‘ìš© ê°’ (í‰ì , ìˆ˜ëŸ‰ ë“±)")
    context: Optional[Dict[str, Any]] = Field(None, description="ì»¨í…ìŠ¤íŠ¸ ì •ë³´")
    
    @validator('interaction_type')
    def validate_interaction_type(cls, v):
        allowed_types = ['view', 'like', 'cart', 'purchase', 'rating', 'review', 'share', 'bookmark']
        if v not in allowed_types:
            raise ValueError(f'Invalid interaction type. Must be one of: {allowed_types}')
        return v

class ProductBasicSchema(Schema):
    """ê¸°ë³¸ ìƒí’ˆ ì •ë³´ ìŠ¤í‚¤ë§ˆ"""
    id: int
    name: str
    price: float
    image_url: Optional[str] = None
    category_name: str
    brand_name: str
    average_rating: float
    view_count: int

class RecommendationItemSchema(Schema):
    """ì¶”ì²œ ì•„ì´í…œ ìŠ¤í‚¤ë§ˆ"""
    product: ProductBasicSchema
    score: float = Field(..., description="ì¶”ì²œ ì ìˆ˜")
    rank: int = Field(..., description="ì¶”ì²œ ìˆœìœ„")
    explanation: Optional[Dict[str, Any]] = Field(None, description="ì¶”ì²œ ì´ìœ ")
    
    class Config:
        from_attributes = True

class RecommendationRequestSchema(Schema):
    """ì¶”ì²œ ìš”ì²­ ìŠ¤í‚¤ë§ˆ"""
    algorithm: Optional[str] = Field('hybrid', description="ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜")
    num_recommendations: int = Field(10, ge=1, le=50, description="ì¶”ì²œ ê°œìˆ˜")
    context: Optional[Dict[str, Any]] = Field(None, description="ì¶”ì²œ ì»¨í…ìŠ¤íŠ¸")
    include_explanation: bool = Field(False, description="ì¶”ì²œ ì´ìœ  í¬í•¨ ì—¬ë¶€")
    
    @validator('algorithm')
    def validate_algorithm(cls, v):
        allowed_algorithms = ['collaborative', 'content_based', 'hybrid', 'popular', 'random']
        if v not in allowed_algorithms:
            raise ValueError(f'Invalid algorithm. Must be one of: {allowed_algorithms}')
        return v

class RecommendationResponseSchema(Schema):
    """ì¶”ì²œ ì‘ë‹µ ìŠ¤í‚¤ë§ˆ"""
    recommendations: List[RecommendationItemSchema]
    algorithm_used: str
    total_count: int
    response_time_ms: int
    request_id: str = Field(..., description="ìš”ì²­ ID (ì¶”ì ìš©)")
    
    # ë©”íƒ€ ì •ë³´
    user_profile: Optional[Dict[str, Any]] = None
    diversification_applied: bool = False
    cache_hit: bool = False

class SimilarItemsSchema(Schema):
    """ìœ ì‚¬ ì•„ì´í…œ ìŠ¤í‚¤ë§ˆ"""
    target_product_id: int
    similar_items: List[RecommendationItemSchema]
    similarity_type: str = Field(..., description="ìœ ì‚¬ë„ ê³„ì‚° ë°©ë²•")

class UserFeedbackSchema(Schema):
    """ì‚¬ìš©ì í”¼ë“œë°± ìŠ¤í‚¤ë§ˆ"""
    recommendation_id: int
    feedback_type: str = Field(..., description="í”¼ë“œë°± ìœ í˜• (like, dislike, not_interested)")
    reason: Optional[str] = Field(None, description="í”¼ë“œë°± ì´ìœ ")
    
    @validator('feedback_type')
    def validate_feedback_type(cls, v):
        allowed_types = ['like', 'dislike', 'not_interested', 'inappropriate']
        if v not in allowed_types:
            raise ValueError(f'Invalid feedback type. Must be one of: {allowed_types}')
        return v

class RecommendationAnalyticsSchema(Schema):
    """ì¶”ì²œ ë¶„ì„ ìŠ¤í‚¤ë§ˆ"""
    algorithm: str
    period: str  # daily, weekly, monthly
    metrics: Dict[str, float] = Field(..., description="ì„±ê³¼ ì§€í‘œ")
    
    # ì£¼ìš” ë©”íŠ¸ë¦­
    click_through_rate: float
    conversion_rate: float
    coverage: float
    diversity: float
    novelty: float

class PersonalizationSettingsSchema(Schema):
    """ê°œì¸í™” ì„¤ì • ìŠ¤í‚¤ë§ˆ"""
    recommendation_enabled: bool = True
    preferred_categories: List[int] = []
    preferred_brands: List[int] = []
    price_range: Optional[Dict[str, float]] = None
    exclude_categories: List[int] = []
    diversity_preference: float = Field(0.5, ge=0, le=1, description="ë‹¤ì–‘ì„± ì„ í˜¸ë„ (0=ì•ˆì „, 1=ë‹¤ì–‘)")

class ExplainableRecommendationSchema(Schema):
    """ì„¤ëª… ê°€ëŠ¥í•œ ì¶”ì²œ ìŠ¤í‚¤ë§ˆ"""
    product: ProductBasicSchema
    score: float
    explanation: Dict[str, Any] = Field(..., description="ìƒì„¸ ì¶”ì²œ ì´ìœ ")
    
    # ì„¤ëª… êµ¬ì„± ìš”ì†Œ
    primary_reason: str = Field(..., description="ì£¼ìš” ì¶”ì²œ ì´ìœ ")
    secondary_reasons: List[str] = Field([], description="ë¶€ì°¨ì  ì¶”ì²œ ì´ìœ ë“¤")
    confidence_score: float = Field(..., ge=0, le=1, description="ì¶”ì²œ ì‹ ë¢°ë„")
```

---

## ğŸ¤ 3. í˜‘ì—… í•„í„°ë§ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„

ì‚¬ìš©ì í–‰ë™ íŒ¨í„´ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ í˜‘ì—… í•„í„°ë§ì„ êµ¬í˜„í•´ë³´ê² ìŠµë‹ˆë‹¤. User-Basedì™€ Item-Based ë‘ ê°€ì§€ ë°©ì‹ì„ ëª¨ë‘ êµ¬í˜„í•©ë‹ˆë‹¤.

### 3.1 ë°ì´í„° ì „ì²˜ë¦¬ ë° ìœ í‹¸ë¦¬í‹°

```python
# apps/recommendations/utils/data_processor.py
import numpy as np
import pandas as pd
from scipy.sparse import csr_matrix
from sklearn.metrics.pairwise import cosine_similarity, pairwise_distances
from sklearn.preprocessing import StandardScaler
from django.core.cache import cache
from django.db.models import Count, Avg, F
from apps.recommendations.models import UserInteraction
from apps.products.models import Product
from typing import Dict, List, Tuple, Optional
import logging

logger = logging.getLogger(__name__)

class InteractionMatrixBuilder:
    """ì‚¬ìš©ì-ì•„ì´í…œ ìƒí˜¸ì‘ìš© ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±"""
    
    def __init__(self):
        self.interaction_weights = {
            'view': 1.0,
            'like': 2.0,
            'cart': 3.0,
            'purchase': 5.0,
            'rating': 4.0,
            'review': 3.0,
            'share': 2.0,
            'bookmark': 2.5,
        }
    
    def build_matrix(self, min_interactions: int = 5, time_decay: bool = True) -> Tuple[csr_matrix, Dict, Dict]:
        """ìƒí˜¸ì‘ìš© ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±"""
        logger.info("Building user-item interaction matrix...")
        
        # ìƒí˜¸ì‘ìš© ë°ì´í„° ì¡°íšŒ
        interactions_qs = UserInteraction.objects.select_related('user', 'product').filter(
            product__is_active=True
        ).values(
            'user_id', 'product_id', 'interaction_type', 'created', 'value'
        )
        
        # íŒë‹¤ìŠ¤ DataFrameìœ¼ë¡œ ë³€í™˜
        df = pd.DataFrame(interactions_qs)
        
        if df.empty:
            logger.warning("No interactions found")
            return csr_matrix((0, 0)), {}, {}
        
        # ê°€ì¤‘ì¹˜ ì ìš©
        df['weight'] = df['interaction_type'].map(self.interaction_weights).fillna(1.0)
        
        # í‰ì ì˜ ê²½ìš° ì‹¤ì œ ê°’ ì‚¬ìš©
        rating_mask = df['interaction_type'] == 'rating'
        df.loc[rating_mask, 'weight'] = df.loc[rating_mask, 'value'].fillna(3.0)
        
        # ì‹œê°„ ê°€ì¤‘ì¹˜ ì ìš© (ìµœê·¼ ìƒí˜¸ì‘ìš©ì¼ìˆ˜ë¡ ë†’ì€ ê°€ì¤‘ì¹˜)
        if time_decay:
            df['days_ago'] = (pd.Timestamp.now() - pd.to_datetime(df['created'])).dt.days
            df['time_weight'] = np.exp(-df['days_ago'] / 30)  # 30ì¼ ê¸°ì¤€ ì§€ìˆ˜ ê°ì†Œ
            df['weight'] *= df['time_weight']
        
        # ì‚¬ìš©ì/ì•„ì´í…œë³„ ìƒí˜¸ì‘ìš© ìˆ˜ ê³„ì‚°
        user_interactions = df.groupby('user_id').size()
        item_interactions = df.groupby('product_id').size()
        
        # ìµœì†Œ ìƒí˜¸ì‘ìš© ìˆ˜ í•„í„°ë§
        valid_users = user_interactions[user_interactions >= min_interactions].index
        valid_items = item_interactions[item_interactions >= min_interactions].index
        
        df_filtered = df[
            df['user_id'].isin(valid_users) & 
            df['product_id'].isin(valid_items)
        ]
        
        if df_filtered.empty:
            logger.warning("No valid interactions after filtering")
            return csr_matrix((0, 0)), {}, {}
        
        # ì‚¬ìš©ì/ì•„ì´í…œ ì§‘ê³„ (ì¤‘ë³µ ìƒí˜¸ì‘ìš© í•©ê³„)
        interaction_matrix_df = df_filtered.groupby(['user_id', 'product_id'])['weight'].sum().reset_index()
        
        # ì¸ë±ìŠ¤ ë§¤í•‘ ìƒì„±
        unique_users = sorted(interaction_matrix_df['user_id'].unique())
        unique_items = sorted(interaction_matrix_df['product_id'].unique())
        
        user_to_idx = {user_id: idx for idx, user_id in enumerate(unique_users)}
        item_to_idx = {item_id: idx for idx, item_id in enumerate(unique_items)}
        
        # í¬ì†Œ í–‰ë ¬ ìƒì„±
        row_indices = [user_to_idx[user_id] for user_id in interaction_matrix_df['user_id']]
        col_indices = [item_to_idx[item_id] for item_id in interaction_matrix_df['product_id']]
        data = interaction_matrix_df['weight'].values
        
        matrix = csr_matrix(
            (data, (row_indices, col_indices)), 
            shape=(len(unique_users), len(unique_items))
        )
        
        logger.info(f"Built matrix: {matrix.shape[0]} users x {matrix.shape[1]} items, density: {matrix.nnz / (matrix.shape[0] * matrix.shape[1]):.4f}")
        
        return matrix, user_to_idx, item_to_idx
    
    def normalize_matrix(self, matrix: csr_matrix, method: str = 'user') -> csr_matrix:
        """ë§¤íŠ¸ë¦­ìŠ¤ ì •ê·œí™”"""
        if method == 'user':
            # ì‚¬ìš©ìë³„ ì •ê·œí™” (ê° ì‚¬ìš©ìì˜ í‰ê·  ì„ í˜¸ë„ ì œê±°)
            user_means = np.array(matrix.mean(axis=1)).flatten()
            user_means[user_means == 0] = 0  # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
            
            # í–‰ë ¬ì—ì„œ ì‚¬ìš©ì í‰ê·  ì°¨ê°
            normalized = matrix.copy().astype(float)
            for i in range(matrix.shape[0]):
                if user_means[i] > 0:
                    normalized.data[normalized.indptr[i]:normalized.indptr[i+1]] -= user_means[i]
            
            return normalized
        
        elif method == 'item':
            # ì•„ì´í…œë³„ ì •ê·œí™”
            item_means = np.array(matrix.mean(axis=0)).flatten()
            normalized = matrix.copy().astype(float)
            
            for j in range(matrix.shape[1]):
                if item_means[j] > 0:
                    col_data = normalized.getcol(j).data
                    col_data -= item_means[j]
            
            return normalized
        
        return matrix

class SimilarityCalculator:
    """ìœ ì‚¬ë„ ê³„ì‚° í´ë˜ìŠ¤"""
    
    @staticmethod
    def cosine_similarity_sparse(matrix: csr_matrix, top_k: int = 50) -> csr_matrix:
        """í¬ì†Œ í–‰ë ¬ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        # ì •ê·œí™”
        matrix_norm = matrix.copy()
        matrix_norm.data = matrix_norm.data / np.sqrt(np.array(matrix_norm.power(2).sum(axis=1)).flatten())
        matrix_norm.data = np.nan_to_num(matrix_norm.data)
        
        # ìœ ì‚¬ë„ ê³„ì‚°
        similarity = matrix_norm @ matrix_norm.T
        
        # Top-Kë§Œ ìœ ì§€ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±)
        if top_k < similarity.shape[0]:
            similarity = SimilarityCalculator._keep_top_k(similarity, top_k)
        
        return similarity
    
    @staticmethod
    def _keep_top_k(similarity_matrix: csr_matrix, k: int) -> csr_matrix:
        """ê° í–‰ì—ì„œ ìƒìœ„ Kê°œ ìœ ì‚¬ë„ë§Œ ìœ ì§€"""
        for i in range(similarity_matrix.shape[0]):
            row_start = similarity_matrix.indptr[i]
            row_end = similarity_matrix.indptr[i + 1]
            
            if row_end - row_start > k:
                # í˜„ì¬ í–‰ì˜ ë°ì´í„°
                row_data = similarity_matrix.data[row_start:row_end]
                row_indices = similarity_matrix.indices[row_start:row_end]
                
                # ìƒìœ„ kê°œ ì¸ë±ìŠ¤ ì°¾ê¸°
                top_k_idx = np.argpartition(row_data, -k)[-k:]
                
                # ìƒìœ„ kê°œë§Œ ìœ ì§€
                similarity_matrix.data[row_start:row_end] = 0
                similarity_matrix.indices[row_start:row_end] = 0
                
                for idx in top_k_idx:
                    similarity_matrix.data[row_start + idx] = row_data[idx]
                    similarity_matrix.indices[row_start + idx] = row_indices[idx]
        
        similarity_matrix.eliminate_zeros()
        return similarity_matrix
    
    @staticmethod
    def pearson_correlation(matrix: csr_matrix) -> np.ndarray:
        """í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜ ê³„ì‚°"""
        # í¬ì†Œ í–‰ë ¬ì„ ë°€ì§‘ í–‰ë ¬ë¡œ ë³€í™˜ (ì‘ì€ ë°ì´í„°ì…‹ìš©)
        dense_matrix = matrix.toarray()
        
        # ê° ì‚¬ìš©ìì˜ í‰ê·  ê³„ì‚° (0ì´ ì•„ë‹Œ ê°’ë“¤ë§Œ)
        user_means = []
        for i in range(dense_matrix.shape[0]):
            non_zero_mask = dense_matrix[i] != 0
            if np.sum(non_zero_mask) > 0:
                user_means.append(np.mean(dense_matrix[i][non_zero_mask]))
            else:
                user_means.append(0)
        
        user_means = np.array(user_means)
        
        # í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜ ê³„ì‚°
        correlation_matrix = np.zeros((matrix.shape[0], matrix.shape[0]))
        
        for i in range(matrix.shape[0]):
            for j in range(i, matrix.shape[0]):
                # ê³µí†µ ì•„ì´í…œ ì°¾ê¸°
                common_items = (dense_matrix[i] != 0) & (dense_matrix[j] != 0)
                
                if np.sum(common_items) > 1:  # ìµœì†Œ 2ê°œ ê³µí†µ ì•„ì´í…œ í•„ìš”
                    user_i_ratings = dense_matrix[i][common_items] - user_means[i]
                    user_j_ratings = dense_matrix[j][common_items] - user_means[j]
                    
                    numerator = np.sum(user_i_ratings * user_j_ratings)
                    denominator = np.sqrt(np.sum(user_i_ratings**2) * np.sum(user_j_ratings**2))
                    
                    if denominator > 0:
                        correlation = numerator / denominator
                        correlation_matrix[i, j] = correlation_matrix[j, i] = correlation
        
        return correlation_matrix
```

### 3.2 User-Based í˜‘ì—… í•„í„°ë§

```python
# apps/recommendations/algorithms/collaborative.py
import numpy as np
from scipy.sparse import csr_matrix
from django.core.cache import cache
from django.contrib.auth.models import User
from apps.products.models import Product
from apps.recommendations.utils.data_processor import InteractionMatrixBuilder, SimilarityCalculator
from apps.recommendations.models import UserSimilarity, RecommendationAlgorithm
from typing import List, Dict, Tuple, Optional
import logging

logger = logging.getLogger(__name__)

class UserBasedCollaborativeFiltering:
    """ì‚¬ìš©ì ê¸°ë°˜ í˜‘ì—… í•„í„°ë§"""
    
    def __init__(self, min_interactions: int = 5, similarity_threshold: float = 0.1, n_neighbors: int = 50):
        self.min_interactions = min_interactions
        self.similarity_threshold = similarity_threshold
        self.n_neighbors = n_neighbors
        self.matrix_builder = InteractionMatrixBuilder()
        
        # ìºì‹œ í‚¤
        self.matrix_cache_key = "cf_user_matrix"
        self.similarity_cache_key = "cf_user_similarity"
    
    def train(self, force_rebuild: bool = False) -> bool:
        """ëª¨ë¸ í›ˆë ¨ (ì‚¬ìš©ì ìœ ì‚¬ë„ ê³„ì‚°)"""
        logger.info("Starting User-Based CF training...")
        
        # ìºì‹œ í™•ì¸
        if not force_rebuild and cache.get(self.matrix_cache_key):
            logger.info("Using cached interaction matrix")
            return True
        
        try:
            # ìƒí˜¸ì‘ìš© ë§¤íŠ¸ë¦­ìŠ¤ êµ¬ì„±
            matrix, user_to_idx, item_to_idx = self.matrix_builder.build_matrix(
                min_interactions=self.min_interactions
            )
            
            if matrix.shape[0] == 0:
                logger.error("Empty interaction matrix")
                return False
            
            # ë§¤íŠ¸ë¦­ìŠ¤ ì •ê·œí™”
            normalized_matrix = self.matrix_builder.normalize_matrix(matrix, method='user')
            
            # ì‚¬ìš©ì ê°„ ìœ ì‚¬ë„ ê³„ì‚°
            user_similarity = SimilarityCalculator.cosine_similarity_sparse(
                normalized_matrix, top_k=self.n_neighbors
            )
            
            # ìºì‹œì— ì €ì¥
            cache_data = {
                'matrix': matrix,
                'normalized_matrix': normalized_matrix,
                'user_similarity': user_similarity,
                'user_to_idx': user_to_idx,
                'item_to_idx': item_to_idx
            }
            
            cache.set(self.matrix_cache_key, cache_data, timeout=3600*24)  # 24ì‹œê°„
            
            # ë°ì´í„°ë² ì´ìŠ¤ì— ìœ ì‚¬ë„ ì €ì¥ (ìƒìœ„ ìœ ì‚¬ ì‚¬ìš©ìë“¤ë§Œ)
            self._save_similarities_to_db(user_similarity, user_to_idx)
            
            logger.info(f"User-Based CF training completed. Matrix shape: {matrix.shape}")
            return True
            
        except Exception as e:
            logger.error(f"Error in User-Based CF training: {str(e)}")
            return False
    
    def _save_similarities_to_db(self, similarity_matrix: csr_matrix, user_to_idx: Dict[int, int]):
        """ìœ ì‚¬ë„ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        idx_to_user = {idx: user_id for user_id, idx in user_to_idx.items()}
        
        # ê¸°ì¡´ ìœ ì‚¬ë„ ì‚­ì œ
        UserSimilarity.objects.filter(algorithm='user_based_cf').delete()
        
        similarities_to_create = []
        
        for i in range(similarity_matrix.shape[0]):
            user_id = idx_to_user[i]
            
            # í˜„ì¬ ì‚¬ìš©ìì™€ ìœ ì‚¬í•œ ì‚¬ìš©ìë“¤ ì°¾ê¸°
            row_start = similarity_matrix.indptr[i]
            row_end = similarity_matrix.indptr[i + 1]
            
            similar_indices = similarity_matrix.indices[row_start:row_end]
            similarity_scores = similarity_matrix.data[row_start:row_end]
            
            for j, score in zip(similar_indices, similarity_scores):
                if i != j and score > self.similarity_threshold:
                    similar_user_id = idx_to_user[j]
                    
                    similarities_to_create.append(
                        UserSimilarity(
                            user1_id=user_id,
                            user2_id=similar_user_id,
                            similarity_score=float(score),
                            algorithm='user_based_cf'
                        )
                    )
        
        # ë²Œí¬ ìƒì„± (ë°°ì¹˜ í¬ê¸°ë¡œ ë¶„í• )
        batch_size = 1000
        for i in range(0, len(similarities_to_create), batch_size):
            batch = similarities_to_create[i:i + batch_size]
            UserSimilarity.objects.bulk_create(batch, ignore_conflicts=True)
        
        logger.info(f"Saved {len(similarities_to_create)} user similarities to database")
    
    def recommend(self, user_id: int, num_recommendations: int = 10, exclude_purchased: bool = True) -> List[Dict]:
        """ì‚¬ìš©ìì—ê²Œ ì¶”ì²œ"""
        cache_data = cache.get(self.matrix_cache_key)
        if not cache_data:
            logger.warning("No cached matrix found, training required")
            if not self.train():
                return []
            cache_data = cache.get(self.matrix_cache_key)
        
        matrix = cache_data['matrix']
        user_similarity = cache_data['user_similarity']
        user_to_idx = cache_data['user_to_idx']
        item_to_idx = cache_data['item_to_idx']
        
        # ì‚¬ìš©ì ì¸ë±ìŠ¤ í™•ì¸
        if user_id not in user_to_idx:
            logger.warning(f"User {user_id} not found in training data")
            return self._get_fallback_recommendations(user_id, num_recommendations)
        
        user_idx = user_to_idx[user_id]
        
        # ì‚¬ìš©ìì˜ ê¸°ì¡´ ìƒí˜¸ì‘ìš© ê°€ì ¸ì˜¤ê¸°
        user_interactions = matrix[user_idx].toarray().flatten()
        
        # ìœ ì‚¬í•œ ì‚¬ìš©ìë“¤ ì°¾ê¸°
        user_similarities = user_similarity[user_idx].toarray().flatten()
        similar_users = np.argsort(user_similarities)[::-1]
        
        # ì¶”ì²œ ì ìˆ˜ ê³„ì‚°
        recommendation_scores = np.zeros(matrix.shape[1])
        total_similarity = 0
        
        for similar_user_idx in similar_users[:self.n_neighbors]:
            if user_similarities[similar_user_idx] <= 0:
                break
            
            similar_user_interactions = matrix[similar_user_idx].toarray().flatten()
            similarity_score = user_similarities[similar_user_idx]
            
            # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ì ìˆ˜ ê³„ì‚°
            recommendation_scores += similarity_score * similar_user_interactions
            total_similarity += similarity_score
        
        if total_similarity > 0:
            recommendation_scores /= total_similarity
        
        # ì´ë¯¸ ìƒí˜¸ì‘ìš©í•œ ì•„ì´í…œ ì œì™¸
        recommendation_scores[user_interactions > 0] = 0
        
        # ìƒìœ„ ì¶”ì²œ ì•„ì´í…œ ì„ íƒ
        top_items = np.argsort(recommendation_scores)[::-1][:num_recommendations * 2]
        
        # ì‹¤ì œ ì¶”ì²œ ê²°ê³¼ ìƒì„±
        idx_to_item = {idx: item_id for item_id, idx in item_to_idx.items()}
        recommendations = []
        
        for item_idx in top_items:
            if len(recommendations) >= num_recommendations:
                break
            
            score = recommendation_scores[item_idx]
            if score <= 0:
                continue
            
            item_id = idx_to_item[item_idx]
            
            # ìƒí’ˆ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            try:
                product = Product.objects.get(id=item_id, is_active=True)
                recommendations.append({
                    'product_id': item_id,
                    'product': product,
                    'score': float(score),
                    'algorithm': 'user_based_cf',
                    'explanation': self._generate_explanation(user_id, item_id, user_similarities, similar_users)
                })
            except Product.DoesNotExist:
                continue
        
        return recommendations
    
    def _generate_explanation(self, user_id: int, item_id: int, user_similarities: np.ndarray, similar_users: np.ndarray) -> Dict:
        """ì¶”ì²œ ì´ìœ  ìƒì„±"""
        # ì´ ì•„ì´í…œì„ ì¢‹ì•„í•œ ìœ ì‚¬ ì‚¬ìš©ìë“¤ ì°¾ê¸°
        cache_data = cache.get(self.matrix_cache_key)
        matrix = cache_data['matrix']
        user_to_idx = cache_data['user_to_idx']
        item_to_idx = cache_data['item_to_idx']
        
        item_idx = item_to_idx.get(item_id, -1)
        if item_idx == -1:
            return {'reason': 'Similar users liked this item'}
        
        # ì´ ì•„ì´í…œì— ìƒí˜¸ì‘ìš©í•œ ìœ ì‚¬ ì‚¬ìš©ìë“¤
        similar_users_who_liked = []
        
        for similar_user_idx in similar_users[:10]:  # ìƒìœ„ 10ëª…ë§Œ í™•ì¸
            similarity_score = user_similarities[similar_user_idx]
            if similarity_score > 0 and matrix[similar_user_idx, item_idx] > 0:
                similar_users_who_liked.append(similarity_score)
        
        return {
            'reason': 'Similar users liked this item',
            'similar_users_count': len(similar_users_who_liked),
            'avg_similarity': float(np.mean(similar_users_who_liked)) if similar_users_who_liked else 0,
            'confidence': min(len(similar_users_who_liked) / 10.0, 1.0)
        }
    
    def _get_fallback_recommendations(self, user_id: int, num_recommendations: int) -> List[Dict]:
        """í´ë°± ì¶”ì²œ (ì¸ê¸°ë„ ê¸°ë°˜)"""
        popular_products = Product.objects.filter(
            is_active=True
        ).order_by('-purchase_count', '-view_count')[:num_recommendations]
        
        recommendations = []
        for i, product in enumerate(popular_products):
            recommendations.append({
                'product_id': product.id,
                'product': product,
                'score': 1.0 - (i * 0.1),  # ìˆœìœ„ ê¸°ë°˜ ì ìˆ˜
                'algorithm': 'popularity_fallback',
                'explanation': {'reason': 'Popular item (fallback)'}
            })
        
        return recommendations
    
    def get_similar_users(self, user_id: int, num_users: int = 10) -> List[Dict]:
        """ìœ ì‚¬í•œ ì‚¬ìš©ì ì¡°íšŒ"""
        similarities = UserSimilarity.objects.filter(
            user1_id=user_id,
            algorithm='user_based_cf'
        ).order_by('-similarity_score')[:num_users]
        
        similar_users = []
        for sim in similarities:
            similar_users.append({
                'user_id': sim.user2_id,
                'user': sim.user2,
                'similarity_score': sim.similarity_score,
                'common_items': sim.common_items_count
            })
        
        return similar_users
```

### 3.3 Item-Based í˜‘ì—… í•„í„°ë§

```python
# apps/recommendations/algorithms/collaborative.pyì— ì¶”ê°€

class ItemBasedCollaborativeFiltering:
    """ì•„ì´í…œ ê¸°ë°˜ í˜‘ì—… í•„í„°ë§"""
    
    def __init__(self, min_interactions: int = 5, similarity_threshold: float = 0.1, n_neighbors: int = 20):
        self.min_interactions = min_interactions
        self.similarity_threshold = similarity_threshold
        self.n_neighbors = n_neighbors
        self.matrix_builder = InteractionMatrixBuilder()
        
        self.matrix_cache_key = "cf_item_matrix"
    
    def train(self, force_rebuild: bool = False) -> bool:
        """ëª¨ë¸ í›ˆë ¨ (ì•„ì´í…œ ìœ ì‚¬ë„ ê³„ì‚°)"""
        logger.info("Starting Item-Based CF training...")
        
        try:
            # ìƒí˜¸ì‘ìš© ë§¤íŠ¸ë¦­ìŠ¤ êµ¬ì„±
            matrix, user_to_idx, item_to_idx = self.matrix_builder.build_matrix(
                min_interactions=self.min_interactions
            )
            
            if matrix.shape[1] == 0:
                logger.error("Empty item matrix")
                return False
            
            # ì•„ì´í…œ-ì‚¬ìš©ì ë§¤íŠ¸ë¦­ìŠ¤ë¡œ ì „ì¹˜
            item_matrix = matrix.T
            
            # ì•„ì´í…œë³„ ì •ê·œí™”
            normalized_matrix = self.matrix_builder.normalize_matrix(item_matrix, method='user')
            
            # ì•„ì´í…œ ê°„ ìœ ì‚¬ë„ ê³„ì‚°
            item_similarity = SimilarityCalculator.cosine_similarity_sparse(
                normalized_matrix, top_k=self.n_neighbors
            )
            
            # ìºì‹œì— ì €ì¥
            cache_data = {
                'user_matrix': matrix,
                'item_matrix': item_matrix,
                'item_similarity': item_similarity,
                'user_to_idx': user_to_idx,
                'item_to_idx': item_to_idx
            }
            
            cache.set(self.matrix_cache_key, cache_data, timeout=3600*24)
            
            # ì•„ì´í…œ ìœ ì‚¬ë„ DB ì €ì¥
            self._save_item_similarities_to_db(item_similarity, item_to_idx)
            
            logger.info(f"Item-Based CF training completed. Items: {item_matrix.shape[0]}")
            return True
            
        except Exception as e:
            logger.error(f"Error in Item-Based CF training: {str(e)}")
            return False
    
    def recommend(self, user_id: int, num_recommendations: int = 10) -> List[Dict]:
        """ì•„ì´í…œ ê¸°ë°˜ ì¶”ì²œ"""
        cache_data = cache.get(self.matrix_cache_key)
        if not cache_data:
            if not self.train():
                return []
            cache_data = cache.get(self.matrix_cache_key)
        
        user_matrix = cache_data['user_matrix']
        item_similarity = cache_data['item_similarity']
        user_to_idx = cache_data['user_to_idx']
        item_to_idx = cache_data['item_to_idx']
        
        if user_id not in user_to_idx:
            return self._get_fallback_recommendations(user_id, num_recommendations)
        
        user_idx = user_to_idx[user_id]
        user_interactions = user_matrix[user_idx].toarray().flatten()
        
        # ì‚¬ìš©ìê°€ ìƒí˜¸ì‘ìš©í•œ ì•„ì´í…œë“¤
        interacted_items = np.where(user_interactions > 0)[0]
        
        if len(interacted_items) == 0:
            return self._get_fallback_recommendations(user_id, num_recommendations)
        
        # ì¶”ì²œ ì ìˆ˜ ê³„ì‚°
        recommendation_scores = np.zeros(len(item_to_idx))
        
        for item_idx in interacted_items:
            user_rating = user_interactions[item_idx]
            
            # ì´ ì•„ì´í…œê³¼ ìœ ì‚¬í•œ ì•„ì´í…œë“¤ ì°¾ê¸°
            similar_items_row = item_similarity[item_idx]
            similar_indices = similar_items_row.indices
            similarity_scores = similar_items_row.data
            
            for similar_item_idx, similarity_score in zip(similar_indices, similarity_scores):
                if similar_item_idx != item_idx:  # ìê¸° ìì‹  ì œì™¸
                    recommendation_scores[similar_item_idx] += user_rating * similarity_score
        
        # ì´ë¯¸ ìƒí˜¸ì‘ìš©í•œ ì•„ì´í…œ ì œì™¸
        recommendation_scores[interacted_items] = 0
        
        # ìƒìœ„ ì¶”ì²œ ì„ íƒ
        top_items = np.argsort(recommendation_scores)[::-1][:num_recommendations]
        
        # ê²°ê³¼ ìƒì„±
        idx_to_item = {idx: item_id for item_id, idx in item_to_idx.items()}
        recommendations = []
        
        for item_idx in top_items:
            score = recommendation_scores[item_idx]
            if score <= 0:
                continue
            
            item_id = idx_to_item[item_idx]
            
            try:
                product = Product.objects.get(id=item_id, is_active=True)
                recommendations.append({
                    'product_id': item_id,
                    'product': product,
                    'score': float(score),
                    'algorithm': 'item_based_cf',
                    'explanation': self._generate_item_explanation(user_id, item_id, interacted_items, item_similarity, item_to_idx)
                })
            except Product.DoesNotExist:
                continue
        
        return recommendations
    
    def get_similar_items(self, item_id: int, num_items: int = 10) -> List[Dict]:
        """ìœ ì‚¬ ì•„ì´í…œ ì¡°íšŒ"""
        from apps.recommendations.models import ItemSimilarity
        
        similarities = ItemSimilarity.objects.filter(
            item1_id=item_id,
            algorithm='item_based_cf'
        ).select_related('item2').order_by('-similarity_score')[:num_items]
        
        similar_items = []
        for sim in similarities:
            similar_items.append({
                'product_id': sim.item2_id,
                'product': sim.item2,
                'similarity_score': sim.similarity_score,
                'explanation': {
                    'category_similarity': sim.category_similarity,
                    'brand_similarity': sim.brand_similarity,
                    'feature_similarity': sim.feature_similarity
                }
            })
        
        return similar_items
    
    def _save_item_similarities_to_db(self, similarity_matrix: csr_matrix, item_to_idx: Dict[int, int]):
        """ì•„ì´í…œ ìœ ì‚¬ë„ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        from apps.recommendations.models import ItemSimilarity
        
        idx_to_item = {idx: item_id for item_id, idx in item_to_idx.items()}
        
        # ê¸°ì¡´ ìœ ì‚¬ë„ ì‚­ì œ
        ItemSimilarity.objects.filter(algorithm='item_based_cf').delete()
        
        similarities_to_create = []
        
        for i in range(similarity_matrix.shape[0]):
            item_id = idx_to_item[i]
            
            row_start = similarity_matrix.indptr[i]
            row_end = similarity_matrix.indptr[i + 1]
            
            similar_indices = similarity_matrix.indices[row_start:row_end]
            similarity_scores = similarity_matrix.data[row_start:row_end]
            
            for j, score in zip(similar_indices, similarity_scores):
                if i != j and score > self.similarity_threshold:
                    similar_item_id = idx_to_item[j]
                    
                    similarities_to_create.append(
                        ItemSimilarity(
                            item1_id=item_id,
                            item2_id=similar_item_id,
                            similarity_score=float(score),
                            algorithm='item_based_cf'
                        )
                    )
        
        # ë²Œí¬ ìƒì„±
        batch_size = 1000
        for i in range(0, len(similarities_to_create), batch_size):
            batch = similarities_to_create[i:i + batch_size]
            ItemSimilarity.objects.bulk_create(batch, ignore_conflicts=True)
    
    def _generate_item_explanation(self, user_id: int, recommended_item_id: int, 
                                 interacted_items: np.ndarray, item_similarity: csr_matrix, 
                                 item_to_idx: Dict[int, int]) -> Dict:
        """ì•„ì´í…œ ê¸°ë°˜ ì¶”ì²œ ì´ìœ  ìƒì„±"""
        # ì¶”ì²œ ì•„ì´í…œê³¼ ê°€ì¥ ìœ ì‚¬í•œ ì‚¬ìš©ì ìƒí˜¸ì‘ìš© ì•„ì´í…œ ì°¾ê¸°
        recommended_idx = item_to_idx.get(recommended_item_id, -1)
        if recommended_idx == -1:
            return {'reason': 'Similar to items you liked'}
        
        similar_interacted_items = []
        
        for interacted_idx in interacted_items:
            # ìœ ì‚¬ë„ í–‰ë ¬ì—ì„œ ìœ ì‚¬ë„ í™•ì¸
            similarity_row = item_similarity[interacted_idx]
            
            # ì¶”ì²œ ì•„ì´í…œê³¼ì˜ ìœ ì‚¬ë„ ì°¾ê¸°
            item_position = np.where(similarity_row.indices == recommended_idx)[0]
            if len(item_position) > 0:
                similarity_score = similarity_row.data[item_position[0]]
                idx_to_item = {idx: item_id for item_id, idx in item_to_idx.items()}
                interacted_item_id = idx_to_item[interacted_idx]
                
                similar_interacted_items.append({
                    'item_id': interacted_item_id,
                    'similarity': similarity_score
                })
        
        # ê°€ì¥ ìœ ì‚¬í•œ ì•„ì´í…œë“¤ ì •ë ¬
        similar_interacted_items.sort(key=lambda x: x['similarity'], reverse=True)
        
        return {
            'reason': 'Similar to items you liked',
            'based_on_items': similar_interacted_items[:3],  # ìƒìœ„ 3ê°œ
            'similarity_count': len(similar_interacted_items)
        }
    
    def _get_fallback_recommendations(self, user_id: int, num_recommendations: int) -> List[Dict]:
        """í´ë°± ì¶”ì²œ"""
        popular_products = Product.objects.filter(
            is_active=True
        ).order_by('-purchase_count')[:num_recommendations]
        
        return [{
            'product_id': product.id,
            'product': product,
            'score': 1.0,
            'algorithm': 'popularity_fallback',
            'explanation': {'reason': 'Popular item'}
        } for product in popular_products]
```

---

## ğŸ“Š 4. ì½˜í…ì¸  ê¸°ë°˜ í•„í„°ë§ êµ¬í˜„

ìƒí’ˆì˜ ì†ì„±ê³¼ íŠ¹ì§•ì„ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ì ì„ í˜¸ë„ì— ë§ëŠ” ìœ ì‚¬í•œ ìƒí’ˆì„ ì¶”ì²œí•˜ëŠ” ì½˜í…ì¸  ê¸°ë°˜ í•„í„°ë§ì„ êµ¬í˜„í•©ë‹ˆë‹¤.

### 4.1 íŠ¹ì§• ì¶”ì¶œ ë° ë²¡í„°í™”

```python
# apps/recommendations/algorithms/content_based.py
import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.decomposition import TruncatedSVD
from django.core.cache import cache
from django.db.models import Q
from apps.products.models import Product, Category, Brand
from apps.recommendations.models import UserInteraction
from typing import Dict, List, Tuple, Optional, Any
import re
import logging

logger = logging.getLogger(__name__)

class ProductFeatureExtractor:
    """ìƒí’ˆ íŠ¹ì§• ì¶”ì¶œê¸°"""
    
    def __init__(self):
        self.tfidf_vectorizer = TfidfVectorizer(
            max_features=1000,
            stop_words='english',
            ngram_range=(1, 2),
            min_df=2,
            max_df=0.8
        )
        self.scaler = StandardScaler()
        self.mlb_tags = MultiLabelBinarizer()
        self.feature_weights = {
            'category': 0.3,
            'brand': 0.2,
            'price': 0.1,
            'description': 0.25,
            'tags': 0.15
        }
    
    def extract_features(self, products_queryset=None) -> Tuple[np.ndarray, Dict[str, Any]]:
        """ìƒí’ˆë“¤ì˜ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ì—¬ ë²¡í„°í™”"""
        logger.info("Extracting product features...")
        
        if products_queryset is None:
            products_queryset = Product.objects.filter(is_active=True).select_related('category', 'brand')
        
        products = list(products_queryset)
        if not products:
            return np.array([]), {}
        
        # íŠ¹ì§•ë³„ ë°ì´í„° ì¤€ë¹„
        feature_data = {
            'product_ids': [p.id for p in products],
            'categories': [p.category.name if p.category else '' for p in products],
            'brands': [p.brand.name if p.brand else '' for p in products],
            'prices': [float(p.price) for p in products],
            'descriptions': [self._clean_text(p.description) for p in products],
            'names': [self._clean_text(p.name) for p in products],
            'tags': [p.tags for p in products]
        }
        
        # 1. ì¹´í…Œê³ ë¦¬ íŠ¹ì§•
        category_features = self._encode_categories(feature_data['categories'])
        
        # 2. ë¸Œëœë“œ íŠ¹ì§•
        brand_features = self._encode_brands(feature_data['brands'])
        
        # 3. ê°€ê²© íŠ¹ì§•
        price_features = self._encode_prices(feature_data['prices'])
        
        # 4. í…ìŠ¤íŠ¸ íŠ¹ì§• (ì œí’ˆëª… + ì„¤ëª…)
        text_data = [f"{name} {desc}" for name, desc in zip(feature_data['names'], feature_data['descriptions'])]
        text_features = self._encode_text(text_data)
        
        # 5. íƒœê·¸ íŠ¹ì§•
        tag_features = self._encode_tags(feature_data['tags'])
        
        # íŠ¹ì§• ê²°í•©
        all_features = []
        feature_info = {
            'product_ids': feature_data['product_ids'],
            'feature_names': [],
            'feature_ranges': {}
        }
        
        start_idx = 0
        
        # ì¹´í…Œê³ ë¦¬ íŠ¹ì§• ì¶”ê°€
        if category_features.size > 0:
            weighted_category = category_features * self.feature_weights['category']
            all_features.append(weighted_category)
            end_idx = start_idx + category_features.shape[1]
            feature_info['feature_ranges']['category'] = (start_idx, end_idx)
            start_idx = end_idx
        
        # ë¸Œëœë“œ íŠ¹ì§• ì¶”ê°€
        if brand_features.size > 0:
            weighted_brand = brand_features * self.feature_weights['brand']
            all_features.append(weighted_brand)
            end_idx = start_idx + brand_features.shape[1]
            feature_info['feature_ranges']['brand'] = (start_idx, end_idx)
            start_idx = end_idx
        
        # ê°€ê²© íŠ¹ì§• ì¶”ê°€
        if price_features.size > 0:
            weighted_price = price_features * self.feature_weights['price']
            all_features.append(weighted_price)
            end_idx = start_idx + price_features.shape[1]
            feature_info['feature_ranges']['price'] = (start_idx, end_idx)
            start_idx = end_idx
        
        # í…ìŠ¤íŠ¸ íŠ¹ì§• ì¶”ê°€
        if text_features.size > 0:
            weighted_text = text_features * self.feature_weights['description']
            all_features.append(weighted_text)
            end_idx = start_idx + text_features.shape[1]
            feature_info['feature_ranges']['description'] = (start_idx, end_idx)
            start_idx = end_idx
        
        # íƒœê·¸ íŠ¹ì§• ì¶”ê°€
        if tag_features.size > 0:
            weighted_tags = tag_features * self.feature_weights['tags']
            all_features.append(weighted_tags)
            end_idx = start_idx + tag_features.shape[1]
            feature_info['feature_ranges']['tags'] = (start_idx, end_idx)
            start_idx = end_idx
        
        # ìµœì¢… íŠ¹ì§• ë§¤íŠ¸ë¦­ìŠ¤
        if all_features:
            combined_features = np.hstack(all_features)
        else:
            combined_features = np.array([])
        
        logger.info(f"Feature extraction completed. Shape: {combined_features.shape}")
        return combined_features, feature_info
    
    def _clean_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬"""
        if not text:
            return ""
        
        # HTML íƒœê·¸ ì œê±°
        text = re.sub(r'<[^>]+>', '', text)
        # íŠ¹ìˆ˜ë¬¸ì ì •ê·œí™”
        text = re.sub(r'[^\w\s]', ' ', text)
        # ê³µë°± ì •ê·œí™”
        text = re.sub(r'\s+', ' ', text)
        
        return text.strip().lower()
    
    def _encode_categories(self, categories: List[str]) -> np.ndarray:
        """ì¹´í…Œê³ ë¦¬ ì›í•« ì¸ì½”ë”©"""
        from sklearn.preprocessing import LabelEncoder, OneHotEncoder
        
        if not categories:
            return np.array([])
        
        # ë¹ˆ ë¬¸ìì—´ ì²˜ë¦¬
        categories = [cat if cat else 'unknown' for cat in categories]
        
        le = LabelEncoder()
        encoded_categories = le.fit_transform(categories)
        
        ohe = OneHotEncoder(sparse_output=False)
        onehot_categories = ohe.fit_transform(encoded_categories.reshape(-1, 1))
        
        return onehot_categories
    
    def _encode_brands(self, brands: List[str]) -> np.ndarray:
        """ë¸Œëœë“œ ì›í•« ì¸ì½”ë”©"""
        from sklearn.preprocessing import LabelEncoder, OneHotEncoder
        
        if not brands:
            return np.array([])
        
        brands = [brand if brand else 'unknown' for brand in brands]
        
        le = LabelEncoder()
        encoded_brands = le.fit_transform(brands)
        
        ohe = OneHotEncoder(sparse_output=False)
        onehot_brands = ohe.fit_transform(encoded_brands.reshape(-1, 1))
        
        return onehot_brands
    
    def _encode_prices(self, prices: List[float]) -> np.ndarray:
        """ê°€ê²© íŠ¹ì§• ì¸ì½”ë”©"""
        if not prices:
            return np.array([])
        
        prices_array = np.array(prices).reshape(-1, 1)
        
        # ê°€ê²© êµ¬ê°„ë³„ íŠ¹ì§• ìƒì„±
        price_ranges = [
            (0, 50000),      # ì €ê°€
            (50000, 100000), # ì¤‘ì €ê°€  
            (100000, 200000),# ì¤‘ê°€
            (200000, 500000),# ì¤‘ê³ ê°€
            (500000, float('inf'))  # ê³ ê°€
        ]
        
        price_features = np.zeros((len(prices), len(price_ranges)))
        
        for i, price in enumerate(prices):
            for j, (min_price, max_price) in enumerate(price_ranges):
                if min_price <= price < max_price:
                    price_features[i, j] = 1
                    break
        
        # ì •ê·œí™”ëœ ê°€ê²©ë„ ì¶”ê°€
        normalized_prices = self.scaler.fit_transform(prices_array)
        
        return np.hstack([price_features, normalized_prices])
    
    def _encode_text(self, texts: List[str]) -> np.ndarray:
        """í…ìŠ¤íŠ¸ TF-IDF ì¸ì½”ë”©"""
        if not texts or all(not text for text in texts):
            return np.array([])
        
        # ë¹ˆ í…ìŠ¤íŠ¸ ì²˜ë¦¬
        texts = [text if text else 'no description' for text in texts]
        
        try:
            tfidf_features = self.tfidf_vectorizer.fit_transform(texts)
            
            # ì°¨ì› ì¶•ì†Œ (ì„ íƒì‚¬í•­)
            if tfidf_features.shape[1] > 100:
                svd = TruncatedSVD(n_components=100, random_state=42)
                tfidf_features = svd.fit_transform(tfidf_features)
            else:
                tfidf_features = tfidf_features.toarray()
            
            return tfidf_features
            
        except ValueError as e:
            logger.error(f"Error in text encoding: {str(e)}")
            return np.zeros((len(texts), 1))
    
    def _encode_tags(self, tags_list: List[List[str]]) -> np.ndarray:
        """íƒœê·¸ ë©€í‹°ë ˆì´ë¸” ì¸ì½”ë”©"""
        if not tags_list:
            return np.array([])
        
        # ë¹ˆ íƒœê·¸ ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬
        tags_list = [tags if tags else [] for tags in tags_list]
        
        try:
            tag_features = self.mlb_tags.fit_transform(tags_list)
            return tag_features
        except ValueError:
            return np.zeros((len(tags_list), 1))

class UserProfileBuilder:
    """ì‚¬ìš©ì í”„ë¡œí•„ ìƒì„±ê¸°"""
    
    def __init__(self, feature_extractor: ProductFeatureExtractor):
        self.feature_extractor = feature_extractor
        
        # ìƒí˜¸ì‘ìš© ê°€ì¤‘ì¹˜
        self.interaction_weights = {
            'view': 1.0,
            'like': 3.0,
            'cart': 4.0,
            'purchase': 5.0,
            'rating': 4.0,
            'bookmark': 2.0
        }
    
    def build_user_profile(self, user_id: int, feature_matrix: np.ndarray, 
                          feature_info: Dict[str, Any]) -> Optional[np.ndarray]:
        """ì‚¬ìš©ì ì„ í˜¸ë„ í”„ë¡œí•„ ìƒì„±"""
        # ì‚¬ìš©ì ìƒí˜¸ì‘ìš© ë°ì´í„° ì¡°íšŒ
        interactions = UserInteraction.objects.filter(
            user_id=user_id,
            product__is_active=True
        ).select_related('product').order_by('-created')[:100]  # ìµœê·¼ 100ê°œ
        
        if not interactions:
            return None
        
        # ìƒí˜¸ì‘ìš©í•œ ìƒí’ˆë“¤ì˜ íŠ¹ì§• ê°€ì ¸ì˜¤ê¸°
        product_ids = feature_info['product_ids']
        user_product_indices = []
        weights = []
        
        for interaction in interactions:
            try:
                product_idx = product_ids.index(interaction.product_id)
                user_product_indices.append(product_idx)
                
                # ìƒí˜¸ì‘ìš© ê°€ì¤‘ì¹˜ ê³„ì‚°
                base_weight = self.interaction_weights.get(interaction.interaction_type, 1.0)
                
                # í‰ì ì´ ìˆëŠ” ê²½ìš° ë°˜ì˜
                if interaction.interaction_type == 'rating' and interaction.value:
                    rating_weight = interaction.value / 5.0  # 5ì  ë§Œì ì„ 1ì  ë§Œì ìœ¼ë¡œ ì •ê·œí™”
                    base_weight *= rating_weight
                
                # ì‹œê°„ ê°€ì¤‘ì¹˜ (ìµœê·¼ì¼ìˆ˜ë¡ ë†’ì€ ê°€ì¤‘ì¹˜)
                days_ago = (timezone.now() - interaction.created).days
                time_weight = np.exp(-days_ago / 30)  # 30ì¼ ê¸°ì¤€ ì§€ìˆ˜ ê°ì†Œ
                
                final_weight = base_weight * time_weight
                weights.append(final_weight)
                
            except (ValueError, IndexError):
                continue
        
        if not user_product_indices:
            return None
        
        # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ì‚¬ìš©ì í”„ë¡œí•„ ìƒì„±
        user_features = feature_matrix[user_product_indices]
        weights_array = np.array(weights).reshape(-1, 1)
        
        # ê°€ì¤‘ í‰ê·  ê³„ì‚°
        weighted_features = user_features * weights_array
        user_profile = np.sum(weighted_features, axis=0) / np.sum(weights_array)
        
        return user_profile
    
    def build_user_category_preference(self, user_id: int) -> Dict[str, float]:
        """ì‚¬ìš©ì ì¹´í…Œê³ ë¦¬ ì„ í˜¸ë„ ë¶„ì„"""
        interactions = UserInteraction.objects.filter(
            user_id=user_id,
            product__is_active=True
        ).select_related('product__category').values(
            'product__category__name', 'interaction_type'
        )
        
        category_scores = {}
        
        for interaction in interactions:
            category = interaction['product__category__name'] or 'unknown'
            weight = self.interaction_weights.get(interaction['interaction_type'], 1.0)
            
            if category in category_scores:
                category_scores[category] += weight
            else:
                category_scores[category] = weight
        
        # ì •ê·œí™”
        if category_scores:
            total_score = sum(category_scores.values())
            category_scores = {k: v/total_score for k, v in category_scores.items()}
        
        return category_scores

class ContentBasedRecommender:
    """ì½˜í…ì¸  ê¸°ë°˜ ì¶”ì²œê¸°"""
    
    def __init__(self):
        self.feature_extractor = ProductFeatureExtractor()
        self.user_profile_builder = UserProfileBuilder(self.feature_extractor)
        self.cache_timeout = 3600 * 6  # 6ì‹œê°„
    
    def train(self, force_rebuild: bool = False) -> bool:
        """íŠ¹ì§• ë§¤íŠ¸ë¦­ìŠ¤ êµ¬ì¶•"""
        cache_key = "content_based_features"
        
        if not force_rebuild and cache.get(cache_key):
            logger.info("Using cached feature matrix")
            return True
        
        try:
            logger.info("Building content-based feature matrix...")
            
            # í™œì„± ìƒí’ˆë“¤ì˜ íŠ¹ì§• ì¶”ì¶œ
            products_qs = Product.objects.filter(is_active=True).select_related('category', 'brand')
            feature_matrix, feature_info = self.feature_extractor.extract_features(products_qs)
            
            if feature_matrix.size == 0:
                logger.error("Empty feature matrix")
                return False
            
            # ìƒí’ˆ ê°„ ìœ ì‚¬ë„ ê³„ì‚°
            similarity_matrix = cosine_similarity(feature_matrix)
            
            # ìºì‹œì— ì €ì¥
            cache_data = {
                'feature_matrix': feature_matrix,
                'feature_info': feature_info,
                'similarity_matrix': similarity_matrix
            }
            
            cache.set(cache_key, cache_data, timeout=self.cache_timeout)
            
            logger.info(f"Content-based training completed. Feature matrix shape: {feature_matrix.shape}")
            return True
            
        except Exception as e:
            logger.error(f"Error in content-based training: {str(e)}")
            return False
    
    def recommend(self, user_id: int, num_recommendations: int = 10, 
                 diversity_factor: float = 0.3) -> List[Dict]:
        """ì½˜í…ì¸  ê¸°ë°˜ ì¶”ì²œ"""
        cache_key = "content_based_features"
        cache_data = cache.get(cache_key)
        
        if not cache_data:
            if not self.train():
                return self._get_fallback_recommendations(user_id, num_recommendations)
            cache_data = cache.get(cache_key)
        
        feature_matrix = cache_data['feature_matrix']
        feature_info = cache_data['feature_info']
        similarity_matrix = cache_data['similarity_matrix']
        
        # ì‚¬ìš©ì í”„ë¡œí•„ êµ¬ì¶•
        user_profile = self.user_profile_builder.build_user_profile(
            user_id, feature_matrix, feature_info
        )
        
        if user_profile is None:
            return self._get_fallback_recommendations(user_id, num_recommendations)
        
        # ì‚¬ìš©ì í”„ë¡œí•„ê³¼ ê° ìƒí’ˆ ê°„ì˜ ìœ ì‚¬ë„ ê³„ì‚°
        product_similarities = cosine_similarity([user_profile], feature_matrix)[0]
        
        # ì‚¬ìš©ìê°€ ì´ë¯¸ ìƒí˜¸ì‘ìš©í•œ ìƒí’ˆë“¤ ì œì™¸
        interacted_products = set(
            UserInteraction.objects.filter(user_id=user_id)
            .values_list('product_id', flat=True)
        )
        
        # ì¶”ì²œ ì ìˆ˜ ê³„ì‚°
        recommendations = []
        product_ids = feature_info['product_ids']
        
        for i, similarity_score in enumerate(product_similarities):
            product_id = product_ids[i]
            
            if product_id in interacted_products:
                continue
            
            try:
                product = Product.objects.get(id=product_id, is_active=True)
                
                # ë‹¤ì–‘ì„± ìš”ì†Œ ì¶”ê°€
                diversified_score = self._apply_diversity(
                    similarity_score, product, recommendations, diversity_factor
                )
                
                recommendations.append({
                    'product_id': product_id,
                    'product': product,
                    'score': float(diversified_score),
                    'similarity_score': float(similarity_score),
                    'algorithm': 'content_based',
                    'explanation': self._generate_explanation(user_id, product, user_profile, feature_matrix[i], feature_info)
                })
                
            except Product.DoesNotExist:
                continue
        
        # ì ìˆ˜ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ ì¶”ì²œ ë°˜í™˜
        recommendations.sort(key=lambda x: x['score'], reverse=True)
        return recommendations[:num_recommendations]
    
    def get_similar_products(self, product_id: int, num_recommendations: int = 10) -> List[Dict]:
        """íŠ¹ì • ìƒí’ˆê³¼ ìœ ì‚¬í•œ ìƒí’ˆë“¤ ì¶”ì²œ"""
        cache_key = "content_based_features"
        cache_data = cache.get(cache_key)
        
        if not cache_data:
            if not self.train():
                return []
            cache_data = cache.get(cache_key)
        
        feature_info = cache_data['feature_info']
        similarity_matrix = cache_data['similarity_matrix']
        
        try:
            product_idx = feature_info['product_ids'].index(product_id)
        except ValueError:
            logger.warning(f"Product {product_id} not found in feature matrix")
            return []
        
        # ìœ ì‚¬ë„ ì ìˆ˜ ê°€ì ¸ì˜¤ê¸°
        similarities = similarity_matrix[product_idx]
        
        # ìê¸° ìì‹  ì œì™¸í•˜ê³  ì •ë ¬
        similar_indices = np.argsort(similarities)[::-1]
        
        recommendations = []
        for idx in similar_indices:
            if len(recommendations) >= num_recommendations:
                break
            
            if idx == product_idx:  # ìê¸° ìì‹  ì œì™¸
                continue
            
            similar_product_id = feature_info['product_ids'][idx]
            similarity_score = similarities[idx]
            
            try:
                product = Product.objects.get(id=similar_product_id, is_active=True)
                recommendations.append({
                    'product_id': similar_product_id,
                    'product': product,
                    'score': float(similarity_score),
                    'algorithm': 'content_based_similar',
                    'explanation': {'reason': 'Similar product features'}
                })
            except Product.DoesNotExist:
                continue
        
        return recommendations
    
    def _apply_diversity(self, base_score: float, product: Product, 
                        existing_recommendations: List[Dict], diversity_factor: float) -> float:
        """ë‹¤ì–‘ì„± ìš”ì†Œë¥¼ ì ìš©í•˜ì—¬ ì ìˆ˜ ì¡°ì •"""
        if not existing_recommendations or diversity_factor == 0:
            return base_score
        
        # ê¸°ì¡´ ì¶”ì²œë“¤ê³¼ì˜ ì¹´í…Œê³ ë¦¬/ë¸Œëœë“œ ì¤‘ë³µë„ ê³„ì‚°
        category_penalty = 0
        brand_penalty = 0
        
        existing_categories = [rec['product'].category_id for rec in existing_recommendations]
        existing_brands = [rec['product'].brand_id for rec in existing_recommendations]
        
        # ì¹´í…Œê³ ë¦¬ ì¤‘ë³µ íŒ¨ë„í‹°
        category_count = existing_categories.count(product.category_id)
        category_penalty = category_count * diversity_factor * 0.2
        
        # ë¸Œëœë“œ ì¤‘ë³µ íŒ¨ë„í‹°
        brand_count = existing_brands.count(product.brand_id)
        brand_penalty = brand_count * diversity_factor * 0.1
        
        # ìµœì¢… ì ìˆ˜ ê³„ì‚° (íŒ¨ë„í‹° ì ìš©)
        diversified_score = base_score * (1 - category_penalty - brand_penalty)
        return max(diversified_score, 0)  # ìŒìˆ˜ ë°©ì§€
    
    def _generate_explanation(self, user_id: int, product: Product, 
                            user_profile: np.ndarray, product_features: np.ndarray,
                            feature_info: Dict[str, Any]) -> Dict:
        """ì¶”ì²œ ì´ìœ  ìƒì„±"""
        explanations = []
        
        # ì‚¬ìš©ì ì¹´í…Œê³ ë¦¬ ì„ í˜¸ë„
        category_prefs = self.user_profile_builder.build_user_category_preference(user_id)
        
        if product.category and product.category.name in category_prefs:
            pref_score = category_prefs[product.category.name]
            if pref_score > 0.2:  # 20% ì´ìƒ ì„ í˜¸í•˜ëŠ” ê²½ìš°
                explanations.append(f"You often browse {product.category.name} category")
        
        # íŠ¹ì§•ë³„ ìœ ì‚¬ë„ ë¶„ì„
        feature_ranges = feature_info.get('feature_ranges', {})
        
        for feature_name, (start, end) in feature_ranges.items():
            if feature_name in ['category', 'brand']:
                user_feature_part = user_profile[start:end]
                product_feature_part = product_features[start:end]
                
                similarity = cosine_similarity([user_feature_part], [product_feature_part])[0][0]
                
                if similarity > 0.7:  # ë†’ì€ ìœ ì‚¬ë„
                    if feature_name == 'brand':
                        explanations.append(f"You like {product.brand.name} brand")
                    elif feature_name == 'category':
                        explanations.append(f"Matches your {product.category.name} preferences")
        
        return {
            'primary_reason': explanations[0] if explanations else "Based on your preferences",
            'all_reasons': explanations,
            'match_score': float(cosine_similarity([user_profile], [product_features])[0][0])
        }
    
    def _get_fallback_recommendations(self, user_id: int, num_recommendations: int) -> List[Dict]:
        """í´ë°± ì¶”ì²œ (ì¸ê¸° ìƒí’ˆ)"""
        popular_products = Product.objects.filter(
            is_active=True
        ).order_by('-view_count', '-purchase_count')[:num_recommendations]
        
        return [{
            'product_id': product.id,
            'product': product,
            'score': 1.0,
            'algorithm': 'popularity_fallback',
            'explanation': {'reason': 'Popular product'}
        } for product in popular_products]
```

### 4.2 ê³ ê¸‰ íŠ¹ì§• ì—”ì§€ë‹ˆì–´ë§

```python
# apps/recommendations/algorithms/advanced_features.py
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sentence_transformers import SentenceTransformer
import torch
from typing import Dict, List, Tuple, Optional
from apps.products.models import Product
import logging

logger = logging.getLogger(__name__)

class AdvancedFeatureExtractor:
    """ê³ ê¸‰ íŠ¹ì§• ì¶”ì¶œê¸°"""
    
    def __init__(self):
        self.sentence_transformer = None
        self.price_clusterer = KMeans(n_clusters=5, random_state=42)
        self.popularity_scaler = StandardScaler()
        
    def _load_sentence_transformer(self):
        """Sentence Transformer ëª¨ë¸ ë¡œë“œ (ì§€ì—° ë¡œë”©)"""
        if self.sentence_transformer is None:
            try:
                self.sentence_transformer = SentenceTransformer('all-MiniLM-L6-v2')
                logger.info("Sentence Transformer model loaded")
            except Exception as e:
                logger.error(f"Failed to load Sentence Transformer: {str(e)}")
                self.sentence_transformer = None
    
    def extract_semantic_features(self, products: List[Product]) -> Optional[np.ndarray]:
        """ì˜ë¯¸ì  íŠ¹ì§• ì¶”ì¶œ (Sentence Embeddings)"""
        self._load_sentence_transformer()
        
        if self.sentence_transformer is None:
            return None
        
        try:
            # ìƒí’ˆëª…ê³¼ ì„¤ëª…ì„ ê²°í•©í•œ í…ìŠ¤íŠ¸
            texts = []
            for product in products:
                text = f"{product.name} {product.description}"
                texts.append(text[:512])  # í† í° ê¸¸ì´ ì œí•œ
            
            # ì„ë² ë”© ìƒì„±
            embeddings = self.sentence_transformer.encode(
                texts, 
                show_progress_bar=True,
                batch_size=32
            )
            
            logger.info(f"Generated semantic embeddings: {embeddings.shape}")
            return embeddings
            
        except Exception as e:
            logger.error(f"Error in semantic feature extraction: {str(e)}")
            return None
    
    def extract_behavioral_features(self, products: List[Product]) -> np.ndarray:
        """í–‰ë™ ê¸°ë°˜ íŠ¹ì§• ì¶”ì¶œ"""
        features = []
        
        for product in products:
            # ì¸ê¸°ë„ ì§€í‘œ
            view_count = product.view_count
            purchase_count = product.purchase_count
            rating_count = product.rating_count
            average_rating = product.average_rating
            
            # CTR (Click Through Rate) ì¶”ì •
            ctr = purchase_count / max(view_count, 1)
            
            # ì „í™˜ìœ¨ (Conversion Rate)
            conversion_rate = purchase_count / max(view_count, 1)
            
            # í‰ì  ì‹ ë¢°ë„ (ë§ì€ í‰ì ì„ ë°›ì„ìˆ˜ë¡ ì‹ ë¢°ë„ ë†’ìŒ)
            rating_reliability = min(rating_count / 100, 1.0)
            
            # ìƒí’ˆ ìˆ˜ëª… (ìƒì„±ì¼ë¡œë¶€í„° ê²½ê³¼ ì‹œê°„)
            age_days = (timezone.now() - product.created).days
            age_normalized = min(age_days / 365, 1.0)  # 1ë…„ ê¸°ì¤€ ì •ê·œí™”
            
            features.append([
                view_count,
                purchase_count,
                rating_count,
                average_rating,
                ctr,
                conversion_rate,
                rating_reliability,
                age_normalized
            ])
        
        features_array = np.array(features)
        
        # ì •ê·œí™”
        normalized_features = self.popularity_scaler.fit_transform(features_array)
        
        return normalized_features
    
    def extract_price_clustering_features(self, products: List[Product]) -> np.ndarray:
        """ê°€ê²© í´ëŸ¬ìŠ¤í„°ë§ íŠ¹ì§•"""
        prices = np.array([float(product.price) for product in products]).reshape(-1, 1)
        
        # ê°€ê²©ëŒ€ë³„ í´ëŸ¬ìŠ¤í„°ë§
        price_clusters = self.price_clusterer.fit_predict(prices)
        
        # ì›í•« ì¸ì½”ë”©
        cluster_features = np.zeros((len(products), self.price_clusterer.n_clusters))
        for i, cluster in enumerate(price_clusters):
            cluster_features[i, cluster] = 1
        
        # ê°€ê²© í†µê³„ íŠ¹ì§• ì¶”ê°€
        price_stats = []
        for price in prices.flatten():
            # ê°€ê²© ë¶„ìœ„ìˆ˜
            percentile_25 = np.percentile(prices, 25)
            percentile_50 = np.percentile(prices, 50)
            percentile_75 = np.percentile(prices, 75)
            
            price_features = [
                1 if price <= percentile_25 else 0,  # ì €ê°€
                1 if percentile_25 < price <= percentile_50 else 0,  # ì¤‘ì €ê°€
                1 if percentile_50 < price <= percentile_75 else 0,  # ì¤‘ê³ ê°€
                1 if price > percentile_75 else 0,  # ê³ ê°€
            ]
            price_stats.append(price_features)
        
        price_stats_array = np.array(price_stats)
        
        # í´ëŸ¬ìŠ¤í„° íŠ¹ì§•ê³¼ í†µê³„ íŠ¹ì§• ê²°í•©
        return np.hstack([cluster_features, price_stats_array])
    
    def extract_temporal_features(self, products: List[Product]) -> np.ndarray:
        """ì‹œê°„ì  íŠ¹ì§• ì¶”ì¶œ"""
        features = []
        
        for product in products:
            # ê³„ì ˆì„± íŠ¹ì§• (ìƒí’ˆ ìƒì„± ì›”)
            created_month = product.created.month
            season_features = [0, 0, 0, 0]  # ë´„, ì—¬ë¦„, ê°€ì„, ê²¨ìš¸
            
            if created_month in [3, 4, 5]:
                season_features[0] = 1  # ë´„
            elif created_month in [6, 7, 8]:
                season_features[1] = 1  # ì—¬ë¦„
            elif created_month in [9, 10, 11]:
                season_features[2] = 1  # ê°€ì„
            else:
                season_features[3] = 1  # ê²¨ìš¸
            
            # ìš”ì¼ íŠ¹ì§• (ìƒí’ˆ ìƒì„± ìš”ì¼)
            created_weekday = product.created.weekday()
            weekday_features = [0] * 7
            weekday_features[created_weekday] = 1
            
            # íŠ¸ë Œë“œ íŠ¹ì§•
            # ìµœê·¼ ìƒì„±ëœ ìƒí’ˆì¼ìˆ˜ë¡ ë†’ì€ íŠ¸ë Œë“œ ì ìˆ˜
            days_since_creation = (timezone.now() - product.created).days
            trend_score = max(0, 1 - days_since_creation / 365)  # 1ë…„ ê¸°ì¤€
            
            all_features = season_features + weekday_features + [trend_score]
            features.append(all_features)
        
        return np.array(features)

class MultiModalFeatureFusion:
    """ë‹¤ì¤‘ ëª¨ë‹¬ íŠ¹ì§• ìœµí•©"""
    
    def __init__(self, fusion_method: str = 'concatenation'):
        self.fusion_method = fusion_method
        self.feature_weights = {
            'semantic': 0.3,
            'behavioral': 0.25,
            'price': 0.2,
            'temporal': 0.15,
            'categorical': 0.1
        }
    
    def fuse_features(self, feature_dict: Dict[str, np.ndarray]) -> np.ndarray:
        """ì—¬ëŸ¬ íŠ¹ì§•ë“¤ì„ ìœµí•©"""
        if self.fusion_method == 'concatenation':
            return self._concatenate_features(feature_dict)
        elif self.fusion_method == 'weighted_sum':
            return self._weighted_sum_features(feature_dict)
        elif self.fusion_method == 'attention':
            return self._attention_fusion(feature_dict)
        else:
            raise ValueError(f"Unknown fusion method: {self.fusion_method}")
    
    def _concatenate_features(self, feature_dict: Dict[str, np.ndarray]) -> np.ndarray:
        """ë‹¨ìˆœ ì—°ê²°"""
        features_list = []
        
        for feature_name, features in feature_dict.items():
            if features is not None and features.size > 0:
                # ê°€ì¤‘ì¹˜ ì ìš©
                weight = self.feature_weights.get(feature_name, 1.0)
                weighted_features = features * weight
                features_list.append(weighted_features)
        
        if features_list:
            return np.hstack(features_list)
        else:
            return np.array([])
    
    def _weighted_sum_features(self, feature_dict: Dict[str, np.ndarray]) -> np.ndarray:
        """ê°€ì¤‘ í•©"""
        # ëª¨ë“  íŠ¹ì§•ì˜ ì°¨ì›ì„ ë§ì¶˜ í›„ ê°€ì¤‘ í‰ê· 
        target_dim = max(f.shape[1] for f in feature_dict.values() if f is not None)
        
        weighted_sum = None
        total_weight = 0
        
        for feature_name, features in feature_dict.items():
            if features is None:
                continue
            
            weight = self.feature_weights.get(feature_name, 1.0)
            
            # ì°¨ì› ë§ì¶”ê¸° (íŒ¨ë”© ë˜ëŠ” ì°¨ì› ì¶•ì†Œ)
            if features.shape[1] < target_dim:
                padded_features = np.pad(
                    features, 
                    ((0, 0), (0, target_dim - features.shape[1])), 
                    'constant'
                )
            elif features.shape[1] > target_dim:
                padded_features = features[:, :target_dim]
            else:
                padded_features = features
            
            if weighted_sum is None:
                weighted_sum = weight * padded_features
            else:
                weighted_sum += weight * padded_features
            
            total_weight += weight
        
        if weighted_sum is not None and total_weight > 0:
            return weighted_sum / total_weight
        else:
            return np.array([])
    
    def _attention_fusion(self, feature_dict: Dict[str, np.ndarray]) -> np.ndarray:
        """ì–´í…ì…˜ ê¸°ë°˜ ìœµí•© (ê°„ë‹¨í•œ ë²„ì „)"""
        # ê° íŠ¹ì§•ì˜ ì¤‘ìš”ë„ë¥¼ ë™ì ìœ¼ë¡œ ê³„ì‚°
        features_list = []
        attention_weights = []
        
        for feature_name, features in feature_dict.items():
            if features is None:
                continue
            
            # íŠ¹ì§•ì˜ ë¶„ì‚°ì„ ê¸°ë°˜ìœ¼ë¡œ ì¤‘ìš”ë„ ê³„ì‚°
            feature_variance = np.var(features, axis=0).mean()
            attention_weight = np.exp(feature_variance) / (1 + np.exp(feature_variance))
            
            features_list.append(features)
            attention_weights.append(attention_weight)
        
        if not features_list:
            return np.array([])
        
        # ì–´í…ì…˜ ê°€ì¤‘ì¹˜ ì •ê·œí™”
        attention_weights = np.array(attention_weights)
        attention_weights = attention_weights / attention_weights.sum()
        
        # ê°€ì¤‘ ì—°ê²°
        weighted_features = []
        for features, weight in zip(features_list, attention_weights):
            weighted_features.append(features * weight)
        
        return np.hstack(weighted_features)
```

---

## ğŸ”€ 5. í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ì‹œìŠ¤í…œ êµ¬í˜„

ì—¬ëŸ¬ ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ì„ ì¡°í•©í•˜ì—¬ ê°ê°ì˜ ì¥ì ì„ ì‚´ë¦¬ê³  ë‹¨ì ì„ ë³´ì™„í•˜ëŠ” í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œì„ êµ¬í˜„í•©ë‹ˆë‹¤.

### 5.1 í•˜ì´ë¸Œë¦¬ë“œ ì „ëµ ë§¤ë‹ˆì €

```python
# apps/recommendations/algorithms/hybrid.py
import numpy as np
from typing import Dict, List, Optional, Any, Tuple
from django.core.cache import cache
from django.contrib.auth.models import User
from apps.recommendations.algorithms.collaborative import (
    UserBasedCollaborativeFiltering, 
    ItemBasedCollaborativeFiltering
)
from apps.recommendations.algorithms.content_based import ContentBasedRecommender
from apps.recommendations.models import UserInteraction, RecommendationRequest
from apps.products.models import Product
import logging

logger = logging.getLogger(__name__)

class HybridRecommendationStrategy:
    """í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ì „ëµ ì¸í„°í˜ì´ìŠ¤"""
    
    def combine_recommendations(self, recommendations_dict: Dict[str, List[Dict]], 
                             user_id: int, num_recommendations: int) -> List[Dict]:
        raise NotImplementedError

class WeightedHybridStrategy(HybridRecommendationStrategy):
    """ê°€ì¤‘ì¹˜ ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ"""
    
    def __init__(self, algorithm_weights: Dict[str, float] = None):
        self.algorithm_weights = algorithm_weights or {
            'collaborative_user': 0.4,
            'collaborative_item': 0.3,
            'content_based': 0.3
        }
    
    def combine_recommendations(self, recommendations_dict: Dict[str, List[Dict]], 
                             user_id: int, num_recommendations: int) -> List[Dict]:
        """ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ì¶”ì²œ ì¡°í•©"""
        
        # ëª¨ë“  ì¶”ì²œëœ ìƒí’ˆë“¤ ìˆ˜ì§‘
        all_products = {}
        
        for algorithm, recommendations in recommendations_dict.items():
            weight = self.algorithm_weights.get(algorithm, 0.1)
            
            for rec in recommendations:
                product_id = rec['product_id']
                
                if product_id not in all_products:
                    all_products[product_id] = {
                        'product_id': product_id,
                        'product': rec['product'],
                        'total_score': 0,
                        'algorithm_scores': {},
                        'explanations': []
                    }
                
                # ê°€ì¤‘ì¹˜ ì ìš©í•œ ì ìˆ˜ í•©ì‚°
                weighted_score = rec['score'] * weight
                all_products[product_id]['total_score'] += weighted_score
                all_products[product_id]['algorithm_scores'][algorithm] = rec['score']
                
                # ì„¤ëª… ìˆ˜ì§‘
                if 'explanation' in rec:
                    all_products[product_id]['explanations'].append({
                        'algorithm': algorithm,
                        'explanation': rec['explanation']
                    })
        
        # ì ìˆ˜ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_products = sorted(
            all_products.values(), 
            key=lambda x: x['total_score'], 
            reverse=True
        )
        
        # ìµœì¢… ì¶”ì²œ ê²°ê³¼ ìƒì„±
        final_recommendations = []
        for i, product_data in enumerate(sorted_products[:num_recommendations]):
            final_recommendations.append({
                'product_id': product_data['product_id'],
                'product': product_data['product'],
                'score': product_data['total_score'],
                'rank': i + 1,
                'algorithm': 'weighted_hybrid',
                'algorithm_scores': product_data['algorithm_scores'],
                'explanation': self._generate_hybrid_explanation(product_data)
            })
        
        return final_recommendations
    
    def _generate_hybrid_explanation(self, product_data: Dict) -> Dict:
        """í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ì„¤ëª… ìƒì„±"""
        explanations = product_data['explanations']
        algorithm_scores = product_data['algorithm_scores']
        
        # ê°€ì¥ ë†’ì€ ì ìˆ˜ë¥¼ ì¤€ ì•Œê³ ë¦¬ì¦˜ ì°¾ê¸°
        best_algorithm = max(algorithm_scores, key=algorithm_scores.get)
        best_score = algorithm_scores[best_algorithm]
        
        # ì£¼ìš” ì¶”ì²œ ì´ìœ  ê²°ì •
        primary_reasons = []
        for exp_data in explanations:
            if exp_data['algorithm'] == best_algorithm:
                exp = exp_data['explanation']
                if isinstance(exp, dict):
                    primary_reasons.append(exp.get('primary_reason', 'Recommended by multiple algorithms'))
                else:
                    primary_reasons.append('Recommended by multiple algorithms')
        
        return {
            'primary_reason': primary_reasons[0] if primary_reasons else 'Recommended by multiple algorithms',
            'contributing_algorithms': list(algorithm_scores.keys()),
            'best_algorithm': best_algorithm,
            'confidence_score': min(best_score, 1.0),
            'consensus_score': len(algorithm_scores) / 3.0  # 3ê°œ ì•Œê³ ë¦¬ì¦˜ ê¸°ì¤€
        }

class SwitchingHybridStrategy(HybridRecommendationStrategy):
    """ìŠ¤ìœ„ì¹­ ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ (ìƒí™©ì— ë”°ë¼ ì•Œê³ ë¦¬ì¦˜ ì„ íƒ)"""
    
    def __init__(self):
        self.min_interactions_for_cf = 10
        self.min_products_for_content = 50
    
    def combine_recommendations(self, recommendations_dict: Dict[str, List[Dict]], 
                             user_id: int, num_recommendations: int) -> List[Dict]:
        """ìƒí™©ì— ë”°ë¼ ìµœì  ì•Œê³ ë¦¬ì¦˜ ì„ íƒ"""
        
        # ì‚¬ìš©ì ìƒí™© ë¶„ì„
        user_context = self._analyze_user_context(user_id)
        
        # ì•Œê³ ë¦¬ì¦˜ ì„ íƒ ë¡œì§
        selected_algorithm = self._select_best_algorithm(user_context, recommendations_dict)
        
        logger.info(f"Switching strategy selected: {selected_algorithm} for user {user_id}")
        
        # ì„ íƒëœ ì•Œê³ ë¦¬ì¦˜ì˜ ì¶”ì²œ ë°˜í™˜
        if selected_algorithm in recommendations_dict:
            recommendations = recommendations_dict[selected_algorithm][:num_recommendations]
            
            # ì•Œê³ ë¦¬ì¦˜ ì •ë³´ ì¶”ê°€
            for rec in recommendations:
                rec['algorithm'] = f'switching_{selected_algorithm}'
                if 'explanation' not in rec:
                    rec['explanation'] = {}
                rec['explanation']['selection_reason'] = f'Best algorithm for your profile: {selected_algorithm}'
            
            return recommendations
        
        # í´ë°±: ê°€ì¤‘ì¹˜ ì „ëµ ì‚¬ìš©
        weighted_strategy = WeightedHybridStrategy()
        return weighted_strategy.combine_recommendations(recommendations_dict, user_id, num_recommendations)
    
    def _analyze_user_context(self, user_id: int) -> Dict:
        """ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ë¶„ì„"""
        # ì‚¬ìš©ì ìƒí˜¸ì‘ìš© í†µê³„
        interactions_count = UserInteraction.objects.filter(user_id=user_id).count()
        
        # ìƒí˜¸ì‘ìš© ë‹¤ì–‘ì„± (ì„œë¡œ ë‹¤ë¥¸ ìƒí’ˆ ìˆ˜)
        unique_products = UserInteraction.objects.filter(
            user_id=user_id
        ).values('product_id').distinct().count()
        
        # ìµœê·¼ í™œë™ (7ì¼ ì´ë‚´)
        from django.utils import timezone
        from datetime import timedelta
        
        recent_interactions = UserInteraction.objects.filter(
            user_id=user_id,
            created__gte=timezone.now() - timedelta(days=7)
        ).count()
        
        # ì‚¬ìš©ì í”„ë¡œí•„ ì™„ì„±ë„
        try:
            user = User.objects.get(id=user_id)
            profile_completeness = 0
            if hasattr(user, 'profile'):
                profile = user.profile
                if profile.preferred_categories.exists():
                    profile_completeness += 0.3
                if profile.preferred_brands.exists():
                    profile_completeness += 0.3
                if profile.preferred_price_range:
                    profile_completeness += 0.2
                if profile.age_range:
                    profile_completeness += 0.2
        except:
            profile_completeness = 0
        
        return {
            'interactions_count': interactions_count,
            'unique_products': unique_products,
            'recent_activity': recent_interactions,
            'profile_completeness': profile_completeness,
            'diversity_ratio': unique_products / max(interactions_count, 1)
        }
    
    def _select_best_algorithm(self, user_context: Dict, recommendations_dict: Dict) -> str:
        """ìµœì  ì•Œê³ ë¦¬ì¦˜ ì„ íƒ"""
        interactions_count = user_context['interactions_count']
        profile_completeness = user_context['profile_completeness']
        recent_activity = user_context['recent_activity']
        
        # ì‹ ê·œ ì‚¬ìš©ì (ìƒí˜¸ì‘ìš© ë¶€ì¡±)
        if interactions_count < self.min_interactions_for_cf:
            if profile_completeness > 0.5:
                return 'content_based'  # í”„ë¡œí•„ ì •ë³´ê°€ ìˆìœ¼ë©´ ì½˜í…ì¸  ê¸°ë°˜
            else:
                return 'popularity'  # ì¸ê¸°ë„ ê¸°ë°˜ í´ë°±
        
        # í™œë°œí•œ ì‚¬ìš©ì
        elif interactions_count >= self.min_interactions_for_cf:
            # ìµœê·¼ í™œë™ì´ ë§ìœ¼ë©´ í˜‘ì—… í•„í„°ë§
            if recent_activity >= 3:
                return 'collaborative_user'
            else:
                return 'collaborative_item'
        
        # ì¤‘ê°„ ë‹¨ê³„ ì‚¬ìš©ì
        else:
            return 'content_based'

class CascadingHybridStrategy(HybridRecommendationStrategy):
    """ìºìŠ¤ì¼€ì´ë”© í•˜ì´ë¸Œë¦¬ë“œ (ìˆœì°¨ì  í•„í„°ë§)"""
    
    def __init__(self, cascade_order: List[str] = None, min_recommendations_per_stage: int = 5):
        self.cascade_order = cascade_order or [
            'collaborative_user',
            'collaborative_item', 
            'content_based'
        ]
        self.min_recommendations_per_stage = min_recommendations_per_stage
    
    def combine_recommendations(self, recommendations_dict: Dict[str, List[Dict]], 
                             user_id: int, num_recommendations: int) -> List[Dict]:
        """ìˆœì°¨ì ìœ¼ë¡œ ì¶”ì²œ ìƒì„±"""
        
        final_recommendations = []
        used_product_ids = set()
        
        for algorithm in self.cascade_order:
            if algorithm not in recommendations_dict:
                continue
            
            # í˜„ì¬ ë‹¨ê³„ì—ì„œ í•„ìš”í•œ ì¶”ì²œ ìˆ˜
            needed = num_recommendations - len(final_recommendations)
            if needed <= 0:
                break
            
            # ì´ë¯¸ ì„ íƒëœ ìƒí’ˆ ì œì™¸í•˜ê³  ì¶”ì²œ ì¶”ê°€
            algorithm_recommendations = recommendations_dict[algorithm]
            
            stage_count = 0
            for rec in algorithm_recommendations:
                if stage_count >= max(needed, self.min_recommendations_per_stage):
                    break
                
                product_id = rec['product_id']
                if product_id not in used_product_ids:
                    # ìºìŠ¤ì¼€ì´ë”© ì •ë³´ ì¶”ê°€
                    rec_copy = rec.copy()
                    rec_copy['algorithm'] = f'cascading_{algorithm}'
                    rec_copy['cascade_stage'] = len(final_recommendations) // self.min_recommendations_per_stage + 1
                    
                    final_recommendations.append(rec_copy)
                    used_product_ids.add(product_id)
                    stage_count += 1
        
        # ìˆœìœ„ ì¬ì •ë ¬
        for i, rec in enumerate(final_recommendations):
            rec['rank'] = i + 1
        
        return final_recommendations[:num_recommendations]

class MixedHybridStrategy(HybridRecommendationStrategy):
    """ë¯¹ìŠ¤ë“œ í•˜ì´ë¸Œë¦¬ë“œ (ì•Œê³ ë¦¬ì¦˜ë³„ë¡œ ì¼ì • ë¹„ìœ¨ ë°°ë¶„)"""
    
    def __init__(self, algorithm_ratios: Dict[str, float] = None):
        self.algorithm_ratios = algorithm_ratios or {
            'collaborative_user': 0.4,
            'collaborative_item': 0.3,
            'content_based': 0.3
        }
    
    def combine_recommendations(self, recommendations_dict: Dict[str, List[Dict]], 
                             user_id: int, num_recommendations: int) -> List[Dict]:
        """ê° ì•Œê³ ë¦¬ì¦˜ì—ì„œ ì¼ì • ë¹„ìœ¨ë¡œ ì¶”ì²œ ì„ íƒ"""
        
        final_recommendations = []
        used_product_ids = set()
        
        # ê° ì•Œê³ ë¦¬ì¦˜ë³„ í• ë‹¹ ê°œìˆ˜ ê³„ì‚°
        algorithm_allocations = {}
        remaining_slots = num_recommendations
        
        for algorithm, ratio in self.algorithm_ratios.items():
            if algorithm in recommendations_dict:
                allocated = int(num_recommendations * ratio)
                algorithm_allocations[algorithm] = allocated
                remaining_slots -= allocated
        
        # ë‚¨ì€ ìŠ¬ë¡¯ì„ ì²« ë²ˆì§¸ ì•Œê³ ë¦¬ì¦˜ì— í• ë‹¹
        if remaining_slots > 0 and algorithm_allocations:
            first_algorithm = next(iter(algorithm_allocations.keys()))
            algorithm_allocations[first_algorithm] += remaining_slots
        
        # ê° ì•Œê³ ë¦¬ì¦˜ì—ì„œ í• ë‹¹ëœ ìˆ˜ë§Œí¼ ì¶”ì²œ ì„ íƒ
        for algorithm, allocated_count in algorithm_allocations.items():
            if algorithm not in recommendations_dict:
                continue
            
            algorithm_recommendations = recommendations_dict[algorithm]
            added_count = 0
            
            for rec in algorithm_recommendations:
                if added_count >= allocated_count:
                    break
                
                product_id = rec['product_id']
                if product_id not in used_product_ids:
                    rec_copy = rec.copy()
                    rec_copy['algorithm'] = f'mixed_{algorithm}'
                    rec_copy['allocation_source'] = algorithm
                    
                    final_recommendations.append(rec_copy)
                    used_product_ids.add(product_id)
                    added_count += 1
        
        # ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ì„ íƒì‚¬í•­)
        final_recommendations.sort(key=lambda x: x.get('score', 0), reverse=True)
        
        # ìˆœìœ„ ì¬ì •ë ¬
        for i, rec in enumerate(final_recommendations):
            rec['rank'] = i + 1
        
        return final_recommendations

class HybridRecommendationManager:
    """í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ê´€ë¦¬ì"""
    
    def __init__(self):
        self.collaborative_user = UserBasedCollaborativeFiltering()
        self.collaborative_item = ItemBasedCollaborativeFiltering()
        self.content_based = ContentBasedRecommender()
        
        # í•˜ì´ë¸Œë¦¬ë“œ ì „ëµë“¤
        self.strategies = {
            'weighted': WeightedHybridStrategy(),
            'switching': SwitchingHybridStrategy(),
            'cascading': CascadingHybridStrategy(),
            'mixed': MixedHybridStrategy()
        }
        
        self.default_strategy = 'weighted'
    
    def recommend(self, user_id: int, num_recommendations: int = 10, 
                 strategy: str = None, context: Dict = None) -> List[Dict]:
        """í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ì‹¤í–‰"""
        
        if strategy is None:
            strategy = self._select_optimal_strategy(user_id, context)
        
        logger.info(f"Using hybrid strategy: {strategy} for user {user_id}")
        
        try:
            # ê° ì•Œê³ ë¦¬ì¦˜ë³„ ì¶”ì²œ ìƒì„±
            recommendations_dict = {}
            
            # User-Based Collaborative Filtering
            try:
                cf_user_recs = self.collaborative_user.recommend(
                    user_id, num_recommendations * 2  # ë” ë§ì´ ìƒì„± í›„ í•„í„°ë§
                )
                if cf_user_recs:
                    recommendations_dict['collaborative_user'] = cf_user_recs
            except Exception as e:
                logger.error(f"User-based CF failed: {str(e)}")
            
            # Item-Based Collaborative Filtering  
            try:
                cf_item_recs = self.collaborative_item.recommend(
                    user_id, num_recommendations * 2
                )
                if cf_item_recs:
                    recommendations_dict['collaborative_item'] = cf_item_recs
            except Exception as e:
                logger.error(f"Item-based CF failed: {str(e)}")
            
            # Content-Based Filtering
            try:
                content_recs = self.content_based.recommend(
                    user_id, num_recommendations * 2
                )
                if content_recs:
                    recommendations_dict['content_based'] = content_recs
            except Exception as e:
                logger.error(f"Content-based filtering failed: {str(e)}")
            
            # ì¶”ì²œì´ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ ì¸ê¸°ë„ ê¸°ë°˜ í´ë°±
            if not recommendations_dict:
                return self._get_popularity_recommendations(user_id, num_recommendations)
            
            # ì„ íƒëœ ì „ëµìœ¼ë¡œ í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ìƒì„±
            hybrid_strategy = self.strategies.get(strategy, self.strategies[self.default_strategy])
            
            final_recommendations = hybrid_strategy.combine_recommendations(
                recommendations_dict, user_id, num_recommendations
            )
            
            # ë‹¤ì–‘ì„± ì¦ì§„ (ì„ íƒì‚¬í•­)
            if context and context.get('diversity_boost', False):
                final_recommendations = self._apply_diversity_boost(final_recommendations)
            
            return final_recommendations
            
        except Exception as e:
            logger.error(f"Hybrid recommendation failed: {str(e)}")
            return self._get_popularity_recommendations(user_id, num_recommendations)
    
    def _select_optimal_strategy(self, user_id: int, context: Dict = None) -> str:
        """ìµœì  í•˜ì´ë¸Œë¦¬ë“œ ì „ëµ ì„ íƒ"""
        
        # ì‚¬ìš©ì ìƒí˜¸ì‘ìš© ìˆ˜ í™•ì¸
        interaction_count = UserInteraction.objects.filter(user_id=user_id).count()
        
        # A/B í…ŒìŠ¤íŠ¸ ê·¸ë£¹ í™•ì¸
        ab_group = self._get_ab_test_group(user_id)
        
        # ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì„ íƒ
        if context:
            if context.get('exploration_mode', False):
                return 'mixed'  # íƒí—˜ ëª¨ë“œì—ì„œëŠ” ë‹¤ì–‘í•œ ì•Œê³ ë¦¬ì¦˜ í˜¼í•©
            elif context.get('precision_mode', False):
                return 'weighted'  # ì •í™•ë„ ìš°ì„ ì‹œ
        
        # ê¸°ë³¸ ì„ íƒ ë¡œì§
        if interaction_count < 5:
            return 'cascading'  # ì‹ ê·œ ì‚¬ìš©ì
        elif interaction_count < 20:
            return 'switching'  # ì¤‘ê°„ ì‚¬ìš©ì
        else:
            if ab_group == 'A':
                return 'weighted'
            else:
                return 'mixed'
    
    def _get_ab_test_group(self, user_id: int) -> str:
        """A/B í…ŒìŠ¤íŠ¸ ê·¸ë£¹ ê²°ì •"""
        # ì‚¬ìš©ì ID ê¸°ë°˜ í•´ì‹œë¡œ ì¼ê´€ëœ ê·¸ë£¹ ë°°ì •
        return 'A' if user_id % 2 == 0 else 'B'
    
    def _apply_diversity_boost(self, recommendations: List[Dict]) -> List[Dict]:
        """ë‹¤ì–‘ì„± ì¦ì§„ ì ìš©"""
        if len(recommendations) <= 1:
            return recommendations
        
        # ì¹´í…Œê³ ë¦¬/ë¸Œëœë“œ ë‹¤ì–‘ì„± í™•ì¸
        categories = set()
        brands = set()
        diversified_recs = []
        
        for rec in recommendations:
            product = rec['product']
            category_id = product.category_id if product.category else None
            brand_id = product.brand_id if product.brand else None
            
            # ë‹¤ì–‘ì„± ì ìˆ˜ ê³„ì‚°
            diversity_bonus = 0
            
            if category_id not in categories:
                diversity_bonus += 0.1
                categories.add(category_id)
            
            if brand_id not in brands:
                diversity_bonus += 0.05
                brands.add(brand_id)
            
            # ì ìˆ˜ì— ë‹¤ì–‘ì„± ë³´ë„ˆìŠ¤ ì¶”ê°€
            rec['score'] += diversity_bonus
            diversified_recs.append(rec)
        
        # ìƒˆë¡œìš´ ì ìˆ˜ë¡œ ì¬ì •ë ¬
        diversified_recs.sort(key=lambda x: x['score'], reverse=True)
        
        # ìˆœìœ„ ì¬ì„¤ì •
        for i, rec in enumerate(diversified_recs):
            rec['rank'] = i + 1
        
        return diversified_recs
    
    def _get_popularity_recommendations(self, user_id: int, num_recommendations: int) -> List[Dict]:
        """ì¸ê¸°ë„ ê¸°ë°˜ í´ë°± ì¶”ì²œ"""
        popular_products = Product.objects.filter(
            is_active=True
        ).order_by('-purchase_count', '-view_count')[:num_recommendations]
        
        recommendations = []
        for i, product in enumerate(popular_products):
            recommendations.append({
                'product_id': product.id,
                'product': product,
                'score': 1.0 - (i * 0.05),  # ìˆœìœ„ë³„ ì ìˆ˜
                'rank': i + 1,
                'algorithm': 'popularity_fallback',
                'explanation': {
                    'primary_reason': 'Popular product',
                    'fallback_reason': 'Insufficient data for personalized recommendations'
                }
            })
        
        return recommendations
    
    def evaluate_strategy_performance(self, user_id: int, strategy: str, 
                                   recommendations: List[Dict]) -> Dict[str, float]:
        """ì „ëµ ì„±ê³¼ í‰ê°€"""
        
        # ì‹¤ì œ ì‚¬ìš©ì í–‰ë™ê³¼ ë¹„êµí•˜ì—¬ ì„±ê³¼ ì¸¡ì •
        # (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” A/B í…ŒìŠ¤íŠ¸ ê²°ê³¼ë‚˜ ì˜¤í”„ë¼ì¸ í‰ê°€ ë°ì´í„° ì‚¬ìš©)
        
        metrics = {
            'precision': 0.0,
            'recall': 0.0,
            'diversity': 0.0,
            'novelty': 0.0,
            'coverage': 0.0
        }
        
        if not recommendations:
            return metrics
        
        # ë‹¤ì–‘ì„± ê³„ì‚° (ì¹´í…Œê³ ë¦¬/ë¸Œëœë“œ ê¸°ì¤€)
        categories = set(rec['product'].category_id for rec in recommendations if rec['product'].category)
        brands = set(rec['product'].brand_id for rec in recommendations if rec['product'].brand)
        
        metrics['diversity'] = (len(categories) + len(brands)) / (2 * len(recommendations))
        
        # ì‹ ê·œì„± ê³„ì‚° (ì¸ê¸°ë„ ì—­ìˆ˜ ê¸°ì¤€)
        popularity_scores = [1.0 / max(rec['product'].view_count, 1) for rec in recommendations]
        metrics['novelty'] = np.mean(popularity_scores)
        
        # ì»¤ë²„ë¦¬ì§€ (ì „ì²´ ìƒí’ˆ ëŒ€ë¹„ ì¶”ì²œëœ ìƒí’ˆ ë¹„ìœ¨)
        total_products = Product.objects.filter(is_active=True).count()
        metrics['coverage'] = len(recommendations) / max(total_products, 1)
        
        return metrics
```

### 5.2 ì‹¤ì‹œê°„ ì¶”ì²œ ìµœì í™”

```python
# apps/recommendations/services.py
from typing import Dict, List, Optional, Any
from django.core.cache import cache
from django.contrib.auth.models import User
from django.utils import timezone
from datetime import timedelta
from apps.recommendations.algorithms.hybrid import HybridRecommendationManager
from apps.recommendations.models import (
    RecommendationRequest, RecommendationResult, 
    RecommendationAlgorithm, UserInteraction
)
import logging
import time
import hashlib

logger = logging.getLogger(__name__)

class RecommendationService:
    """ì¶”ì²œ ì„œë¹„ìŠ¤ ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.hybrid_manager = HybridRecommendationManager()
        self.cache_timeout = 1800  # 30ë¶„
        self.max_cache_size = 1000
    
    def get_recommendations(self, user_id: int, num_recommendations: int = 10,
                          context: Dict = None, force_refresh: bool = False) -> Dict[str, Any]:
        """ë©”ì¸ ì¶”ì²œ API"""
        
        start_time = time.time()
        
        try:
            # ìºì‹œ í‚¤ ìƒì„±
            cache_key = self._generate_cache_key(user_id, num_recommendations, context)
            
            # ìºì‹œ í™•ì¸
            if not force_refresh:
                cached_result = cache.get(cache_key)
                if cached_result:
                    logger.info(f"Cache hit for user {user_id}")
                    cached_result['cache_hit'] = True
                    cached_result['response_time_ms'] = int((time.time() - start_time) * 1000)
                    return cached_result
            
            # ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ë¶„ì„
            user_context = self._analyze_user_context(user_id, context)
            
            # ì¶”ì²œ ìƒì„±
            recommendations = self.hybrid_manager.recommend(
                user_id=user_id,
                num_recommendations=num_recommendations,
                context=user_context
            )
            
            # ì¶”ì²œ ìš”ì²­ ë¡œê¹…
            request_id = self._log_recommendation_request(
                user_id, recommendations, user_context, start_time
            )
            
            # ê²°ê³¼ í¬ë§·íŒ…
            result = {
                'recommendations': [
                    {
                        'product_id': rec['product_id'],
                        'product_name': rec['product'].name,
                        'product_price': float(rec['product'].price),
                        'product_image': getattr(rec['product'], 'image_url', ''),
                        'score': rec['score'],
                        'rank': rec['rank'],
                        'algorithm': rec['algorithm'],
                        'explanation': rec.get('explanation', {})
                    }
                    for rec in recommendations
                ],
                'total_count': len(recommendations),
                'algorithm_used': recommendations[0]['algorithm'] if recommendations else 'none',
                'request_id': request_id,
                'user_context': user_context,
                'cache_hit': False,
                'response_time_ms': int((time.time() - start_time) * 1000)
            }
            
            # ê²°ê³¼ ìºì‹±
            cache.set(cache_key, result, timeout=self.cache_timeout)
            
            return result
            
        except Exception as e:
            logger.error(f"Error in get_recommendations: {str(e)}")
            return {
                'recommendations': [],
                'total_count': 0,
                'algorithm_used': 'error',
                'request_id': '',
                'error': str(e),
                'response_time_ms': int((time.time() - start_time) * 1000)
            }
    
    def get_similar_products(self, product_id: int, num_recommendations: int = 10) -> List[Dict]:
        """ìœ ì‚¬ ìƒí’ˆ ì¶”ì²œ"""
        
        cache_key = f"similar_products_{product_id}_{num_recommendations}"
        cached_result = cache.get(cache_key)
        
        if cached_result:
            return cached_result
        
        try:
            # ì½˜í…ì¸  ê¸°ë°˜ ìœ ì‚¬ ìƒí’ˆ
            content_similar = self.hybrid_manager.content_based.get_similar_products(
                product_id, num_recommendations
            )
            
            # í˜‘ì—… í•„í„°ë§ ê¸°ë°˜ ìœ ì‚¬ ìƒí’ˆ
            cf_similar = self.hybrid_manager.collaborative_item.get_similar_items(
                product_id, num_recommendations
            )
            
            # ë‘ ê²°ê³¼ ì¡°í•© (ê°€ì¤‘ í‰ê· )
            combined_results = self._combine_similar_products(content_similar, cf_similar)
            
            # ìºì‹±
            cache.set(cache_key, combined_results, timeout=3600)  # 1ì‹œê°„
            
            return combined_results
            
        except Exception as e:
            logger.error(f"Error in get_similar_products: {str(e)}")
            return []
    
    def update_user_interaction(self, user_id: int, product_id: int, 
                              interaction_type: str, value: float = None,
                              context: Dict = None) -> bool:
        """ì‚¬ìš©ì ìƒí˜¸ì‘ìš© ì—…ë°ì´íŠ¸"""
        
        try:
            # ìƒí˜¸ì‘ìš© ê¸°ë¡
            interaction = UserInteraction.objects.create(
                user_id=user_id,
                product_id=product_id,
                interaction_type=interaction_type,
                value=value,
                session_id=context.get('session_id', '') if context else '',
                device_type=context.get('device_type', '') if context else '',
                source=context.get('source', '') if context else ''
            )
            
            # ê´€ë ¨ ìºì‹œ ë¬´íš¨í™”
            self._invalidate_user_cache(user_id)
            
            # ì‹¤ì‹œê°„ ëª¨ë¸ ì—…ë°ì´íŠ¸ (ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…)
            from apps.recommendations.tasks import update_user_profile
            update_user_profile.delay(user_id)
            
            logger.info(f"Interaction recorded: user={user_id}, product={product_id}, type={interaction_type}")
            return True
            
        except Exception as e:
            logger.error(f"Error recording interaction: {str(e)}")
            return False
    
    def get_recommendation_explanation(self, user_id: int, product_id: int) -> Dict:
        """ì¶”ì²œ ì´ìœ  ìƒì„¸ ì„¤ëª…"""
        
        try:
            # ìµœê·¼ ì¶”ì²œ ê²°ê³¼ì—ì„œ í•´ë‹¹ ìƒí’ˆ ì°¾ê¸°
            recent_request = RecommendationRequest.objects.filter(
                user_id=user_id,
                created__gte=timezone.now() - timedelta(hours=1)
            ).first()
            
            if recent_request:
                result = RecommendationResult.objects.filter(
                    request=recent_request,
                    product_id=product_id
                ).first()
                
                if result:
                    return {
                        'explanation': result.explanation,
                        'score': result.score,
                        'rank': result.rank,
                        'algorithm_used': recent_request.algorithm.name if recent_request.algorithm else 'unknown'
                    }
            
            # ì‹¤ì‹œê°„ ì„¤ëª… ìƒì„± (ìºì‹œëœ ì¶”ì²œì´ ì—†ëŠ” ê²½ìš°)
            return self._generate_realtime_explanation(user_id, product_id)
            
        except Exception as e:
            logger.error(f"Error generating explanation: {str(e)}")
            return {'explanation': 'Unable to generate explanation'}
    
    def _generate_cache_key(self, user_id: int, num_recommendations: int, context: Dict = None) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        key_parts = [f"rec_{user_id}_{num_recommendations}"]
        
        if context:
            # ì»¨í…ìŠ¤íŠ¸ë¥¼ ì •ë ¬í•˜ì—¬ ì¼ê´€ëœ í‚¤ ìƒì„±
            context_str = '_'.join(f"{k}:{v}" for k, v in sorted(context.items()))
            key_parts.append(context_str)
        
        # í•´ì‹œë¡œ í‚¤ ê¸¸ì´ ì œí•œ
        key_string = '_'.join(key_parts)
        return hashlib.md5(key_string.encode()).hexdigest()
    
    def _analyze_user_context(self, user_id: int, context: Dict = None) -> Dict:
        """ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ë¶„ì„"""
        
        user_context = {
            'user_id': user_id,
            'timestamp': timezone.now().isoformat(),
        }
        
        # ì™¸ë¶€ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        if context:
            user_context.update(context)
        
        # ì‚¬ìš©ì í™œë™ íŒ¨í„´ ë¶„ì„
        recent_interactions = UserInteraction.objects.filter(
            user_id=user_id,
            created__gte=timezone.now() - timedelta(days=7)
        ).count()
        
        user_context['recent_activity_level'] = 'high' if recent_interactions >= 10 else 'low'
        
        # ì‹œê°„ëŒ€ ë¶„ì„
        current_hour = timezone.now().hour
        if 6 <= current_hour < 12:
            user_context['time_segment'] = 'morning'
        elif 12 <= current_hour < 18:
            user_context['time_segment'] = 'afternoon'
        elif 18 <= current_hour < 22:
            user_context['time_segment'] = 'evening'
        else:
            user_context['time_segment'] = 'night'
        
        return user_context
    
    def _log_recommendation_request(self, user_id: int, recommendations: List[Dict],
                                  context: Dict, start_time: float) -> str:
        """ì¶”ì²œ ìš”ì²­ ë¡œê¹…"""
        
        try:
            response_time = int((time.time() - start_time) * 1000)
            
            # ì¶”ì²œ ìš”ì²­ ë¡œê·¸ ìƒì„±
            request = RecommendationRequest.objects.create(
                user_id=user_id,
                num_requested=len(recommendations),
                num_returned=len(recommendations),
                response_time_ms=response_time,
                context=context
            )
            
            # ê°œë³„ ì¶”ì²œ ê²°ê³¼ ë¡œê·¸
            results_to_create = []
            for rec in recommendations:
                results_to_create.append(
                    RecommendationResult(
                        request=request,
                        product_id=rec['product_id'],
                        rank=rec['rank'],
                        score=rec['score'],
                        explanation=rec.get('explanation', {})
                    )
                )
            
            # ë²Œí¬ ìƒì„±
            RecommendationResult.objects.bulk_create(results_to_create)
            
            return str(request.id)
            
        except Exception as e:
            logger.error(f"Error logging recommendation request: {str(e)}")
            return ''
    
    def _combine_similar_products(self, content_similar: List[Dict], 
                                cf_similar: List[Dict]) -> List[Dict]:
        """ìœ ì‚¬ ìƒí’ˆ ê²°ê³¼ ì¡°í•©"""
        
        # ìƒí’ˆë³„ ì ìˆ˜ í•©ì‚°
        product_scores = {}
        
        # ì½˜í…ì¸  ê¸°ë°˜ ì ìˆ˜ (ê°€ì¤‘ì¹˜ 0.6)
        for item in content_similar:
            product_id = item['product_id']
            product_scores[product_id] = {
                'product': item['product'],
                'content_score': item['score'] * 0.6,
                'cf_score': 0
            }
        
        # í˜‘ì—… í•„í„°ë§ ì ìˆ˜ (ê°€ì¤‘ì¹˜ 0.4)
        for item in cf_similar:
            product_id = item['product_id']
            if product_id in product_scores:
                product_scores[product_id]['cf_score'] = item['similarity_score'] * 0.4
            else:
                product_scores[product_id] = {
                    'product': item['product'],
                    'content_score': 0,
                    'cf_score': item['similarity_score'] * 0.4
                }
        
        # ìµœì¢… ì ìˆ˜ ê³„ì‚° ë° ì •ë ¬
        combined_results = []
        for product_id, scores in product_scores.items():
            total_score = scores['content_score'] + scores['cf_score']
            combined_results.append({
                'product_id': product_id,
                'product': scores['product'],
                'score': total_score,
                'algorithm': 'hybrid_similar'
            })
        
        # ì ìˆ˜ìˆœ ì •ë ¬
        combined_results.sort(key=lambda x: x['score'], reverse=True)
        
        return combined_results
    
    def _invalidate_user_cache(self, user_id: int):
        """ì‚¬ìš©ì ê´€ë ¨ ìºì‹œ ë¬´íš¨í™”"""
        
        # ì‚¬ìš©ìë³„ ìºì‹œ íŒ¨í„´ìœ¼ë¡œ ì‚­ì œ
        cache_patterns = [
            f"rec_{user_id}_*",
            f"user_profile_{user_id}",
            f"user_similarities_{user_id}_*"
        ]
        
        # Redisì˜ ê²½ìš° íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ì‚­ì œ ê°€ëŠ¥
        # Django ê¸°ë³¸ ìºì‹œì˜ ê²½ìš° ê°œë³„ í‚¤ ê´€ë¦¬ í•„ìš”
        try:
            cache.delete_pattern(f"rec_{user_id}_*")
        except AttributeError:
            # íŒ¨í„´ ì‚­ì œë¥¼ ì§€ì›í•˜ì§€ ì•ŠëŠ” ìºì‹œ ë°±ì—”ë“œ
            pass
    
    def _generate_realtime_explanation(self, user_id: int, product_id: int) -> Dict:
        """ì‹¤ì‹œê°„ ì¶”ì²œ ì„¤ëª… ìƒì„±"""
        
        try:
            # ì‚¬ìš©ìì˜ ìµœê·¼ ìƒí˜¸ì‘ìš© ë¶„ì„
            recent_interactions = UserInteraction.objects.filter(
                user_id=user_id
            ).select_related('product').order_by('-created')[:10]
            
            explanations = []
            
            # ìœ ì‚¬í•œ ìƒí’ˆ êµ¬ë§¤/ì¡°íšŒ ì´ë ¥
            for interaction in recent_interactions:
                if interaction.product.category_id:
                    try:
                        target_product = Product.objects.get(id=product_id)
                        if (target_product.category_id == interaction.product.category_id):
                            explanations.append(f"Similar to {interaction.product.name} you viewed")
                            break
                    except Product.DoesNotExist:
                        pass
            
            return {
                'explanation': {
                    'primary_reason': explanations[0] if explanations else 'Recommended for you',
                    'confidence': 0.7,
                    'generated_realtime': True
                }
            }
            
        except Exception as e:
            logger.error(f"Error generating realtime explanation: {str(e)}")
            return {'explanation': 'Unable to generate explanation'}
```

---

## ğŸ¯ 6. Django Ninja API ë° ì‹¤ì‹œê°„ ì„œë¹„ìŠ¤

Django Ninjaë¥¼ í™œìš©í•˜ì—¬ ê³ ì„±ëŠ¥ ì¶”ì²œ APIë¥¼ êµ¬í˜„í•˜ê³  ì‹¤ì‹œê°„ ì¶”ì²œ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

### 6.1 Django Ninja API êµ¬í˜„

```python
# apps/recommendations/api.py
from ninja import NinjaAPI, Schema, Query
from ninja.security import HttpBearer
from django.shortcuts import get_object_or_404
from django.contrib.auth.models import User
from django.http import HttpRequest
from typing import List, Optional, Dict, Any
from datetime import datetime
from apps.recommendations.services import RecommendationService
from apps.recommendations.models import UserInteraction
from apps.products.models import Product
import logging

logger = logging.getLogger(__name__)

# API ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
api = NinjaAPI(
    title="Recommendation Engine API",
    version="1.0.0",
    description="Advanced recommendation system powered by Django Ninja",
    docs_url="/recommendations/docs/"
)

# ì¸ì¦ ìŠ¤í‚¤ë§ˆ
class AuthBearer(HttpBearer):
    def authenticate(self, request: HttpRequest, token: str):
        try:
            # JWT í† í° ê²€ì¦ ë¡œì§ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” JWT ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©)
            # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ ì˜ˆì‹œ
            if token.startswith("user_"):
                user_id = int(token.split("_")[1])
                return User.objects.get(id=user_id)
        except:
            pass
        return None

auth = AuthBearer()

# ìš”ì²­/ì‘ë‹µ ìŠ¤í‚¤ë§ˆ
class RecommendationRequest(Schema):
    num_recommendations: int = 10
    strategy: Optional[str] = None
    context: Optional[Dict[str, Any]] = None
    force_refresh: bool = False
    diversity_boost: bool = False

class ProductSchema(Schema):
    id: int
    name: str
    price: float
    image_url: Optional[str] = None
    category: Optional[str] = None
    brand: Optional[str] = None
    rating: Optional[float] = None

class RecommendationItemSchema(Schema):
    product_id: int
    product_name: str
    product_price: float
    product_image: Optional[str] = None
    score: float
    rank: int
    algorithm: str
    explanation: Dict[str, Any]

class RecommendationResponse(Schema):
    recommendations: List[RecommendationItemSchema]
    total_count: int
    algorithm_used: str
    request_id: str
    cache_hit: bool
    response_time_ms: int
    user_context: Optional[Dict[str, Any]] = None

class InteractionRequest(Schema):
    product_id: int
    interaction_type: str  # 'view', 'like', 'purchase', 'cart_add', 'share'
    value: Optional[float] = None
    session_id: Optional[str] = None
    device_type: Optional[str] = None
    source: Optional[str] = None

class InteractionResponse(Schema):
    success: bool
    message: str
    interaction_id: Optional[int] = None

class SimilarProductsResponse(Schema):
    products: List[RecommendationItemSchema]
    total_count: int
    reference_product_id: int

class ExplanationResponse(Schema):
    product_id: int
    explanation: Dict[str, Any]
    score: float
    algorithm_used: str

# ì¶”ì²œ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
recommendation_service = RecommendationService()

@api.post("/recommendations", response=RecommendationResponse, auth=auth)
def get_recommendations(request: HttpRequest, data: RecommendationRequest):
    """ê°œì¸í™”ëœ ì¶”ì²œ ëª©ë¡ ì¡°íšŒ"""
    
    user = request.auth
    
    try:
        # ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
        context = data.context or {}
        context.update({
            'diversity_boost': data.diversity_boost,
            'request_timestamp': datetime.now().isoformat(),
            'user_agent': request.META.get('HTTP_USER_AGENT', ''),
            'ip_address': request.META.get('REMOTE_ADDR', '')
        })
        
        # ì¶”ì²œ ìƒì„±
        result = recommendation_service.get_recommendations(
            user_id=user.id,
            num_recommendations=data.num_recommendations,
            context=context,
            force_refresh=data.force_refresh
        )
        
        # ì‘ë‹µ í¬ë§·íŒ…
        return RecommendationResponse(
            recommendations=[
                RecommendationItemSchema(**rec) for rec in result['recommendations']
            ],
            total_count=result['total_count'],
            algorithm_used=result['algorithm_used'],
            request_id=result['request_id'],
            cache_hit=result.get('cache_hit', False),
            response_time_ms=result['response_time_ms'],
            user_context=result.get('user_context')
        )
        
    except Exception as e:
        logger.error(f"Error in get_recommendations API: {str(e)}")
        return RecommendationResponse(
            recommendations=[],
            total_count=0,
            algorithm_used="error",
            request_id="",
            cache_hit=False,
            response_time_ms=0
        )

@api.post("/interactions", response=InteractionResponse, auth=auth)
def record_interaction(request: HttpRequest, data: InteractionRequest):
    """ì‚¬ìš©ì ìƒí˜¸ì‘ìš© ê¸°ë¡"""
    
    user = request.auth
    
    try:
        # ìƒí˜¸ì‘ìš© ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
        context = {
            'session_id': data.session_id,
            'device_type': data.device_type,
            'source': data.source,
            'timestamp': datetime.now().isoformat(),
            'user_agent': request.META.get('HTTP_USER_AGENT', ''),
            'referer': request.META.get('HTTP_REFERER', '')
        }
        
        # ìƒí˜¸ì‘ìš© ê¸°ë¡
        success = recommendation_service.update_user_interaction(
            user_id=user.id,
            product_id=data.product_id,
            interaction_type=data.interaction_type,
            value=data.value,
            context=context
        )
        
        if success:
            # ìµœê·¼ ìƒì„±ëœ ìƒí˜¸ì‘ìš© ID ì¡°íšŒ
            interaction = UserInteraction.objects.filter(
                user=user,
                product_id=data.product_id,
                interaction_type=data.interaction_type
            ).order_by('-created').first()
            
            return InteractionResponse(
                success=True,
                message="Interaction recorded successfully",
                interaction_id=interaction.id if interaction else None
            )
        else:
            return InteractionResponse(
                success=False,
                message="Failed to record interaction"
            )
            
    except Exception as e:
        logger.error(f"Error recording interaction: {str(e)}")
        return InteractionResponse(
            success=False,
            message=f"Error: {str(e)}"
        )

@api.get("/products/{product_id}/similar", response=SimilarProductsResponse)
def get_similar_products(request: HttpRequest, product_id: int, num_items: int = Query(10)):
    """ìœ ì‚¬ ìƒí’ˆ ì¶”ì²œ"""
    
    try:
        # ìƒí’ˆ ì¡´ì¬ í™•ì¸
        product = get_object_or_404(Product, id=product_id)
        
        # ìœ ì‚¬ ìƒí’ˆ ì¡°íšŒ
        similar_products = recommendation_service.get_similar_products(
            product_id=product_id,
            num_recommendations=num_items
        )
        
        # ì‘ë‹µ í¬ë§·íŒ…
        formatted_products = []
        for item in similar_products:
            formatted_products.append(
                RecommendationItemSchema(
                    product_id=item['product_id'],
                    product_name=item['product'].name,
                    product_price=float(item['product'].price),
                    product_image=getattr(item['product'], 'image_url', ''),
                    score=item['score'],
                    rank=len(formatted_products) + 1,
                    algorithm=item['algorithm'],
                    explanation={'similarity_reason': 'Product similarity based on features'}
                )
            )
        
        return SimilarProductsResponse(
            products=formatted_products,
            total_count=len(formatted_products),
            reference_product_id=product_id
        )
        
    except Exception as e:
        logger.error(f"Error getting similar products: {str(e)}")
        return SimilarProductsResponse(
            products=[],
            total_count=0,
            reference_product_id=product_id
        )

@api.get("/recommendations/{product_id}/explanation", response=ExplanationResponse, auth=auth)
def get_recommendation_explanation(request: HttpRequest, product_id: int):
    """ì¶”ì²œ ì´ìœ  ìƒì„¸ ì„¤ëª…"""
    
    user = request.auth
    
    try:
        explanation = recommendation_service.get_recommendation_explanation(
            user_id=user.id,
            product_id=product_id
        )
        
        return ExplanationResponse(
            product_id=product_id,
            explanation=explanation.get('explanation', {}),
            score=explanation.get('score', 0.0),
            algorithm_used=explanation.get('algorithm_used', 'unknown')
        )
        
    except Exception as e:
        logger.error(f"Error getting explanation: {str(e)}")
        return ExplanationResponse(
            product_id=product_id,
            explanation={'error': str(e)},
            score=0.0,
            algorithm_used='error'
        )

@api.get("/users/stats", auth=auth)
def get_user_stats(request: HttpRequest):
    """ì‚¬ìš©ì ì¶”ì²œ í†µê³„"""
    
    user = request.auth
    
    try:
        from django.db.models import Count, Avg
        from django.utils import timezone
        from datetime import timedelta
        
        # ìµœê·¼ 30ì¼ í†µê³„
        thirty_days_ago = timezone.now() - timedelta(days=30)
        
        stats = {
            'total_interactions': UserInteraction.objects.filter(user=user).count(),
            'recent_interactions': UserInteraction.objects.filter(
                user=user, 
                created__gte=thirty_days_ago
            ).count(),
            'interaction_types': list(
                UserInteraction.objects.filter(user=user)
                .values('interaction_type')
                .annotate(count=Count('id'))
                .order_by('-count')
            ),
            'favorite_categories': [],  # êµ¬í˜„ í•„ìš”
            'recommendation_accuracy': 0.75,  # ì‹¤ì œ ê³„ì‚° í•„ìš”
        }
        
        return stats
        
    except Exception as e:
        logger.error(f"Error getting user stats: {str(e)}")
        return {'error': str(e)}

# ê´€ë¦¬ììš© API
@api.get("/admin/algorithms/performance")
def get_algorithm_performance(request: HttpRequest):
    """ì•Œê³ ë¦¬ì¦˜ ì„±ëŠ¥ í†µê³„ (ê´€ë¦¬ììš©)"""
    
    # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ê´€ë¦¬ì ê¶Œí•œ ì²´í¬ í•„ìš”
    
    try:
        from django.db.models import Avg, Count
        from apps.recommendations.models import RecommendationRequest
        
        # ì•Œê³ ë¦¬ì¦˜ë³„ ì„±ëŠ¥ í†µê³„
        performance_stats = RecommendationRequest.objects.values(
            'algorithm__name'
        ).annotate(
            avg_response_time=Avg('response_time_ms'),
            total_requests=Count('id'),
            avg_returned=Avg('num_returned')
        ).order_by('-total_requests')
        
        return {
            'algorithm_performance': list(performance_stats),
            'total_requests': RecommendationRequest.objects.count(),
            'avg_response_time': RecommendationRequest.objects.aggregate(
                avg=Avg('response_time_ms')
            )['avg']
        }
        
    except Exception as e:
        logger.error(f"Error getting performance stats: {str(e)}")
        return {'error': str(e)}

@api.post("/admin/cache/clear")
def clear_recommendation_cache(request: HttpRequest):
    """ì¶”ì²œ ìºì‹œ í´ë¦¬ì–´ (ê´€ë¦¬ììš©)"""
    
    try:
        from django.core.cache import cache
        
        # íŒ¨í„´ ê¸°ë°˜ ìºì‹œ ì‚­ì œ
        try:
            cache.delete_pattern("rec_*")
            cache.delete_pattern("similar_products_*")
            cache.delete_pattern("user_profile_*")
            return {'success': True, 'message': 'Cache cleared successfully'}
        except AttributeError:
            # íŒ¨í„´ ì‚­ì œë¥¼ ì§€ì›í•˜ì§€ ì•ŠëŠ” ìºì‹œ ë°±ì—”ë“œ
            cache.clear()
            return {'success': True, 'message': 'All cache cleared'}
            
    except Exception as e:
        logger.error(f"Error clearing cache: {str(e)}")
        return {'success': False, 'error': str(e)}

# í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸
@api.get("/health")
def health_check(request: HttpRequest):
    """ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸"""
    
    try:
        from django.db import connection
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì²´í¬
        with connection.cursor() as cursor:
            cursor.execute("SELECT 1")
        
        # ìºì‹œ ì—°ê²° ì²´í¬
        from django.core.cache import cache
        cache.set('health_check', 'ok', 10)
        cache_status = cache.get('health_check') == 'ok'
        
        return {
            'status': 'healthy',
            'timestamp': datetime.now().isoformat(),
            'database': 'ok',
            'cache': 'ok' if cache_status else 'error',
            'version': '1.0.0'
        }
        
    except Exception as e:
        logger.error(f"Health check failed: {str(e)}")
        return {
            'status': 'unhealthy',
            'timestamp': datetime.now().isoformat(),
            'error': str(e)
        }
```

### 6.2 ì‹¤ì‹œê°„ ì¶”ì²œ WebSocket ì„œë¹„ìŠ¤

```python
# apps/recommendations/websocket.py
import json
import asyncio
import logging
from channels.generic.websocket import AsyncWebsocketConsumer
from channels.db import database_sync_to_async
from django.contrib.auth.models import User
from apps.recommendations.services import RecommendationService
from apps.recommendations.models import UserInteraction

logger = logging.getLogger(__name__)

class RecommendationConsumer(AsyncWebsocketConsumer):
    """ì‹¤ì‹œê°„ ì¶”ì²œ WebSocket ì»¨ìŠˆë¨¸"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.user_id = None
        self.room_group_name = None
        self.recommendation_service = RecommendationService()
    
    async def connect(self):
        """WebSocket ì—°ê²°"""
        
        try:
            # URLì—ì„œ ì‚¬ìš©ì ID ì¶”ì¶œ
            self.user_id = self.scope['url_route']['kwargs']['user_id']
            
            # ì¸ì¦ í™•ì¸ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” JWT í† í° ê²€ì¦)
            user = await self.get_user(self.user_id)
            if not user:
                await self.close(code=4001)
                return
            
            # ê·¸ë£¹ ì´ë¦„ ìƒì„±
            self.room_group_name = f"recommendations_{self.user_id}"
            
            # ê·¸ë£¹ ì°¸ê°€
            await self.channel_layer.group_add(
                self.room_group_name,
                self.channel_name
            )
            
            await self.accept()
            
            # ì—°ê²° í™•ì¸ ë©”ì‹œì§€ ì „ì†¡
            await self.send(text_data=json.dumps({
                'type': 'connection_established',
                'message': f'Connected to recommendation stream for user {self.user_id}',
                'timestamp': self._get_timestamp()
            }))
            
            # ì´ˆê¸° ì¶”ì²œ ì „ì†¡
            await self.send_initial_recommendations()
            
        except Exception as e:
            logger.error(f"WebSocket connection error: {str(e)}")
            await self.close(code=4000)
    
    async def disconnect(self, close_code):
        """WebSocket ì—°ê²° í•´ì œ"""
        
        if self.room_group_name:
            await self.channel_layer.group_discard(
                self.room_group_name,
                self.channel_name
            )
    
    async def receive(self, text_data):
        """í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° ë©”ì‹œì§€ ìˆ˜ì‹ """
        
        try:
            data = json.loads(text_data)
            message_type = data.get('type')
            
            if message_type == 'get_recommendations':
                await self.handle_recommendation_request(data)
            
            elif message_type == 'record_interaction':
                await self.handle_interaction(data)
            
            elif message_type == 'get_similar_products':
                await self.handle_similar_products_request(data)
            
            else:
                await self.send_error("Unknown message type")
                
        except json.JSONDecodeError:
            await self.send_error("Invalid JSON format")
        except Exception as e:
            logger.error(f"WebSocket receive error: {str(e)}")
            await self.send_error(str(e))
    
    async def handle_recommendation_request(self, data):
        """ì¶”ì²œ ìš”ì²­ ì²˜ë¦¬"""
        
        try:
            num_recommendations = data.get('num_recommendations', 10)
            context = data.get('context', {})
            force_refresh = data.get('force_refresh', False)
            
            # ì‹¤ì‹œê°„ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
            context.update({
                'channel': 'websocket',
                'real_time': True,
                'session_type': 'streaming'
            })
            
            # ì¶”ì²œ ìƒì„± (ë¹„ë™ê¸°)
            recommendations = await self.get_recommendations_async(
                self.user_id, num_recommendations, context, force_refresh
            )
            
            # í´ë¼ì´ì–¸íŠ¸ì— ì „ì†¡
            await self.send(text_data=json.dumps({
                'type': 'recommendations',
                'data': recommendations,
                'timestamp': self._get_timestamp()
            }))
            
        except Exception as e:
            await self.send_error(f"Recommendation error: {str(e)}")
    
    async def handle_interaction(self, data):
        """ìƒí˜¸ì‘ìš© ê¸°ë¡ ì²˜ë¦¬"""
        
        try:
            product_id = data.get('product_id')
            interaction_type = data.get('interaction_type')
            value = data.get('value')
            
            if not product_id or not interaction_type:
                await self.send_error("Missing product_id or interaction_type")
                return
            
            # ìƒí˜¸ì‘ìš© ê¸°ë¡ (ë¹„ë™ê¸°)
            success = await self.record_interaction_async(
                self.user_id, product_id, interaction_type, value
            )
            
            if success:
                await self.send(text_data=json.dumps({
                    'type': 'interaction_recorded',
                    'product_id': product_id,
                    'interaction_type': interaction_type,
                    'timestamp': self._get_timestamp()
                }))
                
                # ì‹¤ì‹œê°„ ì¶”ì²œ ì—…ë°ì´íŠ¸ íŠ¸ë¦¬ê±°
                await self.trigger_recommendation_update()
            else:
                await self.send_error("Failed to record interaction")
                
        except Exception as e:
            await self.send_error(f"Interaction error: {str(e)}")
    
    async def handle_similar_products_request(self, data):
        """ìœ ì‚¬ ìƒí’ˆ ìš”ì²­ ì²˜ë¦¬"""
        
        try:
            product_id = data.get('product_id')
            num_items = data.get('num_items', 10)
            
            if not product_id:
                await self.send_error("Missing product_id")
                return
            
            # ìœ ì‚¬ ìƒí’ˆ ì¡°íšŒ (ë¹„ë™ê¸°)
            similar_products = await self.get_similar_products_async(product_id, num_items)
            
            await self.send(text_data=json.dumps({
                'type': 'similar_products',
                'product_id': product_id,
                'data': similar_products,
                'timestamp': self._get_timestamp()
            }))
            
        except Exception as e:
            await self.send_error(f"Similar products error: {str(e)}")
    
    async def send_initial_recommendations(self):
        """ì´ˆê¸° ì¶”ì²œ ì „ì†¡"""
        
        try:
            recommendations = await self.get_recommendations_async(self.user_id, 10)
            
            await self.send(text_data=json.dumps({
                'type': 'initial_recommendations',
                'data': recommendations,
                'timestamp': self._get_timestamp()
            }))
            
        except Exception as e:
            logger.error(f"Initial recommendations error: {str(e)}")
    
    async def trigger_recommendation_update(self):
        """ì¶”ì²œ ì—…ë°ì´íŠ¸ íŠ¸ë¦¬ê±°"""
        
        try:
            # ì§§ì€ ì§€ì—° í›„ ì—…ë°ì´íŠ¸ëœ ì¶”ì²œ ì „ì†¡
            await asyncio.sleep(1)
            
            recommendations = await self.get_recommendations_async(
                self.user_id, 10, {'real_time_update': True}, force_refresh=True
            )
            
            await self.send(text_data=json.dumps({
                'type': 'recommendations_updated',
                'data': recommendations,
                'timestamp': self._get_timestamp()
            }))
            
        except Exception as e:
            logger.error(f"Recommendation update error: {str(e)}")
    
    async def send_error(self, message):
        """ì—ëŸ¬ ë©”ì‹œì§€ ì „ì†¡"""
        
        await self.send(text_data=json.dumps({
            'type': 'error',
            'message': message,
            'timestamp': self._get_timestamp()
        }))
    
    def _get_timestamp(self):
        """í˜„ì¬ íƒ€ì„ìŠ¤íƒ¬í”„ ë°˜í™˜"""
        from datetime import datetime
        return datetime.now().isoformat()
    
    # ë¹„ë™ê¸° ë°ì´í„°ë² ì´ìŠ¤ ì‘ì—…
    @database_sync_to_async
    def get_user(self, user_id):
        """ì‚¬ìš©ì ì¡°íšŒ"""
        try:
            return User.objects.get(id=user_id)
        except User.DoesNotExist:
            return None
    
    @database_sync_to_async
    def get_recommendations_async(self, user_id, num_recommendations, context=None, force_refresh=False):
        """ë¹„ë™ê¸° ì¶”ì²œ ì¡°íšŒ"""
        return self.recommendation_service.get_recommendations(
            user_id=user_id,
            num_recommendations=num_recommendations,
            context=context or {},
            force_refresh=force_refresh
        )
    
    @database_sync_to_async
    def record_interaction_async(self, user_id, product_id, interaction_type, value=None):
        """ë¹„ë™ê¸° ìƒí˜¸ì‘ìš© ê¸°ë¡"""
        return self.recommendation_service.update_user_interaction(
            user_id=user_id,
            product_id=product_id,
            interaction_type=interaction_type,
            value=value,
            context={'channel': 'websocket'}
        )
    
    @database_sync_to_async
    def get_similar_products_async(self, product_id, num_items):
        """ë¹„ë™ê¸° ìœ ì‚¬ ìƒí’ˆ ì¡°íšŒ"""
        return self.recommendation_service.get_similar_products(
            product_id=product_id,
            num_recommendations=num_items
        )
    
    # ê·¸ë£¹ ë©”ì‹œì§€ í•¸ë“¤ëŸ¬
    async def recommendation_update(self, event):
        """ê·¸ë£¹ìœ¼ë¡œë¶€í„° ì¶”ì²œ ì—…ë°ì´íŠ¸ ë©”ì‹œì§€ ìˆ˜ì‹ """
        
        await self.send(text_data=json.dumps({
            'type': 'recommendation_update',
            'data': event['data'],
            'timestamp': self._get_timestamp()
        }))

# WebSocket ë¼ìš°íŒ… ì„¤ì •
# apps/recommendations/routing.py
from django.urls import re_path
from . import websocket

websocket_urlpatterns = [
    re_path(r'ws/recommendations/(?P<user_id>\d+)/$', websocket.RecommendationConsumer.as_asgi()),
]
```

### 6.3 ì„±ëŠ¥ ìµœì í™” ë° ëª¨ë‹ˆí„°ë§

```python
# apps/recommendations/monitoring.py
import time
import logging
from functools import wraps
from django.core.cache import cache
from django.db import connection
from django.conf import settings
from typing import Dict, Any, Callable
import json

logger = logging.getLogger(__name__)

class RecommendationMetrics:
    """ì¶”ì²œ ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸°"""
    
    def __init__(self):
        self.metrics_cache_prefix = "metrics_"
        self.metrics_ttl = 3600  # 1ì‹œê°„
    
    def record_api_call(self, endpoint: str, response_time: float, 
                       status_code: int, user_id: int = None):
        """API í˜¸ì¶œ ë©”íŠ¸ë¦­ ê¸°ë¡"""
        
        try:
            # ë©”íŠ¸ë¦­ í‚¤ ìƒì„±
            timestamp = int(time.time())
            minute_bucket = timestamp // 60  # 1ë¶„ ë‹¨ìœ„ ë²„í‚·
            
            metrics_key = f"{self.metrics_cache_prefix}api_{endpoint}_{minute_bucket}"
            
            # ê¸°ì¡´ ë©”íŠ¸ë¦­ ì¡°íšŒ
            current_metrics = cache.get(metrics_key, {
                'calls': 0,
                'total_response_time': 0,
                'status_codes': {},
                'unique_users': set()
            })
            
            # ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            current_metrics['calls'] += 1
            current_metrics['total_response_time'] += response_time
            current_metrics['status_codes'][status_code] = (
                current_metrics['status_codes'].get(status_code, 0) + 1
            )
            
            if user_id:
                current_metrics['unique_users'].add(user_id)
            
            # ìºì‹œ ì €ì¥
            cache.set(metrics_key, current_metrics, self.metrics_ttl)
            
        except Exception as e:
            logger.error(f"Error recording API metrics: {str(e)}")
    
    def record_algorithm_performance(self, algorithm: str, execution_time: float, 
                                   user_id: int, num_results: int, cache_hit: bool):
        """ì•Œê³ ë¦¬ì¦˜ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê¸°ë¡"""
        
        try:
            timestamp = int(time.time())
            hour_bucket = timestamp // 3600  # 1ì‹œê°„ ë‹¨ìœ„
            
            metrics_key = f"{self.metrics_cache_prefix}algo_{algorithm}_{hour_bucket}"
            
            current_metrics = cache.get(metrics_key, {
                'executions': 0,
                'total_execution_time': 0,
                'cache_hits': 0,
                'total_results': 0,
                'unique_users': set()
            })
            
            current_metrics['executions'] += 1
            current_metrics['total_execution_time'] += execution_time
            current_metrics['total_results'] += num_results
            current_metrics['unique_users'].add(user_id)
            
            if cache_hit:
                current_metrics['cache_hits'] += 1
            
            cache.set(metrics_key, current_metrics, self.metrics_ttl * 24)  # 24ì‹œê°„ ë³´ê´€
            
        except Exception as e:
            logger.error(f"Error recording algorithm metrics: {str(e)}")
    
    def get_performance_summary(self, hours: int = 24) -> Dict[str, Any]:
        """ì„±ëŠ¥ ìš”ì•½ ì¡°íšŒ"""
        
        try:
            current_time = int(time.time())
            summary = {
                'api_performance': {},
                'algorithm_performance': {},
                'system_health': {}
            }
            
            # API ì„±ëŠ¥ ì§‘ê³„
            for hour_offset in range(hours):
                hour_bucket = (current_time - (hour_offset * 3600)) // 3600
                
                # API ë©”íŠ¸ë¦­ íŒ¨í„´ìœ¼ë¡œ ê²€ìƒ‰ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” Redis SCAN ë“± ì‚¬ìš©)
                # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ ì˜ˆì‹œ
                pass
            
            # ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
            summary['system_health'] = self._check_system_health()
            
            return summary
            
        except Exception as e:
            logger.error(f"Error getting performance summary: {str(e)}")
            return {}
    
    def _check_system_health(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸"""
        
        health = {
            'database': 'unknown',
            'cache': 'unknown',
            'memory_usage': 0,
            'active_connections': 0
        }
        
        try:
            # ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ
            with connection.cursor() as cursor:
                cursor.execute("SELECT 1")
                health['database'] = 'healthy'
        except:
            health['database'] = 'unhealthy'
        
        try:
            # ìºì‹œ ìƒíƒœ
            cache.set('health_test', 'ok', 10)
            health['cache'] = 'healthy' if cache.get('health_test') == 'ok' else 'unhealthy'
        except:
            health['cache'] = 'unhealthy'
        
        # í™œì„± ì—°ê²° ìˆ˜
        health['active_connections'] = len(connection.queries)
        
        return health

# ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° ì¸ìŠ¤í„´ìŠ¤
metrics = RecommendationMetrics()

def track_performance(endpoint_name: str):
    """ì„±ëŠ¥ ì¶”ì  ë°ì½”ë ˆì´í„°"""
    
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(*args, **kwargs):
            start_time = time.time()
            
            try:
                result = func(*args, **kwargs)
                status_code = 200
                
                # ì‚¬ìš©ì ID ì¶”ì¶œ ì‹œë„
                user_id = None
                if args and hasattr(args[0], 'auth') and args[0].auth:
                    user_id = args[0].auth.id
                
                return result
                
            except Exception as e:
                status_code = 500
                raise
                
            finally:
                execution_time = (time.time() - start_time) * 1000  # ms
                
                # ë©”íŠ¸ë¦­ ê¸°ë¡
                metrics.record_api_call(
                    endpoint=endpoint_name,
                    response_time=execution_time,
                    status_code=status_code,
                    user_id=user_id
                )
        
        return wrapper
    return decorator

def track_algorithm(algorithm_name: str):
    """ì•Œê³ ë¦¬ì¦˜ ì„±ëŠ¥ ì¶”ì  ë°ì½”ë ˆì´í„°"""
    
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(*args, **kwargs):
            start_time = time.time()
            
            result = func(*args, **kwargs)
            
            execution_time = (time.time() - start_time) * 1000  # ms
            
            # ê²°ê³¼ì—ì„œ ë©”íŠ¸ë¦­ ì •ë³´ ì¶”ì¶œ
            num_results = len(result) if isinstance(result, list) else 0
            cache_hit = kwargs.get('cache_hit', False)
            user_id = kwargs.get('user_id', 0)
            
            # ë©”íŠ¸ë¦­ ê¸°ë¡
            metrics.record_algorithm_performance(
                algorithm=algorithm_name,
                execution_time=execution_time,
                user_id=user_id,
                num_results=num_results,
                cache_hit=cache_hit
            )
            
            return result
        
        return wrapper
    return decorator

class RecommendationProfiler:
    """ì¶”ì²œ ì‹œìŠ¤í…œ í”„ë¡œíŒŒì¼ëŸ¬"""
    
    def __init__(self):
        self.active_profiles = {}
    
    def start_profile(self, profile_id: str, context: Dict = None):
        """í”„ë¡œíŒŒì¼ë§ ì‹œì‘"""
        
        self.active_profiles[profile_id] = {
            'start_time': time.time(),
            'context': context or {},
            'steps': []
        }
    
    def add_step(self, profile_id: str, step_name: str, duration: float = None):
        """í”„ë¡œíŒŒì¼ë§ ë‹¨ê³„ ì¶”ê°€"""
        
        if profile_id in self.active_profiles:
            step_time = time.time()
            
            self.active_profiles[profile_id]['steps'].append({
                'name': step_name,
                'timestamp': step_time,
                'duration': duration
            })
    
    def end_profile(self, profile_id: str) -> Dict[str, Any]:
        """í”„ë¡œíŒŒì¼ë§ ì¢…ë£Œ"""
        
        if profile_id not in self.active_profiles:
            return {}
        
        profile = self.active_profiles.pop(profile_id)
        total_time = time.time() - profile['start_time']
        
        return {
            'profile_id': profile_id,
            'total_time_ms': total_time * 1000,
            'context': profile['context'],
            'steps': profile['steps'],
            'steps_count': len(profile['steps'])
        }

# ì „ì—­ í”„ë¡œíŒŒì¼ëŸ¬ ì¸ìŠ¤í„´ìŠ¤
profiler = RecommendationProfiler()

# ëª¨ë‹ˆí„°ë§ ë¯¸ë“¤ì›¨ì–´
class RecommendationMonitoringMiddleware:
    """ì¶”ì²œ API ëª¨ë‹ˆí„°ë§ ë¯¸ë“¤ì›¨ì–´"""
    
    def __init__(self, get_response):
        self.get_response = get_response
    
    def __call__(self, request):
        # ì¶”ì²œ API ê²½ë¡œ í™•ì¸
        if '/recommendations/' in request.path:
            start_time = time.time()
            
            response = self.get_response(request)
            
            # ì‘ë‹µ ì‹œê°„ ê³„ì‚°
            response_time = (time.time() - start_time) * 1000
            
            # ë©”íŠ¸ë¦­ ê¸°ë¡
            endpoint = self._extract_endpoint(request.path)
            user_id = getattr(request.user, 'id', None) if hasattr(request, 'user') else None
            
            metrics.record_api_call(
                endpoint=endpoint,
                response_time=response_time,
                status_code=response.status_code,
                user_id=user_id
            )
            
            # ì‘ë‹µ í—¤ë”ì— ì„±ëŠ¥ ì •ë³´ ì¶”ê°€
            response['X-Response-Time'] = f"{response_time:.2f}ms"
            
            return response
        
        return self.get_response(request)
    
    def _extract_endpoint(self, path: str) -> str:
        """ê²½ë¡œì—ì„œ ì—”ë“œí¬ì¸íŠ¸ëª… ì¶”ì¶œ"""
        
        if '/recommendations' in path and path.endswith('/recommendations'):
            return 'get_recommendations'
        elif '/interactions' in path:
            return 'record_interaction'
        elif '/similar' in path:
            return 'get_similar_products'
        elif '/explanation' in path:
            return 'get_explanation'
        else:
            return 'unknown'
```

---

## ğŸ“Š 7. A/B í…ŒìŠ¤íŠ¸ ë° ì„±ëŠ¥ ë¶„ì„